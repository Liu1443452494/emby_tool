
import logging
import threading
import time
import random
import requests
import json
import os
from typing import List, Dict, Optional, Tuple, Iterable
from urllib.parse import quote
from datetime import datetime
from bs4 import BeautifulSoup
import re
import difflib


from log_manager import ui_logger
from models import AppConfig, ScheduledTasksTargetScope
from task_manager import TaskManager

DOUBAN_FIXER_CACHE_FILE = os.path.join('/app/data', 'douban_fix_cache.json')

class DoubanFixerLogic:
    def __init__(self, app_config: AppConfig):
        self.app_config = app_config
        self.server_config = app_config.server_config
        self.fixer_config = app_config.douban_fixer_config
        self.base_url = self.server_config.server
        self.api_key = self.server_config.api_key
        self.user_id = self.server_config.user_id
        self.params = {"api_key": self.api_key}
        self.session = requests.Session()
        
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
            'Cookie': self.fixer_config.cookie
        })

    def _get_emby_item_details(self, item_id: str) -> Optional[Dict]:
        try:
            url = f"{self.base_url}/Users/{self.user_id}/Items/{item_id}"
            params = {**self.params, "Fields": "ProviderIds,ProductionYear,Name"}
            response = self.session.get(url, params=params, timeout=15)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:

            logging.error(f"ã€è±†ç“£ä¿®å¤å™¨ã€‘è·å– Emby åª’ä½“è¯¦æƒ… (ID: {item_id}) å¤±è´¥: {e}")
            return None

    def _update_emby_item_douban_id(self, item_id: str, douban_id: str, task_cat: str) -> bool:
        try:
            item_details = self._get_emby_item_details(item_id)
            if not item_details:
                return False
            
            if "ProviderIds" not in item_details:
                item_details["ProviderIds"] = {}
            
            provider_ids_lower = {k.lower(): v for k, v in item_details.get("ProviderIds", {}).items()}
            original_id = provider_ids_lower.get("douban")
            item_name = item_details.get('Name', 'æœªçŸ¥åª’ä½“')
            if original_id == douban_id:
                ui_logger.info(f"åª’ä½“ã€{item_name}ã€‘çš„è±†ç“£IDå·²æ˜¯ {douban_id}ï¼Œæ— éœ€æ›´æ–°ã€‚", task_category=task_cat)
                return True

            item_details["ProviderIds"]["Douban"] = douban_id
            
            update_url = f"{self.base_url}/Items/{item_id}"
            headers = {'Content-Type': 'application/json'}
            response = self.session.post(update_url, params=self.params, json=item_details, headers=headers, timeout=20)
            response.raise_for_status()
            
            log_msg = f"æ—§åª’ä½“: ã€{item_name}ã€‘({item_details.get('ProductionYear', 'N/A')}) ---> æ–°åª’ä½“: è±†ç“£ID {douban_id}"
            ui_logger.info(f"æ›´æ–°æˆåŠŸï¼{log_msg}", task_category=task_cat)
            
            return True
        except Exception as e:
            ui_logger.error(f"æ›´æ–° Emby åª’ä½“ (ID: {item_id}) çš„è±†ç“£IDæ—¶å¤±è´¥: {e}", task_category=task_cat)
            return False


    def _search_douban(self, title: str, task_cat: str) -> Optional[List[Dict]]:
        try:
            
            base_cooldown = self.fixer_config.api_cooldown
            jitter = random.uniform(0, 5) # å¢åŠ  0-5 ç§’çš„éšæœºæŠ–åŠ¨
            actual_wait = base_cooldown + jitter
            
            ui_logger.info(f"â¡ï¸ [è±†ç“£æœç´¢] å‡†å¤‡ä¸ºã€{title}ã€‘æœç´¢ï¼Œå°†ç­‰å¾… {actual_wait:.1f} ç§’ (å«éšæœºå»¶è¿Ÿ)...", task_category=task_cat)
            time.sleep(actual_wait)
            
            search_url = f"https://search.douban.com/movie/subject_search?search_text={quote(title)}&cat=1002"
            response = self.session.get(search_url, timeout=20)
            response.raise_for_status()

            match = re.search(r'window\.__DATA__ = (\{.*\});', response.text)
            if not match:
                ui_logger.warning(f"âš ï¸ [è±†ç“£æœç´¢] æœç´¢ã€{title}ã€‘æˆåŠŸï¼Œä½†æœªåœ¨é¡µé¢ä¸­æ‰¾åˆ° window.__DATA__ æ•°æ®å—ã€‚è±†ç“£é¡µé¢ç»“æ„å¯èƒ½å·²æ›´æ–°ã€‚", task_category=task_cat)

                return []

            data = json.loads(match.group(1))
            items = data.get('items', [])
            
            results = []
            for item in items:
                full_title = item.get('title', '')
                year_match = re.search(r'\((\d{4})\)$', full_title.strip())
                year = int(year_match.group(1)) if year_match else None
                clean_title = re.sub(r'\s*\(\d{4}\)$', '', full_title).strip()

                results.append({
                    "id": str(item.get('id')),
                    "title": clean_title,
                    "year": year,
                    "info": item.get('abstract', ''),
                    "poster": item.get('cover_url', '')
                })
            
            
            if results:
                ui_logger.info(f"âœ… [è±†ç“£æœç´¢] æˆåŠŸä¸ºã€{title}ã€‘è§£æåˆ° {len(results)} ä¸ªç»“æœã€‚", task_category=task_cat)
            else:
                ui_logger.warning(f"ğŸ” [è±†ç“£æœç´¢] ä¸ºã€{title}ã€‘çš„æœç´¢è¯·æ±‚æˆåŠŸï¼Œä½†è§£æåˆ°çš„ç»“æœåˆ—è¡¨ä¸ºç©ºã€‚", task_category=task_cat)
            return results
            
            
        except requests.RequestException as e:
            
            ui_logger.error(f"âŒ [è±†ç“£æœç´¢] æœç´¢ã€{title}ã€‘æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}", task_category=task_cat)
            
            return None
        except Exception as e:
            
            ui_logger.error(f"âŒ [è±†ç“£æœç´¢] è§£æã€{title}ã€‘çš„æœç´¢é¡µé¢æˆ–JSONæ•°æ®æ—¶å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            
            return None

    def _find_match_in_results(self, emby_item: Dict, search_results: List[Dict], task_cat: str) -> Optional[str]:
        emby_title = emby_item.get("Name", "").strip()
        emby_year = emby_item.get("ProductionYear")

        if not emby_title or not emby_year:
            return None

        for result in search_results:
            douban_title = result.get("title", "")
            douban_year = result.get("year")
            douban_id = result.get("id")

            if douban_title.startswith(emby_title) and douban_year and abs(douban_year - emby_year) <= 1:
                ui_logger.info(f"ä¸ºã€{emby_item.get('Name')}ã€‘æ‰¾åˆ°åŒ¹é…: ã€{result.get('title')}ã€‘({douban_year}) -> ID: {douban_id}", task_category=task_cat)
                return douban_id
            
        ui_logger.info(f"ç­–ç•¥1æœªå‘½ä¸­ï¼Œå°è¯•ç­–ç•¥2(é™çº§æ¨¡ç³ŠåŒ¹é…)...", task_category=task_cat)
        
        def clean_text(text):
            # å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦ï¼Œè½¬å°å†™
            return re.sub(r'[^\w\u4e00-\u9fa5]', '', text).lower()

        cleaned_emby_title = clean_text(emby_title)
        if cleaned_emby_title:
            best_match = None
            highest_score = 0.0

            for result in search_results:
                douban_year = result.get("year")
                # 1. å¹´ä»½åˆç­› (è¯¯å·® <= 1)
                if not douban_year or abs(douban_year - emby_year) > 1:
                    continue

                douban_title = result.get("title", "")
                cleaned_douban_title = clean_text(douban_title)
                
                # 2. è®¡ç®—è¦†ç›–ç‡ç›¸ä¼¼åº¦ (åŒ¹é…å­—ç¬¦æ•° / Embyæ ‡é¢˜é•¿åº¦)
                matcher = difflib.SequenceMatcher(None, cleaned_emby_title, cleaned_douban_title)
                match_size = sum(block.size for block in matcher.get_matching_blocks())
                
                score = match_size / len(cleaned_emby_title) if len(cleaned_emby_title) > 0 else 0
                
                if score > highest_score:
                    highest_score = score
                    best_match = result

            THRESHOLD = 0.7
            if best_match and highest_score >= THRESHOLD:
                douban_id = best_match.get("id")
                douban_title = best_match.get("title")
                # --- ä¿®æ”¹ ---
                douban_year_log = best_match.get("year")
                ui_logger.info(f"ç­–ç•¥2å‘½ä¸­! åŸæ ‡é¢˜:ã€{emby_title}({emby_year})ã€‘ åŒ¹é…:ã€{douban_title}({douban_year_log})ã€‘ ç›¸ä¼¼åº¦: {highest_score:.2f} (é˜ˆå€¼: {THRESHOLD}) -> ID: {douban_id}", task_category=task_cat)
                # --- ä¿®æ”¹ç»“æŸ ---
                return douban_id
            else:
                if best_match:
                    ui_logger.info(f"ç­–ç•¥2å¤±è´¥ã€‚æœ€é«˜ç›¸ä¼¼åº¦: {highest_score:.2f} (æ¥è‡ª: {best_match.get('title')}) æœªè¾¾åˆ°é˜ˆå€¼ {THRESHOLD}", task_category=task_cat)
        
        return None

    def _load_cache(self) -> Dict[str, Dict]:
        if not os.path.exists(DOUBAN_FIXER_CACHE_FILE):
            return {}
        try:
            with open(DOUBAN_FIXER_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (IOError, json.JSONDecodeError):
            return {}

    def _save_cache(self, cache_data: Dict[str, Dict]):
        try:
            with open(DOUBAN_FIXER_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=4, ensure_ascii=False)
        except IOError as e:

            logging.error(f"ã€è±†ç“£ä¿®å¤å™¨ã€‘ä¿å­˜å¤±è´¥ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def add_to_cache(self, item_details: Dict, task_cat: str):
        cache = self._load_cache()
        item_id = str(item_details['Id'])
        item_name = item_details.get("Name", "æœªçŸ¥åª’ä½“")
        if item_id not in cache:
            cache[item_id] = {
                "Id": item_id,
                "Name": item_name,
                "ProductionYear": item_details.get("ProductionYear"),
                "Type": item_details.get("Type"),
                "AddedTime": datetime.now().isoformat()
            }
            self._save_cache(cache)
            ui_logger.warning(f"åª’ä½“ã€{item_name}ã€‘åŒ¹é…å¤±è´¥ï¼Œå·²æ·»åŠ åˆ°ç¼“å­˜ã€‚", task_category=task_cat)

    def remove_from_cache(self, item_id: str, task_cat: str):
        cache = self._load_cache()
        if str(item_id) in cache:
            del cache[str(item_id)]
            self._save_cache(cache)
            ui_logger.info(f"åª’ä½“é¡¹ {item_id} å·²ä»å¤±è´¥ç¼“å­˜ä¸­ç§»é™¤ã€‚", task_category=task_cat)

    def _process_single_item_for_fixing(self, item_id: str, task_cat: str) -> bool:
        """å¤„ç†å•ä¸ªåª’ä½“é¡¹çš„IDä¿®å¤é€»è¾‘ï¼Œè¿”å›æ˜¯å¦æˆåŠŸä¿®å¤ã€‚"""
        item_details = self._get_emby_item_details(item_id)
        if not item_details:
            ui_logger.warning(f"  -> è·å– Emby åª’ä½“è¯¦æƒ… (ID: {item_id}) å¤±è´¥ï¼Œè·³è¿‡ã€‚", task_category=task_cat)
            return False
        
        item_name = item_details.get("Name", "æœªçŸ¥åç§°")
        ui_logger.info(f"  -> æ­£åœ¨å¤„ç†ã€{item_name}ã€‘(ID: {item_id})", task_category=task_cat)

        provider_ids = item_details.get("ProviderIds", {})
        provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
        if 'douban' in provider_ids_lower:
            ui_logger.debug(f"     -- è·³è¿‡ï¼Œå·²å­˜åœ¨è±†ç“£ID: {provider_ids_lower['douban']}", task_category=task_cat)
            return False

        search_results = self._search_douban(item_name, task_cat)
        if search_results is None:
            ui_logger.warning(f"     -- æœç´¢è±†ç“£å¤±è´¥ï¼Œå°†æ·»åŠ åˆ°ç¼“å­˜ã€‚", task_category=task_cat)
            self.add_to_cache(item_details, task_cat)
            return False

        matched_douban_id = self._find_match_in_results(item_details, search_results, task_cat)
        if matched_douban_id:
            if self._update_emby_item_douban_id(item_id, matched_douban_id, task_cat):
                ui_logger.info(f"     -- åŒ¹é…å¹¶æ›´æ–°æˆåŠŸï¼æ–°ID: {matched_douban_id}", task_category=task_cat)
                self.remove_from_cache(item_id, task_cat)
                return True
            else:
                ui_logger.error(f"     -- åŒ¹é…æˆåŠŸä½†æ›´æ–°Embyå¤±è´¥ï¼Œå°†æ·»åŠ åˆ°ç¼“å­˜ã€‚", task_category=task_cat)
                self.add_to_cache(item_details, task_cat)
                return False
        else:
            ui_logger.warning(f"     -- æœªæ‰¾åˆ°åŒ¹é…ç»“æœï¼Œå°†æ·»åŠ åˆ°ç¼“å­˜ã€‚", task_category=task_cat)
            self.add_to_cache(item_details, task_cat)
            return False

    def run_fixer_for_items(self, item_ids: Iterable[str], cancellation_event: threading.Event, task_id: str, task_manager: TaskManager, task_category: str):
        """ä¸ºæŒ‡å®šçš„åª’ä½“IDåˆ—è¡¨æ‰§è¡ŒIDä¿®å¤"""
        ui_logger.info("æ­£åœ¨æ¸…ç©ºæ—§çš„å¤±è´¥ç¼“å­˜...", task_category=task_category)
        self._save_cache({})

        item_ids_list = list(item_ids)
        total_items = len(item_ids_list)
        ui_logger.info(f"ä»»åŠ¡å¯åŠ¨ï¼Œå…±éœ€å¤„ç† {total_items} ä¸ªåª’ä½“é¡¹ã€‚", task_category=task_category)
        task_manager.update_task_progress(task_id, 0, total_items)

        if total_items == 0:
            ui_logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„åª’ä½“é¡¹ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_category)
            return

        fixed_count = 0
        for i, item_id in enumerate(item_ids_list):
            if cancellation_event.is_set():
                ui_logger.warning("ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_category)
                break
            
            task_manager.update_task_progress(task_id, i + 1, total_items)
            if self._process_single_item_for_fixing(item_id, task_category):
                fixed_count += 1
        
        ui_logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œå…±æˆåŠŸä¿®å¤äº† {fixed_count} ä¸ªé¡¹ç›®ã€‚", task_category=task_category)
        return {"fixed_count": fixed_count}

    def scan_and_match_task(self, scope: ScheduledTasksTargetScope, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """æ‰§è¡Œè±†ç“£IDä¿®å¤æ‰«æä»»åŠ¡"""
        task_cat = f"è±†ç“£ä¿®å¤å™¨({scope.mode})"
        
        # è¯¦ç»†çš„èŒƒå›´æ—¥å¿—
        scope_desc = f"æ¨¡å¼: {scope.mode}"
        if scope.mode == 'by_library':
            scope_desc += f", åº“ID: {scope.library_ids}"
        elif scope.mode == 'by_type':
            scope_desc += f", ç±»å‹: {scope.media_type}"
        elif scope.mode == 'latest':
            scope_desc += f", æœ€è¿‘ {scope.days} å¤©, é™åˆ¶ {scope.limit} æ¡"
        elif scope.mode == 'by_search':
            scope_desc += f", æœç´¢è¯: {scope.item_ids[0] if scope.item_ids else 'æ— '}"
            
        ui_logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ‰«æä»»åŠ¡ï¼ŒèŒƒå›´é…ç½® -> {scope_desc}", task_category=task_cat)
        
        from media_selector import MediaSelector
        
        try:
            selector = MediaSelector(self.app_config)
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ scope å¯¹è±¡è·å– ID åˆ—è¡¨
            item_ids_to_process = selector.get_item_ids(scope)
            
            if not item_ids_to_process:
                ui_logger.warning(f"âš ï¸ æ ¹æ®å½“å‰èŒƒå›´é…ç½®ï¼Œæœªæ‰¾åˆ°ä»»ä½•éœ€è¦å¤„ç†çš„åª’ä½“é¡¹ã€‚ä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
                return

            ui_logger.info(f"âœ… èŒƒå›´ç­›é€‰å®Œæˆï¼Œå…±è·å–åˆ° {len(item_ids_to_process)} ä¸ªåª’ä½“é¡¹ï¼Œå‡†å¤‡å¼€å§‹ä¿®å¤...", task_category=task_cat)
            
            self.run_fixer_for_items(item_ids_to_process, cancellation_event, task_id, task_manager, task_cat)
            
        except Exception as e:
            ui_logger.error(f"âŒ æ‰«æä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}", task_category=task_cat, exc_info=True)