# backend/media_tagger_logic.py (å®Œæ•´æ–‡ä»¶è¦†ç›– - é€»è¾‘éš”ç¦»æœ€ç»ˆç‰ˆ)

import logging
import threading
import requests
from typing import Dict, List, Set, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

from models import AppConfig, MediaTaggerConfig, MediaTaggerRule
from log_manager import ui_logger
from task_manager import TaskManager
from proxy_manager import ProxyManager

class MediaTaggerLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.server_config = config.server_config
        self.tagger_config = config.media_tagger_config
        self.proxy_manager = ProxyManager(config)
        self.session = requests.Session()
        self._library_cache = None
        self._physical_library_cache = None

    # --- é»˜è®¤çš„ã€ç”¨äºæ‰¹é‡ä»»åŠ¡çš„åª’ä½“åº“è·å–æ–¹æ³• (åŸºäº /Views) ---
    def _get_libraries(self) -> List[Dict]:
        if self._library_cache is not None:
            return self._library_cache
        task_cat = "åª’ä½“æ ‡ç­¾å™¨"
        try:
            url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Views"
            params = {"api_key": self.server_config.api_key}
            proxies = self.proxy_manager.get_proxies(url)
            response = self.session.get(url, params=params, timeout=15, proxies=proxies)
            response.raise_for_status()
            views = response.json().get("Items", [])
            libraries = [
                {"Id": v["Id"], "Name": v["Name"]} 
                for v in views 
                if v.get("Id") and v.get("Name")
            ]
            self._library_cache = libraries
            return self._library_cache
        except Exception as e:
            logging.error(f"ã€{task_cat}ã€‘è·å–åª’ä½“åº“åˆ—è¡¨ (/Views) å¤±è´¥: {e}", exc_info=True)
            return []

    # --- ä¸“ç”¨äº Webhook çš„ã€åŸºäºç‰©ç†è·¯å¾„çš„åª’ä½“åº“åŒ¹é…æ–¹æ³• ---
    def _get_library_for_item_by_path(self, item_id: str) -> Optional[Dict]:
        task_cat = "åª’ä½“æ ‡ç­¾å™¨-Webhook"
        try:
            # 1. è·å–åª’ä½“é¡¹çš„ç‰©ç†è·¯å¾„
            item_url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
            params = {"api_key": self.server_config.api_key, "Fields": "Path"}
            proxies = self.proxy_manager.get_proxies(item_url)
            response = self.session.get(item_url, params=params, timeout=15, proxies=proxies)
            response.raise_for_status()
            item_path = response.json().get('Path')
            if not item_path:
                ui_logger.warning(f"âš ï¸ æ— æ³•è·å–åª’ä½“é¡¹ (ID: {item_id}) çš„ç‰©ç†è·¯å¾„ï¼Œæ— æ³•è¿›è¡ŒåŒ¹é…ã€‚", task_cat=task_cat)
                return None

            # 2. è·å–æ‰€æœ‰åª’ä½“åº“åŠå…¶æ‰«æè·¯å¾„ (å¸¦ç¼“å­˜)
            if self._physical_library_cache is None:
                folders_url = f"{self.server_config.server}/Library/VirtualFolders/Query"
                folders_params = {"api_key": self.server_config.api_key}
                folders_proxies = self.proxy_manager.get_proxies(folders_url)
                folders_response = self.session.get(folders_url, params=folders_params, timeout=15, proxies=folders_proxies)
                if folders_response.status_code == 404:
                    folders_url = f"{self.server_config.server}/emby/Library/VirtualFolders/Query"
                    folders_response = self.session.get(folders_url, params=folders_params, timeout=15, proxies=folders_proxies)
                folders_response.raise_for_status()
                self._physical_library_cache = folders_response.json().get("Items", [])
            
            all_physical_libraries = self._physical_library_cache

            # 3. è¿›è¡Œå‰ç¼€åŒ¹é…
            for library in all_physical_libraries:
                if library.get("CollectionType") == "boxsets": continue # æ˜¾å¼è·³è¿‡åˆé›†
                locations = library.get("Locations", [])
                for loc_path in locations:
                    if item_path.startswith(loc_path):
                        return {"Id": library.get("ItemId", library.get("Id")), "Name": library.get("Name")}
            return None
        except Exception as e:
            logging.error(f"ã€{task_cat}ã€‘é€šè¿‡ç‰©ç†è·¯å¾„ä¸ºåª’ä½“é¡¹ {item_id} åŒ¹é…åª’ä½“åº“æ—¶å‡ºé”™: {e}", exc_info=True)
            return None

    def _parse_item_data(self, item: Dict, lib_id: str, library_name: str) -> Dict:
        item_id = item.get('Id')
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¢å¼ºæ ‡ç­¾å’Œç±»å‹çš„è§£æé€»è¾‘ï¼Œä½¿å…¶æ›´å¥å£® ---
        tags_set = set()
        # ä¼˜å…ˆå¤„ç† TagItems (å¯¹è±¡åˆ—è¡¨)
        if 'TagItems' in item and isinstance(item['TagItems'], list):
            tags_set = {t.get('Name') for t in item.get('TagItems', []) if isinstance(t, dict) and t.get('Name')}
        # é™çº§å¤„ç† Tags (å­—ç¬¦ä¸²åˆ—è¡¨)
        elif 'Tags' in item and isinstance(item['Tags'], list):
            tags_set = {tag for tag in item['Tags'] if isinstance(tag, str)}

        genres_set = set()
        # ä¼˜å…ˆå¤„ç† GenreItems (å¯¹è±¡åˆ—è¡¨)
        if 'GenreItems' in item and isinstance(item['GenreItems'], list):
            genres_set = {g.get('Name') for g in item.get('GenreItems', []) if isinstance(g, dict) and g.get('Name')}
        # é™çº§å¤„ç† Genres (å­—ç¬¦ä¸²åˆ—è¡¨)
        elif 'Genres' in item and isinstance(item['Genres'], list):
            genres_set = {genre for genre in item['Genres'] if isinstance(genre, str)}
        # --- ä¿®æ”¹ç»“æŸ ---

        return {
            'Id': item_id, 'Name': item.get('Name', f"ID {item_id}"),
            'LibraryId': lib_id, 'LibraryName': library_name,
            'Tags': tags_set, 'Genres': genres_set
        }

    # backend/media_tagger_logic.py (å‡½æ•°æ›¿æ¢)

    def _get_items_from_library(self, library_id: str, fields: str) -> List[Dict]:
        """è·å–æŒ‡å®šåª’ä½“åº“ä¸­çš„æ‰€æœ‰åª’ä½“é¡¹ï¼Œå¹¶åŒ…å«æŒ‡å®šå­—æ®µ"""
        task_cat = "åª’ä½“æ ‡ç­¾å™¨"
        all_items = []
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šç»Ÿä¸€ä½¿ç”¨ç³»ç»Ÿçº§ /Items ç«¯ç‚¹ ---
        url = f"{self.server_config.server}/Items"
        params = {
            "api_key": self.server_config.api_key, "ParentId": library_id,
            "Recursive": "true", "IncludeItemTypes": "Movie,Series", "Fields": fields
        }
        # --- ä¿®æ”¹ç»“æŸ ---
        start_index = 0
        while True:
            params["StartIndex"] = start_index
            try:
                proxies = self.proxy_manager.get_proxies(url)
                response = self.session.get(url, params=params, timeout=60, proxies=proxies)
                response.raise_for_status()
                page_items = response.json().get("Items", [])
                if not page_items: break
                all_items.extend(page_items)
                start_index += len(page_items)
            except requests.RequestException as e:
                ui_logger.error(f"ã€{task_cat}ã€‘ä»åª’ä½“åº“ {library_id} è·å–é¡¹ç›®æ—¶å‡ºé”™: {e}", task_category=task_cat)
                break
        return all_items

    def _get_media_from_libraries(self, library_ids: List[str], task_cat: str) -> Dict[str, Dict[str, Any]]:
        all_libraries = self._get_libraries()
        target_libraries = [lib for lib in all_libraries if lib['Id'] in library_ids]
        library_names = {lib['Id']: lib['Name'] for lib in target_libraries}
        ui_logger.info(f"ğŸ” å°†æ‰«æ {len(target_libraries)} ä¸ªåª’ä½“åº“: {[lib['Name'] for lib in target_libraries]}", task_category=task_cat)
        all_parsed_items = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_lib = {
                executor.submit(self._get_items_from_library, lib['Id'], "Tags,TagItems,Genres"): lib['Id'] 
                for lib in target_libraries
            }
            for future in as_completed(future_to_lib):
                lib_id = future_to_lib[future]
                try:
                    items = future.result()
                    for item in items:
                        if isinstance(item, dict) and item.get('Id'):
                            parsed_data = self._parse_item_data(item, lib_id, library_names[lib_id])
                            all_parsed_items[parsed_data['Id']] = parsed_data
                        else:
                            logging.warning(f"ã€{task_cat}ã€‘åœ¨åª’ä½“åº“ (ID: {lib_id}) ä¸­å‘ç°ä¸€ä¸ªéæ ‡å‡†æ ¼å¼çš„é¡¹ç›®ï¼Œå·²è·³è¿‡: {item}")
                except Exception as e:
                    ui_logger.error(f"âŒ å¤„ç†åª’ä½“åº“ (ID: {lib_id}) å†…å®¹æ—¶å¤±è´¥: {e}", task_category=task_cat)
        ui_logger.info(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…±è·å–åˆ° {len(all_parsed_items)} ä¸ªåª’ä½“é¡¹ã€‚", task_category=task_cat)
        return all_parsed_items

    def _update_item_tags(self, item_id: str, final_tags: List[str]) -> bool:
        task_cat = "åª’ä½“æ ‡ç­¾å™¨"
        try:
            get_url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
            params = {"api_key": self.server_config.api_key}
            proxies = self.proxy_manager.get_proxies(get_url)
            response = self.session.get(get_url, params=params, timeout=15, proxies=proxies)
            response.raise_for_status()
            item_data = response.json()
            sorted_final_tags = sorted(list(final_tags))
            item_data['Tags'] = sorted_final_tags
            item_data['TagItems'] = [{"Name": tag} for tag in sorted_final_tags]
            locked_fields = set(item_data.get('LockedFields', []))
            if 'Tags' in locked_fields:
                ui_logger.info(f"   - â„¹ï¸ æ³¨æ„ï¼šåª’ä½“é¡¹ã€{item_data.get('Name')}ã€‘çš„æ ‡ç­¾å­—æ®µè¢«é”å®šï¼Œå°†ä¸´æ—¶è§£é”ä»¥è¿›è¡Œæ›´æ–°ã€‚", task_cat=task_cat)
                locked_fields.remove('Tags')
                item_data['LockedFields'] = list(locked_fields)
            update_url = f"{self.server_config.server}/Items/{item_id}"
            headers = {'Content-Type': 'application/json'}
            update_params = {"api_key": self.server_config.api_key}
            update_proxies = self.proxy_manager.get_proxies(update_url)
            update_response = self.session.post(
                update_url, params=update_params, headers=headers, json=item_data, timeout=20, proxies=update_proxies
            )
            update_response.raise_for_status()
            return True
        except Exception as e:
            logging.error(f"æ›´æ–°åª’ä½“ {item_id} æ ‡ç­¾æ—¶å‡ºé”™: {e}", exc_info=True)
            if 'update_response' in locals() and update_response is not None:
                logging.error(f"å¤±è´¥çš„è¯·æ±‚å“åº”å†…å®¹: {update_response.text}")
            return False

    def _filter_items_by_rule(self, all_items: Dict[str, Dict[str, Any]], rule: MediaTaggerRule) -> Set[str]:
        lib_target = rule.target.libraries
        if lib_target.mode == 'all':
            eligible_ids = set(all_items.keys())
        elif lib_target.mode == 'include':
            eligible_ids = {item_id for item_id, item in all_items.items() if item['LibraryName'] in lib_target.names}
        elif lib_target.mode == 'exclude':
            eligible_ids = {item_id for item_id, item in all_items.items() if item['LibraryName'] not in lib_target.names}
        else: eligible_ids = set()
        genre_target = rule.target.genres
        if genre_target.mode == 'any' or not genre_target.names: return eligible_ids
        final_ids, filter_genres = set(), set(genre_target.names)
        for item_id in eligible_ids:
            item_genres = all_items[item_id]['Genres']
            if genre_target.mode == 'include':
                if genre_target.match == 'or' and item_genres.intersection(filter_genres): final_ids.add(item_id)
                elif genre_target.match == 'and' and filter_genres.issubset(item_genres): final_ids.add(item_id)
            elif genre_target.mode == 'exclude':
                if genre_target.match == 'or' and not item_genres.intersection(filter_genres): final_ids.add(item_id)
                elif genre_target.match == 'and' and not filter_genres.issubset(item_genres): final_ids.add(item_id)
        return final_ids

    def process_single_item(self, item_id: str, task_cat: str):
        ui_logger.info(f"â¡ï¸ å¼€å§‹ä¸ºåª’ä½“é¡¹ (ID: {item_id}) åº”ç”¨æ ‡ç­¾è§„åˆ™...", task_category=task_cat)
        try:
            # 1. ç¡®å®šåª’ä½“é¡¹æ‰€å±çš„åª’ä½“åº“ (ä½¿ç”¨ç‰©ç†è·¯å¾„åŒ¹é…çš„ä¸“ç”¨æ–¹æ³•)
            library = self._get_library_for_item_by_path(item_id)
            if not library:
                ui_logger.warning(f"âš ï¸ æ— æ³•ç¡®å®šåª’ä½“é¡¹ (ID: {item_id}) æ‰€å±çš„åª’ä½“åº“ï¼Œè·³è¿‡æ‰“æ ‡ç­¾ã€‚", task_category=task_cat)
                return
            library_id, library_name = library['Id'], library['Name']
            ui_logger.info(f"   - âœ… å·²ç¡®å®šåª’ä½“é¡¹æ‰€å±åª’ä½“åº“ä¸º: ã€{library_name}ã€‘", task_category=task_cat)

            # 2. è·å–åª’ä½“é¡¹çš„è¯¦ç»†ä¿¡æ¯
            item_data_url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
            item_data_params = {"api_key": self.server_config.api_key, "Fields": "Tags,TagItems,Genres"}
            item_data_proxies = self.proxy_manager.get_proxies(item_data_url)
            item_data_response = self.session.get(item_data_url, params=item_data_params, timeout=15, proxies=item_data_proxies)
            item_data_response.raise_for_status()
            item_data = item_data_response.json()

            # 3. è§„åˆ™åŒ¹é…ä¸æ¼”ç®—
            parsed_item = self._parse_item_data(item_data, library_id, library_name)
            initial_tags = parsed_item['Tags']
            change_set = {"add": set(), "remove": set()}
            enabled_rules = [rule for rule in self.tagger_config.rules if rule.enabled]
            for i, rule in enumerate(enabled_rules):
                matched_ids = self._filter_items_by_rule({item_id: parsed_item}, rule)
                if item_id in matched_ids:
                    ui_logger.info(f"   - âœ… å‘½ä¸­è§„åˆ™ #{i+1}: â€œ{rule.remark}â€", task_category=task_cat)
                    tags_to_add, tags_to_remove = set(rule.action.add_tags), set(rule.action.remove_tags)
                    change_set["add"].update(tags_to_add)
                    change_set["remove"].update(tags_to_remove)
                    conflicts = change_set["add"].intersection(change_set["remove"])
                    if conflicts:
                        change_set["add"].difference_update(conflicts)
                        change_set["remove"].difference_update(conflicts)
            
            # 4. è®¡ç®—å¹¶æ›´æ–°
            final_tags = (initial_tags.union(change_set['add'])).difference(change_set['remove'])
            if final_tags != initial_tags:
                added = sorted(list(final_tags - initial_tags))
                removed = sorted(list(initial_tags - final_tags))
                log_msg = f"   - æ­£åœ¨å¤„ç†ã€{parsed_item['Name']}ã€‘: å½“å‰æ ‡ç­¾ [{', '.join(sorted(list(initial_tags)))}]ï¼Œ"
                if added: log_msg += f" æ–°å¢ [{', '.join(added)}]"
                if removed: log_msg += f" ç§»é™¤ [{', '.join(removed)}]"
                ui_logger.info(log_msg.strip(), task_category=task_cat)
                self._update_item_tags(item_id, list(final_tags))
            else:
                ui_logger.info(f"   - åª’ä½“é¡¹ã€{parsed_item['Name']}ã€‘çš„æ ‡ç­¾å·²ç¬¦åˆæ‰€æœ‰è§„åˆ™ï¼Œæ— éœ€æ›´æ–°ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒ ä¸ºåª’ä½“é¡¹ {item_id} åº”ç”¨æ ‡ç­¾æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat)

    # backend/media_tagger_logic.py (å‡½æ•°æ›¿æ¢)

    def run_tagging_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "åª’ä½“æ ‡ç­¾å™¨-åº”ç”¨è§„åˆ™"
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 1/4] å¼€å§‹é¢„åˆ†æè§„åˆ™å¹¶ç¡®å®šéœ€è¦æ‰«æçš„åª’ä½“åº“...", task_category=task_cat)
        all_libraries = self._get_libraries()
        if not all_libraries:
            ui_logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•åª’ä½“åº“ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return
        all_lib_map_name_to_id = {lib['Name']: lib["Id"] for lib in all_libraries}
        all_lib_ids = set(all_lib_map_name_to_id.values())
        final_required_ids = set()
        enabled_rules = [rule for rule in self.tagger_config.rules if rule.enabled]
        if not enabled_rules:
            ui_logger.info("âœ… æœªå¯ç”¨ä»»ä½•è§„åˆ™ï¼Œæ— éœ€æ‰«æåª’ä½“é¡¹ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚", task_category=task_cat)
            return
        for rule in enabled_rules:
            lib_target = rule.target.libraries
            if lib_target.mode == 'all':
                final_required_ids = all_lib_ids
                break
            elif lib_target.mode == 'include':
                rule_ids = {all_lib_map_name_to_id[name] for name in lib_target.names if name in all_lib_map_name_to_id}
                final_required_ids.update(rule_ids)
            elif lib_target.mode == 'exclude':
                excluded_ids = {all_lib_map_name_to_id[name] for name in lib_target.names if name in all_lib_map_name_to_id}
                rule_ids = all_lib_ids - excluded_ids
                final_required_ids.update(rule_ids)
        if not final_required_ids:
            ui_logger.info("âœ… æ ¹æ®æ‰€æœ‰è§„åˆ™è®¡ç®—åï¼Œæ²¡æœ‰éœ€è¦æ‰«æçš„åª’ä½“åº“ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚", task_category=task_cat)
            return
        all_items = self._get_media_from_libraries(list(final_required_ids), task_cat)
        if not all_items: return
        if cancellation_event.is_set():
            ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨æ•°æ®å‡†å¤‡é˜¶æ®µè¢«å–æ¶ˆã€‚", task_category=task_cat)
            return
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 2/4] å¼€å§‹æ ¹æ®è§„åˆ™è¿›è¡Œç¦»çº¿æ¼”ç®—...", task_category=task_cat)
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåˆå§‹åŒ– change_set ä»¥å­˜å‚¨å‘½ä¸­è§„åˆ™çš„è¯¦ç»†ä¿¡æ¯ ---
        change_set: Dict[str, Dict[str, Any]] = {}
        # --- ä¿®æ”¹ç»“æŸ ---

        for i, rule in enumerate(enabled_rules):
            ui_logger.info(f"   - [è§„åˆ™ {i+1}/{len(enabled_rules)}] æ­£åœ¨å¤„ç†: â€œ{rule.remark}â€", task_category=task_cat)
            matched_ids = self._filter_items_by_rule(all_items, rule)
            ui_logger.info(f"     - ğŸ” åŒ¹é…åˆ° {len(matched_ids)} ä¸ªåª’ä½“é¡¹ã€‚", task_category=task_cat)
            tags_to_add, tags_to_remove = set(rule.action.add_tags), set(rule.action.remove_tags)
            for item_id in matched_ids:
                if item_id not in change_set:
                    # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ‰©å±• change_set ç»“æ„ ---
                    change_set[item_id] = {"add": set(), "remove": set(), "matched_rules": []}
                
                change_set[item_id]["add"].update(tags_to_add)
                change_set[item_id]["remove"].update(tags_to_remove)
                # --- æ–°å¢ï¼šè®°å½•å‘½ä¸­çš„è§„åˆ™å¤‡æ³¨ ---
                change_set[item_id]["matched_rules"].append(rule.remark)
                # --- æ–°å¢ç»“æŸ ---

                conflicts = change_set[item_id]["add"].intersection(change_set[item_id]["remove"])
                if conflicts:
                    change_set[item_id]["add"].difference_update(conflicts)
                    change_set[item_id]["remove"].difference_update(conflicts)

        ui_logger.info("âœ… [æ­¥éª¤ 2/4] ç¦»çº¿æ¼”ç®—å®Œæˆã€‚", task_category=task_cat)
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 3/4] å¼€å§‹è®¡ç®—æœ€ç»ˆæ ‡ç­¾å¹¶è¯†åˆ«å˜æ›´...", task_category=task_cat)
        items_to_update = []
        for item_id, changes in change_set.items():
            initial_tags = all_items[item_id]['Tags']
            final_tags = (initial_tags.union(changes['add'])).difference(changes['remove'])
            if final_tags != initial_tags:
                items_to_update.append({
                    'id': item_id, 'name': all_items[item_id]['Name'],
                    'initial_tags': initial_tags, 'final_tags': final_tags,
                    # --- æ–°å¢ï¼šå°†å‘½ä¸­çš„è§„åˆ™å’Œç±»å‹ä¿¡æ¯ä¼ é€’ä¸‹å» ---
                    'matched_rules': changes['matched_rules'],
                    'genres': all_items[item_id]['Genres']
                    # --- æ–°å¢ç»“æŸ ---
                })
        if not items_to_update:
            ui_logger.info("âœ… [æ­¥éª¤ 3/4] è®¡ç®—å®Œæˆï¼Œæœªå‘ç°ä»»ä½•éœ€è¦å˜æ›´æ ‡ç­¾çš„åª’ä½“é¡¹ã€‚", task_category=task_cat)
            ui_logger.info("ğŸ‰ æ‰€æœ‰åª’ä½“çš„æ ‡ç­¾å‡ç¬¦åˆè§„åˆ™ï¼Œä»»åŠ¡å®Œæˆï¼", task_category=task_cat)
            return
        ui_logger.info(f"âœ… [æ­¥éª¤ 3/4] è®¡ç®—å®Œæˆï¼Œå…±å‘ç° {len(items_to_update)} ä¸ªåª’ä½“é¡¹éœ€è¦æ›´æ–°æ ‡ç­¾ã€‚", task_category=task_cat)
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 4/4] å¼€å§‹å°†å˜æ›´åº”ç”¨åˆ° Emby...", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, len(items_to_update))
        processed_count, success_count = 0, 0
        for item_data in items_to_update:
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨åº”ç”¨å˜æ›´é˜¶æ®µè¢«å–æ¶ˆã€‚", task_category=task_cat)
                return
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ„å»ºæ›´è¯¦ç»†çš„æ—¥å¿—è¾“å‡º ---
            item_id, item_name = item_data['id'], item_data['name']
            initial_tags, final_tags = item_data['initial_tags'], item_data['final_tags']
            genres_str = ', '.join(sorted(list(item_data['genres']))) if item_data['genres'] else 'æ— '
            
            ui_logger.info(f"   - æ­£åœ¨å¤„ç†ã€{item_name}ã€‘", task_category=task_cat)
            ui_logger.info(f"     - ç±»å‹: [{genres_str}]", task_category=task_cat)
            for rule_remark in item_data['matched_rules']:
                ui_logger.info(f"     - å‘½ä¸­è§„åˆ™: â€œ{rule_remark}â€", task_category=task_cat)

            added = sorted(list(final_tags - initial_tags))
            removed = sorted(list(initial_tags - final_tags))
            
            change_log = ""
            if added: change_log += f" æ–°å¢ [{', '.join(added)}]"
            if removed: change_log += f" ç§»é™¤ [{', '.join(removed)}]"
            
            if change_log:
                ui_logger.info(f"     - æ ‡ç­¾å˜æ›´: å½“å‰ [{', '.join(sorted(list(initial_tags)))}] â†’{change_log.strip()}", task_category=task_cat)
            # --- ä¿®æ”¹ç»“æŸ ---

            if self._update_item_tags(item_id, list(final_tags)):
                success_count += 1
            processed_count += 1
            task_manager.update_task_progress(task_id, processed_count, len(items_to_update))
        ui_logger.info(f"âœ… [æ­¥éª¤ 4/4] åº”ç”¨å˜æ›´å®Œæˆã€‚", task_category=task_cat)
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼å…±å¤„ç† {len(items_to_update)} ä¸ªåª’ä½“é¡¹ï¼ŒæˆåŠŸæ›´æ–° {success_count} ä¸ªã€‚", task_category=task_cat)

    def clear_all_tags_task(self, scope: Dict, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¸…ç©ºæ‰€æœ‰æ ‡ç­¾"
        ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 1/2] å¼€å§‹æ ¹æ®èŒƒå›´è·å–åª’ä½“é¡¹...", task_category=task_cat)
        all_libraries = self._get_libraries()
        all_lib_map_name_to_id = {lib['Name']: lib["Id"] for lib in all_libraries}
        if scope.get('mode') == 'all':
            target_lib_ids = list(all_lib_map_name_to_id.values())
        else:
            target_lib_ids = [all_lib_map_name_to_id[name] for name in scope.get('library_names', []) if name in all_lib_map_name_to_id]
        if not target_lib_ids:
            ui_logger.warning("âš ï¸ åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“åº“ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return
        all_items = self._get_media_from_libraries(target_lib_ids, task_cat)
        if not all_items: return
        items_to_clear = [item_id for item_id, item_data in all_items.items() if item_data.get('Tags')]
        if not items_to_clear:
            ui_logger.info("âœ… èŒƒå›´å†…æ‰€æœ‰åª’ä½“é¡¹éƒ½æ²¡æœ‰æ ‡ç­¾ï¼Œæ— éœ€æ“ä½œã€‚", task_category=task_cat)
            return
        ui_logger.info(f"ğŸ” [æ­¥éª¤ 2/2] å‘ç° {len(items_to_clear)} ä¸ªåª’ä½“é¡¹éœ€è¦æ¸…ç©ºæ ‡ç­¾ï¼Œå¼€å§‹å¤„ç†...", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, len(items_to_clear))
        processed_count, success_count = 0, 0
        for item_id in items_to_clear:
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«å–æ¶ˆã€‚", task_category=task_cat)
                return
            item_name = all_items[item_id].get('Name', f"ID {item_id}")
            current_tags = all_items[item_id].get('Tags', set())
            ui_logger.info(f"   - æ­£åœ¨å¤„ç†ã€{item_name}ã€‘: å½“å‰æ ‡ç­¾ [{', '.join(sorted(list(current_tags)))}]ï¼Œå°†æ¸…ç©ºæ‰€æœ‰æ ‡ç­¾...", task_category=task_cat)
            if self._update_item_tags(item_id, []):
                success_count += 1
            processed_count += 1
            task_manager.update_task_progress(task_id, processed_count, len(items_to_clear))
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼å…±å¤„ç† {processed_count} ä¸ªåª’ä½“é¡¹ï¼ŒæˆåŠŸæ¸…ç©º {success_count} ä¸ªã€‚", task_category=task_cat)

    def remove_specific_tags_task(self, tags_to_remove: List[str], scope: Dict, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "ç§»é™¤æŒ‡å®šæ ‡ç­¾"
        tags_to_remove_set = set(tags_to_remove)
        ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 1/2] å¼€å§‹æ ¹æ®èŒƒå›´è·å–åª’ä½“é¡¹ï¼Œå‡†å¤‡ç§»é™¤æ ‡ç­¾: {tags_to_remove}", task_category=task_cat)
        all_libraries = self._get_libraries()
        all_lib_map_name_to_id = {lib['Name']: lib["Id"] for lib in all_libraries}
        if scope.get('mode') == 'all':
            target_lib_ids = list(all_lib_map_name_to_id.values())
        else:
            target_lib_ids = [all_lib_map_name_to_id[name] for name in scope.get('library_names', []) if name in all_lib_map_name_to_id]
        if not target_lib_ids:
            ui_logger.warning("âš ï¸ åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“åº“ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return
        all_items = self._get_media_from_libraries(target_lib_ids, task_cat)
        if not all_items: return
        items_to_process = [
            item_id for item_id, item_data in all_items.items() 
            if item_data.get('Tags', set()).intersection(tags_to_remove_set)
        ]
        if not items_to_process:
            ui_logger.info(f"âœ… èŒƒå›´å†…æœªåœ¨ä»»ä½•åª’ä½“é¡¹ä¸­æ‰¾åˆ°æŒ‡å®šçš„æ ‡ç­¾ï¼Œæ— éœ€æ“ä½œã€‚", task_category=task_cat)
            return
        ui_logger.info(f"ğŸ” [æ­¥éª¤ 2/2] å‘ç° {len(items_to_process)} ä¸ªåª’ä½“é¡¹åŒ…å«æŒ‡å®šæ ‡ç­¾ï¼Œå¼€å§‹å¤„ç†...", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, len(items_to_process))
        processed_count, success_count = 0, 0
        for item_id in items_to_process:
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«å–æ¶ˆã€‚", task_category=task_cat)
                return
            item_name = all_items[item_id].get('Name', f"ID {item_id}")
            current_tags = all_items[item_id].get('Tags', set())
            removed = sorted(list(current_tags.intersection(tags_to_remove_set)))
            new_tags = list(current_tags - tags_to_remove_set)
            ui_logger.info(f"   - æ­£åœ¨å¤„ç†ã€{item_name}ã€‘: å½“å‰æ ‡ç­¾ [{', '.join(sorted(list(current_tags)))}]ï¼Œå°†ç§»é™¤ [{', '.join(removed)}]...", task_category=task_cat)
            if self._update_item_tags(item_id, new_tags):
                success_count += 1
            processed_count += 1
            task_manager.update_task_progress(task_id, processed_count, len(items_to_process))
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼å…±å¤„ç† {processed_count} ä¸ªåª’ä½“é¡¹ï¼ŒæˆåŠŸæ›´æ–° {success_count} ä¸ªã€‚", task_category=task_cat)