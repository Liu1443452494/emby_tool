# backend/douban_metadata_refresher_logic.py (å®Œæ•´æ–‡ä»¶è¦†ç›–)

import logging
import threading
import time
import requests
import json
import os
import shutil
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from filelock import FileLock, Timeout

from log_manager import ui_logger
from models import AppConfig, DoubanMetadataRefresherConfig, ScheduledTasksTargetScope
from task_manager import TaskManager
from media_selector import MediaSelector
from douban_manager import DOUBAN_CACHE_FILE, _parse_folder_name
from actor_localizer_logic import ActorLocalizerLogic
from actor_role_mapper_logic import ActorRoleMapperLogic

class DoubanMetadataRefresherLogic:
    def __init__(self, app_config: AppConfig):
        self.app_config = app_config
        self.server_config = app_config.server_config
        self.douban_config = app_config.douban_config
        self.base_url = self.server_config.server
        self.api_key = self.server_config.api_key
        self.user_id = self.server_config.user_id
        self.params = {"api_key": self.api_key}
        self.session = requests.Session()

    def _get_item_details(self, item_id: str, fields: str = "ProviderIds,Name,Type,Path,Locked") -> Optional[Dict]:
        try:
            url = f"{self.base_url}/Users/{self.user_id}/Items/{item_id}"
            params = {**self.params, "Fields": fields}
            response = self.session.get(url, params=params, timeout=15)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logging.error(f"ã€è±†ç“£å…ƒæ•°æ®åˆ·æ–°ã€‘è·å– Emby åª’ä½“è¯¦æƒ… (ID: {item_id}) å¤±è´¥: {e}")
            return None

    def _update_item_provider_ids(self, item_id: str, new_provider_ids: Dict) -> bool:
        try:
            # è·å–å®Œæ•´é¡¹ç›®ä¿¡æ¯ç”¨äºæ›´æ–°
            item_details_full = self._get_item_details(item_id, fields="")
            if not item_details_full:
                raise Exception("è·å–é¡¹ç›®å®Œæ•´è¯¦æƒ…å¤±è´¥")
            
            item_details_full["ProviderIds"] = new_provider_ids
            
            update_url = f"{self.base_url}/Items/{item_id}"
            headers = {'Content-Type': 'application/json'}
            response = self.session.post(update_url, params=self.params, json=item_details_full, headers=headers, timeout=20)
            response.raise_for_status()
            return True
        except Exception as e:
            logging.error(f"ã€è±†ç“£å…ƒæ•°æ®åˆ·æ–°ã€‘æ›´æ–°åª’ä½“ (ID: {item_id}) çš„ ProviderIds æ—¶å¤±è´¥: {e}")
            return False
        
    def _unlock_item(self, item_id: str, task_cat: str) -> bool:
        """è§£é”åª’ä½“é¡¹ï¼Œä»¥ä¾¿å¯ä»¥åˆ·æ–°å…ƒæ•°æ®"""
        try:
            # è¯·æ±‚Lockedå­—æ®µå³å¯ï¼Œå‡å°‘æ•°æ®é‡
            item_details = self._get_item_details(item_id, fields="Locked")
            if not item_details:
                return False
            
            if not item_details.get("Locked", False):
                ui_logger.debug(f"     - [è§£é”] åª’ä½“é¡¹ (ID: {item_id}) æœªè¢«é”å®šï¼Œæ— éœ€æ“ä½œã€‚", task_category=task_cat)
                return True

            # ä»…ä¿®æ”¹Lockedå­—æ®µï¼Œé¿å…åŠ¨åˆ°å…¶ä»–æ•°æ®
            item_details["Locked"] = False
            
            update_url = f"{self.base_url}/Items/{item_id}"
            headers = {'Content-Type': 'application/json'}
            response = self.session.post(update_url, params=self.params, json=item_details, headers=headers, timeout=20)
            response.raise_for_status()
            ui_logger.info(f"     - [è§£é”] æˆåŠŸå‘é€è§£é”è¯·æ±‚ã€‚", task_category=task_cat)
            return True
        except Exception as e:
            ui_logger.error(f"     - [è§£é”] âŒ è§£é”åª’ä½“é¡¹ (ID: {item_id}) æ—¶å¤±è´¥: {e}", task_category=task_cat)
            return False

    def _trigger_emby_refresh(self, item_id: str, task_cat: str) -> bool:
        try:
            if not self._unlock_item(item_id, task_cat):
                ui_logger.warning(f"     - âš ï¸ è§£é”åª’ä½“é¡¹ (ID: {item_id}) å¤±è´¥ï¼Œä½†ä»å°†ç»§ç»­å°è¯•åˆ·æ–°...", task_category=task_cat)

            url = f"{self.base_url}/Items/{item_id}/Refresh"
            params = {
                **self.params,
                "Recursive": "true",
                "MetadataRefreshMode": "FullRefresh",
                "ImageRefreshMode": "Default",
                "ReplaceAllMetadata": "true",
                "ReplaceAllImages": "false"
            }
            response = self.session.post(url, params=params, timeout=30)
            response.raise_for_status()
            
            if response.status_code == 204:
                ui_logger.info(f"       - âœ… å·²æˆåŠŸå‘ Emby å‘é€å…ƒæ•°æ®åˆ·æ–°æŒ‡ä»¤ (ä¸æ›¿æ¢å›¾ç‰‡)ã€‚", task_category=task_cat)
                return True
            else:
                ui_logger.warning(f"       - âš ï¸ Emby æœåŠ¡å™¨è¿”å›å¼‚å¸¸çŠ¶æ€ç  {response.status_code}ï¼Œåˆ·æ–°å¯èƒ½æœªæˆåŠŸã€‚", task_category=task_cat)
                return False
        except Exception as e:
            ui_logger.error(f"       - âŒ å‘ Emby å‘é€å…ƒæ•°æ®åˆ·æ–°æŒ‡ä»¤æ—¶å¤±è´¥: {e}", task_category=task_cat)
            return False

    def _compare_actor_lists(self, old_actors: List[Dict], new_actors: List[Dict]) -> bool:
        """æ¯”è¾ƒæ–°æ—§æ¼”å‘˜åˆ—è¡¨æ˜¯å¦æœ‰å®è´¨æ€§å˜åŒ–ï¼Œè¿”å›Trueè¡¨ç¤ºæœ‰å˜åŒ–"""
        if len(old_actors) != len(new_actors):
            return True

        old_map = {actor.get('name'): actor.get('character', '') for actor in old_actors if actor.get('name')}
        new_map = {actor.get('name'): actor.get('character', '') for actor in new_actors if actor.get('name')}

        if old_map.keys() != new_map.keys():
            return True

        for name, old_char in old_map.items():
            if old_char != new_map.get(name, ''):
                return True
        
        return False

    def run_refresh_task(self, scope: ScheduledTasksTargetScope, config: DoubanMetadataRefresherConfig, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "è±†ç“£å…ƒæ•°æ®åˆ·æ–°"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼ŒèŒƒå›´: {scope.mode}", task_category=task_cat)

        # é˜¶æ®µä¸€ï¼šå‡†å¤‡ä¸è¿‡æ»¤
        ui_logger.info("â¡ï¸ [é˜¶æ®µ 1/5] æ­£åœ¨è·å–å¹¶è¿‡æ»¤åª’ä½“é¡¹...", task_category=task_cat)
        selector = MediaSelector(self.app_config)
        all_item_ids = selector.get_item_ids(scope)
        if not all_item_ids:
            ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
            return

        items_to_process = []
        skipped_count = 0
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(self._get_item_details, item_id): item_id for item_id in all_item_ids}
            for future in as_completed(future_to_id):
                if cancellation_event.is_set(): return
                try:
                    details = future.result()
                    if details:
                        provider_ids = details.get("ProviderIds", {})
                        # å…¼å®¹å¤§å°å†™
                        provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                        if 'douban' in provider_ids_lower and provider_ids_lower['douban']:
                            items_to_process.append(details)
                        else:
                            skipped_count += 1
                            logging.info(f"ã€è±†ç“£å…ƒæ•°æ®åˆ·æ–°-è·³è¿‡ã€‘åª’ä½“ã€Š{details.get('Name')}ã€‹å› ç¼ºå°‘è±†ç“£IDè€Œè¢«è·³è¿‡ã€‚")
                    else:
                        item_id = future_to_id[future]
                        ui_logger.warning(f"   - âš ï¸ è·å–åª’ä½“é¡¹ (ID: {item_id}) è¯¦æƒ…å¤±è´¥ï¼Œå·²è·³è¿‡ã€‚")
                        skipped_count += 1
                except Exception as e:
                    item_id = future_to_id[future]
                    ui_logger.error(f"   - âŒ å¤„ç†åª’ä½“é¡¹ (ID: {item_id}) æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}ï¼Œå·²è·³è¿‡ã€‚")
                    skipped_count += 1
        
        if not items_to_process:
            ui_logger.warning(f"âš ï¸ åœ¨æŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰åª’ä½“é¡¹å‡ç¼ºå°‘è±†ç“£IDæˆ–è·å–å¤±è´¥ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚å…±è·³è¿‡ {skipped_count} é¡¹ã€‚", task_category=task_cat)
            return
        
        total_items = len(items_to_process)
        ui_logger.info(f"âœ… è¿‡æ»¤å®Œæˆï¼Œå…± {total_items} ä¸ªé¡¹ç›®åŒ…å«è±†ç“£IDï¼Œå°†å¼€å§‹å¤„ç†ã€‚(å·²è·³è¿‡ {skipped_count} ä¸ªæ— IDæˆ–è·å–å¤±è´¥çš„é¡¹ç›®)", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, total_items)

        # é˜¶æ®µäºŒï¼šæ ¸å¿ƒåˆ·æ–°å¾ªç¯
        ui_logger.info("â¡ï¸ [é˜¶æ®µ 2/5] å¼€å§‹é€ä¸€åˆ·æ–°è±†ç“£å…ƒæ•°æ®...", task_category=task_cat)
        successful_items = []
        old_actor_data_map = {}
        douban_data_root = self.douban_config.directory

        for i, item in enumerate(items_to_process):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                break
            
            item_id = item['Id']
            item_name = item['Name']
            item_type = item['Type']
            provider_ids = item.get("ProviderIds", {})
            douban_id = next((v for k, v in provider_ids.items() if k.lower() == 'douban'), None)
            
            ui_logger.info(f"  - ({i+1}/{total_items}) æ­£åœ¨å¤„ç†ã€Š{item_name}ã€‹ (è±†ç“£ID: {douban_id})...", task_category=task_cat)
            task_manager.update_task_progress(task_id, i + 1, total_items)

            try:
                # 1. æ‰¾åˆ°å¹¶å¤‡ä»½/åˆ é™¤æœ¬åœ°æ•°æ®
                sub_dir = 'douban-movies' if item_type == 'Movie' else 'douban-tv'
                target_dir = os.path.join(douban_data_root, sub_dir)
                found_folder = None
                if os.path.isdir(target_dir):
                    for folder_name in os.listdir(target_dir):
                        parsed_db_id, _ = _parse_folder_name(folder_name)
                        if parsed_db_id == douban_id:
                            found_folder = os.path.join(target_dir, folder_name)
                            break
                
                if not found_folder:
                    ui_logger.warning(f"     - [è·³è¿‡] æœªåœ¨æœ¬åœ°æ‰¾åˆ°ä¸è±†ç“£ID {douban_id} åŒ¹é…çš„å…ƒæ•°æ®æ–‡ä»¶å¤¹ã€‚", task_category=task_cat)
                    continue

                if config.enable_post_refresh_actions:
                    json_filename = 'all.json' if item_type == 'Movie' else 'series.json'
                    json_path = os.path.join(found_folder, json_filename)
                    if os.path.exists(json_path):
                        with open(json_path, 'r', encoding='utf-8') as f:
                            old_data = json.load(f)
                        old_actor_data_map[douban_id] = old_data.get('actors', [])
                        ui_logger.info(f"     - [å¤‡ä»½] å·²ä¸ºåç»­æ¯”å¯¹å¤‡ä»½æ—§çš„æ¼”å‘˜æ•°æ®ã€‚", task_category=task_cat)

                shutil.rmtree(found_folder)
                ui_logger.info(f"     - [æ¸…ç†] å·²æˆåŠŸåˆ é™¤æœ¬åœ°æ—§å…ƒæ•°æ®æ–‡ä»¶å¤¹: {os.path.basename(found_folder)}", task_category=task_cat)

                # 2. è§¦å‘Embyåˆ·æ–°
                provider_ids_copy = {k: v for k, v in provider_ids.items() if k.lower() != 'douban'}
                if not self._update_item_provider_ids(item_id, provider_ids_copy):
                    raise Exception("æ“¦é™¤è±†ç“£IDå¤±è´¥")
                
                ui_logger.info(f"     - â±ï¸ [è§¦å‘] å·²æ“¦é™¤è±†ç“£IDï¼Œç­‰å¾… {config.delete_id_wait_seconds} ç§’...", task_category=task_cat)
                time.sleep(config.delete_id_wait_seconds)

                # ç»Ÿä¸€ä½¿ç”¨ 'Douban' ä½œä¸ºé”®å†™å›
                provider_ids_copy['Douban'] = douban_id
                if not self._update_item_provider_ids(item_id, provider_ids_copy):
                    raise Exception("å†™å›è±†ç“£IDå¤±è´¥")
                
                ui_logger.info(f"     - â±ï¸ [è§¦å‘] å·²å†™å›è±†ç“£IDï¼Œç­‰å¾… {config.readd_id_wait_seconds} ç§’è®©æ’ä»¶ä¸‹è½½æ–°æ•°æ®...", task_category=task_cat)
                time.sleep(config.readd_id_wait_seconds)

                # 3. éªŒè¯
                new_folder_found = False
                if os.path.isdir(target_dir):
                    for folder_name in os.listdir(target_dir):
                        parsed_db_id, _ = _parse_folder_name(folder_name)
                        if parsed_db_id == douban_id:
                            new_folder_found = True
                            break
                
                if new_folder_found:
                    ui_logger.info(f"     - âœ… [éªŒè¯] æˆåŠŸï¼æœ¬åœ°å·²ç”Ÿæˆæ–°çš„å…ƒæ•°æ®æ–‡ä»¶å¤¹ã€‚", task_category=task_cat)
                    successful_items.append(item)
                else:
                    raise Exception("éªŒè¯å¤±è´¥ï¼Œæœ¬åœ°æœªé‡æ–°ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶å¤¹")

            except Exception as e:
                ui_logger.error(f"     - âŒ å¤„ç†ã€Š{item_name}ã€‹æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat)
            
            if i < total_items - 1:
                ui_logger.info(f"     - â±ï¸ [é—´éš”] ç­‰å¾… {config.item_interval_seconds} ç§’...", task_category=task_cat)
                time.sleep(config.item_interval_seconds)

        # é˜¶æ®µä¸‰ï¼šæ‰¹é‡æ›´æ–°ä¸»ç¼“å­˜
        ui_logger.info(f"â¡ï¸ [é˜¶æ®µ 3/5] å¼€å§‹æ‰¹é‡æ›´æ–°ä¸»ç¼“å­˜æ–‡ä»¶ `douban_data.json`...", task_category=task_cat)
        if successful_items:
            try:
                lock_path = DOUBAN_CACHE_FILE + ".lock"
                with FileLock(lock_path, timeout=10):
                    if os.path.exists(DOUBAN_CACHE_FILE):
                        with open(DOUBAN_CACHE_FILE, 'r', encoding='utf-8') as f:
                            douban_map = json.load(f)
                    else:
                        douban_map = {}
                    
                    updated_count = 0
                    for item in successful_items:
                        douban_id = next((v for k, v in item.get("ProviderIds", {}).items() if k.lower() == 'douban'), None)
                        if not douban_id: continue

                        sub_dir = 'douban-movies' if item['Type'] == 'Movie' else 'douban-tv'
                        target_dir = os.path.join(douban_data_root, sub_dir)
                        found_folder = None
                        if not os.path.isdir(target_dir): continue
                        for folder_name in os.listdir(target_dir):
                            parsed_db_id, _ = _parse_folder_name(folder_name)
                            if parsed_db_id == douban_id:
                                found_folder = os.path.join(target_dir, folder_name)
                                break
                        
                        if not found_folder: continue

                        json_filename = 'all.json' if item['Type'] == 'Movie' else 'series.json'
                        json_path = os.path.join(found_folder, json_filename)
                        if not os.path.isfile(json_path): continue

                        with open(json_path, 'r', encoding='utf-8') as f:
                            new_data = json.load(f)
                        
                        item_data = {
                            'type': item['Type'],
                            'title': new_data.get('title', 'N/A'),
                            'year': new_data.get('year', ''),
                            'genres': new_data.get('genres', []),
                            'intro': new_data.get('intro', ''),
                            'pic': new_data.get('pic', {}),
                            'actors': [
                                {
                                    'id': actor.get('id'), 'name': actor.get('name'),
                                    'latin_name': actor.get('latin_name'), 'character': actor.get('character'),
                                    'avatar': actor.get('avatar', {})
                                } for actor in new_data.get('actors', [])
                            ],
                            'imdb_id': _parse_folder_name(os.path.basename(found_folder))[1],
                            'countries': new_data.get('countries', [])
                        }
                        
                        extra_fields = self.douban_config.extra_fields
                        if 'rating' in extra_fields: item_data['rating'] = new_data.get('rating', {}).get('value')
                        if 'pubdate' in extra_fields: item_data['pubdate'] = new_data.get('pubdate', [])
                        if 'card_subtitle' in extra_fields: item_data['card_subtitle'] = new_data.get('card_subtitle', '')
                        if 'languages' in extra_fields: item_data['languages'] = new_data.get('languages', [])
                        if 'durations' in extra_fields and item['Type'] == 'Movie': item_data['durations'] = new_data.get('durations', [])

                        douban_map[douban_id] = item_data
                        updated_count += 1

                    with open(DOUBAN_CACHE_FILE, 'w', encoding='utf-8') as f:
                        json.dump(douban_map, f, ensure_ascii=False, indent=4)
                    ui_logger.info(f"âœ… ä¸»ç¼“å­˜æ›´æ–°å®Œæ¯•ï¼Œå…±è¦†ç›– {updated_count} æ¡è®°å½•ã€‚", task_category=task_cat)

            except Timeout:
                ui_logger.error("âŒ æ›´æ–°ä¸»ç¼“å­˜å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ã€‚", task_category=task_cat)
            except Exception as e:
                ui_logger.error(f"âŒ æ›´æ–°ä¸»ç¼“å­˜æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat)
        else:
            ui_logger.info("æ²¡æœ‰æˆåŠŸåˆ·æ–°çš„é¡¹ç›®ï¼Œè·³è¿‡ä¸»ç¼“å­˜æ›´æ–°ã€‚", task_category=task_cat)

        # é˜¶æ®µå››ï¼šåç»­è‡ªåŠ¨åŒ–
        if not config.enable_post_refresh_actions:
            ui_logger.info("â¡ï¸ [é˜¶æ®µ 4/5 & 5/5] åç»­è‡ªåŠ¨åŒ–æµç¨‹å·²ç¦ç”¨ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
            return

        ui_logger.info("â¡ï¸ [é˜¶æ®µ 4/5] åç»­è‡ªåŠ¨åŒ–å·²å¯ç”¨ï¼Œå¼€å§‹æ¯”å¯¹å…ƒæ•°æ®å˜æ›´...", task_category=task_cat)
        items_to_deep_process = []
        try:
            with open(DOUBAN_CACHE_FILE, 'r', encoding='utf-8') as f:
                current_douban_map = json.load(f)
            
            for item in successful_items:
                douban_id = next((v for k, v in item.get("ProviderIds", {}).items() if k.lower() == 'douban'), None)
                if not douban_id: continue

                old_actors = old_actor_data_map.get(douban_id, [])
                new_item_data = current_douban_map.get(douban_id)
                if not new_item_data: continue
                new_actors = new_item_data.get('actors', [])

                if self._compare_actor_lists(old_actors, new_actors):
                    ui_logger.info(f"   - [æ£€æµ‹åˆ°å˜æ›´] ã€Š{item['Name']}ã€‹çš„æ¼”å‘˜æˆ–è§’è‰²ä¿¡æ¯å·²æ›´æ–°ã€‚", task_category=task_cat)
                    items_to_deep_process.append(item)
                else:
                    ui_logger.info(f"   - [æ— å˜æ›´] ã€Š{item['Name']}ã€‹çš„æ¼”å‘˜ä¿¡æ¯æœªå‘ç”Ÿå˜åŒ–ï¼Œè·³è¿‡æ·±åº¦å¤„ç†ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒ æ¯”å¯¹å…ƒæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå°†è·³è¿‡åç»­è‡ªåŠ¨åŒ–æµç¨‹: {e}", task_category=task_cat)
            items_to_deep_process = []

        if not items_to_deep_process:
            ui_logger.info("â¡ï¸ [é˜¶æ®µ 5/5] æ²¡æœ‰æ£€æµ‹åˆ°å…ƒæ•°æ®æœ‰å˜æ›´çš„é¡¹ç›®ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
            return

        ui_logger.info(f"â¡ï¸ [é˜¶æ®µ 5/5] å¼€å§‹å¯¹ {len(items_to_deep_process)} ä¸ªå˜æ›´é¡¹ç›®æ‰§è¡Œæ·±åº¦å¤„ç†...", task_category=task_cat)
        for i, item in enumerate(items_to_deep_process):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨æ·±åº¦å¤„ç†é˜¶æ®µè¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                break
            
            item_id = item['Id']
            item_name = item['Name']
            ui_logger.info(f"  - ({i+1}/{len(items_to_deep_process)}) æ­£åœ¨æ·±åº¦å¤„ç†ã€Š{item_name}ã€‹...", task_category=task_cat)
            
            # 1. è§¦å‘Embyåˆ·æ–°
            self._trigger_emby_refresh(item_id, task_cat)
            ui_logger.info(f"     - â±ï¸ ç­‰å¾… {config.emby_refresh_wait_seconds} ç§’è®© Emby åº”ç”¨å…ƒæ•°æ®...", task_category=task_cat)
            time.sleep(config.emby_refresh_wait_seconds)

            # 2. æ¼”å‘˜ä¸­æ–‡åŒ–
            try:
                localizer_logic = ActorLocalizerLogic(self.app_config)
                localizer_logic._process_single_item_for_localization(item_id, self.app_config.actor_localizer_config, task_cat)
            except Exception as e:
                ui_logger.error(f"     - âŒ æ¼”å‘˜ä¸­æ–‡åŒ–æ­¥éª¤å¤±è´¥: {e}", task_category=task_cat)

            # 3. è§’è‰²æ˜ å°„æ›´æ–°
            try:
                role_mapper_logic = ActorRoleMapperLogic(self.app_config)
                role_mapper_logic.generate_map_for_single_item(item_id, task_category=task_cat, overwrite=True)
            except Exception as e:
                ui_logger.error(f"     - âŒ è§’è‰²æ˜ å°„æ›´æ–°æ­¥éª¤å¤±è´¥: {e}", task_category=task_cat)

        ui_logger.info("ğŸ‰ æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼", task_category=task_cat)


    def run_metadata_fix_task(self, scope: ScheduledTasksTargetScope, config: DoubanMetadataRefresherConfig, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "å…ƒæ•°æ®ä¿®å¤"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼ŒèŒƒå›´: {scope.mode}", task_category=task_cat)

        # é˜¶æ®µä¸€ï¼šå‡†å¤‡ä¸å¼ºåˆ¶è¿‡æ»¤
        ui_logger.info("â¡ï¸ [é˜¶æ®µ 1/3] æ­£åœ¨è·å–å¹¶å¼ºåˆ¶è¿‡æ»¤åª’ä½“é¡¹ (å¿…é¡»åŒ…å«è±†ç“£ID)...", task_category=task_cat)
        selector = MediaSelector(self.app_config)
        all_item_ids = selector.get_item_ids(scope)
        if not all_item_ids:
            ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
            return

        items_to_process = []
        skipped_count = 0
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(self._get_item_details, item_id): item_id for item_id in all_item_ids}
            for future in as_completed(future_to_id):
                if cancellation_event.is_set(): return
                try:
                    details = future.result()
                    if details:
                        provider_ids = details.get("ProviderIds", {})
                        provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                        if 'douban' in provider_ids_lower and provider_ids_lower['douban']:
                            items_to_process.append(details)
                        else:
                            skipped_count += 1
                            logging.info(f"ã€{task_cat}-è·³è¿‡ã€‘åª’ä½“ã€Š{details.get('Name')}ã€‹å› ç¼ºå°‘è±†ç“£IDè€Œè¢«è·³è¿‡ã€‚")
                    else:
                        skipped_count += 1
                except Exception:
                    skipped_count += 1
        
        if not items_to_process:
            ui_logger.warning(f"âš ï¸ åœ¨æŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰åª’ä½“é¡¹å‡ç¼ºå°‘è±†ç“£IDæˆ–è·å–å¤±è´¥ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚å…±è·³è¿‡ {skipped_count} é¡¹ã€‚", task_category=task_cat)
            return
        
        total_items = len(items_to_process)
        ui_logger.info(f"âœ… è¿‡æ»¤å®Œæˆï¼Œå…± {total_items} ä¸ªé¡¹ç›®å°†æ‰§è¡Œä¿®å¤ã€‚(å·²è·³è¿‡ {skipped_count} ä¸ªæ— IDæˆ–è·å–å¤±è´¥çš„é¡¹ç›®)", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, total_items)

        # é˜¶æ®µäºŒï¼šæ ¸å¿ƒä¿®å¤å¾ªç¯
        ui_logger.info("â¡ï¸ [é˜¶æ®µ 2/3] å¼€å§‹å¯¹æ¯ä¸ªé¡¹ç›®æ‰§è¡Œä¿®å¤é“¾æ¡...", task_category=task_cat)
        for i, item in enumerate(items_to_process):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                break
            
            item_id = item['Id']
            item_name = item['Name']
            ui_logger.info(f"  - ({i+1}/{total_items}) æ­£åœ¨å¤„ç†ã€Š{item_name}ã€‹...", task_category=task_cat)
            task_manager.update_task_progress(task_id, i + 1, total_items)

            try:
                # 1. è§¦å‘Embyåˆ·æ–°
                self._trigger_emby_refresh(item_id, task_cat)
                ui_logger.info(f"     - â±ï¸ ç­‰å¾… {config.emby_refresh_wait_seconds} ç§’è®© Emby åº”ç”¨å…ƒæ•°æ®...", task_category=task_cat)
                time.sleep(config.emby_refresh_wait_seconds)

                # 2. æ¼”å‘˜ä¸­æ–‡åŒ–
                localizer_logic = ActorLocalizerLogic(self.app_config)
                localizer_logic._process_single_item_for_localization(item_id, self.app_config.actor_localizer_config, task_cat)

                # 3. è§’è‰²æ˜ å°„è¦†ç›–æ›´æ–°
                role_mapper_logic = ActorRoleMapperLogic(self.app_config)
                role_mapper_logic.generate_map_for_single_item(item_id, task_category=task_cat, overwrite=True)

            except Exception as e:
                ui_logger.error(f"     - âŒ å¤„ç†ã€Š{item_name}ã€‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)

            if i < total_items - 1:
                ui_logger.info(f"     - â±ï¸ [é—´éš”] ç­‰å¾… {config.item_interval_seconds} ç§’...", task_category=task_cat)
                time.sleep(config.item_interval_seconds)

        ui_logger.info("â¡ï¸ [é˜¶æ®µ 3/3] ğŸ‰ æ‰€æœ‰é€‰å®šé¡¹ç›®ä¿®å¤æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼", task_category=task_cat)