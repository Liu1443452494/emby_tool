# backend/chasing_center_logic.py (æ–°æ–‡ä»¶)

import logging
import threading
import time
import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from filelock import FileLock, Timeout

from log_manager import ui_logger
from models import AppConfig, ChasingCenterConfig
from tmdb_logic import TmdbLogic
from episode_refresher_logic import EpisodeRefresherLogic
from notification_manager import notification_manager, escape_markdown
from task_manager import TaskManager

CHASING_LIST_FILE = os.path.join('/app/data', 'chasing_series.json')

class ChasingCenterLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.chasing_config = config.chasing_center_config
        self.tmdb_logic = TmdbLogic(config)
        self.episode_refresher = EpisodeRefresherLogic(config)
        self.memory_cache: Dict[str, Any] = {}

    def _get_chasing_list(self) -> List[Dict[str, Any]]:
        """å®‰å…¨åœ°è¯»å–è¿½æ›´åˆ—è¡¨æ–‡ä»¶ï¼Œå¹¶å…¼å®¹æ–°æ—§æ ¼å¼"""
        if not os.path.exists(CHASING_LIST_FILE):
            return []
        try:
            with open(CHASING_LIST_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if not data:
                return []
            
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ–‡ä»¶å†…å®¹æ˜¯æ—§çš„å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼ï¼Œåˆ™è½¬æ¢ä¸ºæ–°çš„å¯¹è±¡åˆ—è¡¨æ ¼å¼
            if isinstance(data[0], str):
                ui_logger.info("â¡ï¸ [è¿½æ›´åˆ—è¡¨] æ£€æµ‹åˆ°æ—§ç‰ˆè¿½æ›´åˆ—è¡¨æ ¼å¼ï¼Œå°†è‡ªåŠ¨åœ¨åå°è¿›è¡Œè½¬æ¢...", task_category="è¿½æ›´ä¸­å¿ƒ")
                return [{"emby_id": item, "tmdb_id": None, "cache": None} for item in data]

            return data

        except (IOError, json.JSONDecodeError) as e:
            ui_logger.error(f"âŒ [è¿½æ›´åˆ—è¡¨] è¯»å–è¿½æ›´åˆ—è¡¨æ–‡ä»¶å¤±è´¥: {e}", task_category="è¿½æ›´ä¸­å¿ƒ")
            return []

    def _save_chasing_list(self, series_list: List[Dict[str, Any]]):
        """å®‰å…¨åœ°å†™å…¥è¿½æ›´åˆ—è¡¨æ–‡ä»¶"""
        lock_path = CHASING_LIST_FILE + ".lock"
        try:
            with FileLock(lock_path, timeout=10):
                # è¿™æ˜¯ä¸€ä¸ªä¿é™©æªæ–½ï¼Œé˜²æ­¢ä¸å®Œæ•´çš„æ¡ç›®è¢«å†™å…¥
                final_list = [item for item in series_list if item.get("emby_id") and item.get("tmdb_id")]
                if len(final_list) != len(series_list):
                    ui_logger.warning("âš ï¸ [è¿½æ›´åˆ—è¡¨] åœ¨ä¿å­˜æ—¶å‘ç°éƒ¨åˆ†æ¡ç›®ç¼ºå°‘ Emby ID æˆ– TMDB IDï¼Œå·²è¢«è¿‡æ»¤ã€‚", task_category="è¿½æ›´ä¸­å¿ƒ")

                with open(CHASING_LIST_FILE, 'w', encoding='utf-8') as f:
                    json.dump(final_list, f, indent=4)
        except Timeout:
            ui_logger.error("âŒ [è¿½æ›´åˆ—è¡¨] å†™å…¥æ–‡ä»¶æ—¶è·å–é”è¶…æ—¶ï¼", task_category="è¿½æ›´ä¸­å¿ƒ")
        except Exception as e:
            ui_logger.error(f"âŒ [è¿½æ›´åˆ—è¡¨] å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category="è¿½æ›´ä¸­å¿ƒ")



    # backend/chasing_center_logic.py (å‡½æ•°æ›¿æ¢)

    def get_detailed_chasing_list(self) -> List[Dict]:
        """è·å–èšåˆäº† Emby å’Œ TMDB ä¿¡æ¯çš„è¯¦ç»†è¿½æ›´åˆ—è¡¨ï¼Œå¹¶å®ç°ä¸¤çº§ç¼“å­˜å’ŒåŠ¨æ€åˆ†ç•Œçº¿é€»è¾‘"""
        from trakt_manager import TraktManager
        from collections import Counter
        import pytz
        import os

        task_cat = "è¿½æ›´ä¸­å¿ƒ"
        chasing_items_in_memory = self._get_chasing_list()
        if not chasing_items_in_memory:
            return []

        cache_duration_memory = 3600
        cache_duration_file = 86400

        items_to_resave = False
        detailed_list = []
        updates_to_apply = {}
        
        # --- æ–°å¢ ---
        ids_to_remove = []
        # --- æ–°å¢ç»“æŸ ---

        trakt_manager = TraktManager(self.config)

        for item_data in chasing_items_in_memory:
            emby_id = item_data.get("emby_id")
            tmdb_id = item_data.get("tmdb_id")
            
            try:
                emby_details = self.episode_refresher._get_emby_item_details(emby_id, fields="Name,ProductionYear,ProviderIds,ImageTags,BackdropImageTags")
                
                # --- æ–°å¢ï¼šå¥åº·æ£€æŸ¥ä¸è‡ªåŠ¨æ¸…ç†é€»è¾‘ ---
                if not emby_details:
                    ui_logger.warning(f"âš ï¸ [è¿½æ›´ç»´æŠ¤] æ£€æµ‹åˆ°å‰§é›† (Emby ID: {emby_id}) å·²åœ¨ Emby ä¸­è¢«åˆ é™¤æˆ–æ— æ³•è®¿é—®ï¼Œå°†è‡ªåŠ¨ä»è¿½æ›´åˆ—è¡¨ä¸­ç§»é™¤ã€‚", task_category=task_cat)
                    ids_to_remove.append(emby_id)
                    items_to_resave = True
                    continue
                # --- æ–°å¢ç»“æŸ ---

                if not tmdb_id:
                    provider_ids_lower = {k.lower(): v for k, v in emby_details.get("ProviderIds", {}).items()}
                    tmdb_id = provider_ids_lower.get("tmdb")
                    if tmdb_id:
                        item_data["tmdb_id"] = tmdb_id
                        items_to_resave = True
                    else:
                        ui_logger.warning(f"âš ï¸ [è¿½æ›´] å‰§é›†ã€Š{emby_details.get('Name')}ã€‹ç¼ºå°‘ TMDB IDï¼Œæ— æ³•å¤„ç†ã€‚", task_category=task_cat)
                        continue
                
                episodes_url = f"{self.config.server_config.server}/Items"
                episodes_params = {
                    "api_key": self.config.server_config.api_key, 
                    "ParentId": emby_id, 
                    "IncludeItemTypes": "Episode", 
                    "Recursive": "true", 
                    "Fields": "ParentIndexNumber"
                }
                emby_episodes_full_list = self.episode_refresher.session.get(episodes_url, params=episodes_params, timeout=30).json().get("Items", [])
                emby_total_episodes_count = len(emby_episodes_full_list)

                tmdb_cache_data = None
                
                if tmdb_id in self.memory_cache:
                    cached_item = self.memory_cache[tmdb_id]
                    if time.time() - cached_item.get("timestamp", 0) < cache_duration_memory:
                        # --- ä¿®æ”¹ï¼šä¼˜åŒ–æ—¥å¿—è¾“å‡º ---
                        remaining_seconds = cache_duration_memory - (time.time() - cached_item.get("timestamp", 0))
                        remaining_time_str = f"{remaining_seconds / 60:.0f}åˆ†é’Ÿ"
                        
                        cached_status_text = cached_item.get("data", {}).get("details", {}).get("status", "æœªçŸ¥")
                        status_map = {"Returning Series": "æ›´æ–°ä¸­", "Ended": "å·²å®Œç»“", "Canceled": "å·²ç ", "In Production": "åˆ¶ä½œä¸­"}
                        display_status = status_map.get(cached_status_text, cached_status_text)

                        ui_logger.debug(f"ğŸ” [è¿½æ›´-ç¼“å­˜] å‘½ä¸­å†…å­˜ç¼“å­˜: {emby_details.get('Name')} (å‰§é›†çŠ¶æ€: {display_status}, å‰©ä½™: {remaining_time_str})", task_category=task_cat)
                        # --- ä¿®æ”¹ç»“æŸ ---
                        tmdb_cache_data = cached_item["data"]

                if not tmdb_cache_data and item_data.get("cache"):
                    cached_item = item_data["cache"]
                    cached_status = cached_item.get("data", {}).get("details", {}).get("status")
                    
                    if cached_status in ["Ended", "Canceled"]:
                        cache_duration_file = 14 * 86400 # 14å¤©
                    else:
                        cache_duration_file = 1 * 86400 # 24å°æ—¶

                    if time.time() - datetime.fromisoformat(cached_item.get("timestamp", "1970-01-01T00:00:00Z")).timestamp() < cache_duration_file:
                        # --- ä¿®æ”¹ï¼šä¼˜åŒ–æ—¥å¿—è¾“å‡º ---
                        remaining_seconds = cache_duration_file - (time.time() - datetime.fromisoformat(cached_item.get("timestamp", "1970-01-01T00:00:00Z")).timestamp())
                        if remaining_seconds > 86400:
                            remaining_time_str = f"{remaining_seconds / 86400:.1f}å¤©"
                        else:
                            remaining_time_str = f"{remaining_seconds / 3600:.1f}å°æ—¶"
                        
                        cached_status_text = cached_item.get("data", {}).get("details", {}).get("status", "æœªçŸ¥")
                        status_map = {"Returning Series": "æ›´æ–°ä¸­", "Ended": "å·²å®Œç»“", "Canceled": "å·²ç ", "In Production": "åˆ¶ä½œä¸­"}
                        display_status = status_map.get(cached_status_text, cached_status_text)
                        
                        ui_logger.debug(f"ğŸ” [è¿½æ›´-ç¼“å­˜] å‘½ä¸­æ–‡ä»¶ç¼“å­˜: {emby_details.get('Name')} (å‰§é›†çŠ¶æ€: {display_status}, æœ‰æ•ˆæœŸ: {cache_duration_file // 86400}å¤©, å‰©ä½™: {remaining_time_str})", task_category=task_cat)
                        # --- ä¿®æ”¹ç»“æŸ ---
                        tmdb_cache_data = cached_item["data"]
                        self.memory_cache[tmdb_id] = {"timestamp": time.time(), "data": tmdb_cache_data}

                if not tmdb_cache_data:
                    ui_logger.info(f"â¡ï¸ [è¿½æ›´-API] ç¼“å­˜æœªå‘½ä¸­æˆ–å·²è¿‡æœŸï¼Œæ­£åœ¨ä¸ºã€Š{emby_details.get('Name')}ã€‹è¯·æ±‚ TMDB API...", task_category=task_cat)
                    
                    ui_logger.debug(f"   - [è¿½æ›´-API] æ‰§è¡Œè½»é‡çº§å·¡æ£€...", task_category=task_cat)
                    tmdb_details_full = self.tmdb_logic._tmdb_request(f"tv/{tmdb_id}")
                    new_status = tmdb_details_full.get("status")
                    
                    tmdb_cache_data = {
                        "details": {
                            "status": new_status,
                            "number_of_episodes": tmdb_details_full.get("number_of_episodes"),
                            "first_air_date": tmdb_details_full.get("first_air_date"),
                        }
                    }

                    is_chasing = new_status in ["Returning Series", "In Production"]

                    if is_chasing:
                        ui_logger.debug(f"   - [è¿½æ›´-API] å‰§é›†æ’­å‡ºä¸­ï¼Œè¯·æ±‚å¹¶ç¼“å­˜è¯¦ç»†åˆ†é›†åˆ—è¡¨ã€‚")
                        latest_season_summary = max(
                            (s for s in tmdb_details_full.get("seasons", []) if s.get("season_number", 0) > 0 and s.get("episode_count", 0) > 0),
                            key=lambda x: x.get("season_number", 0),
                            default=None
                        )
                        chasing_season_details = {}
                        if latest_season_summary:
                            season_number = latest_season_summary.get("season_number")
                            season_data = self.tmdb_logic.get_season_details(int(tmdb_id), season_number)

                            
                            if season_data and season_data.get("episodes"):
                                chasing_season_details[str(season_number)] = season_data["episodes"]
                        
                        
                        trakt_result = trakt_manager.get_show_seasons_with_episodes(tmdb_id)
                        trakt_episodes_map = None
                        trakt_episode_count = 0
                        if trakt_result:
                            trakt_episodes_map, trakt_episode_count = trakt_result
                        

                        
                        if trakt_episodes_map and latest_season_summary:
                            tmdb_latest_season_num = latest_season_summary.get("season_number")
                            
                            trakt_season_num = None
                            if trakt_episodes_map:
                                first_key = next(iter(trakt_episodes_map))
                                trakt_season_num = int(first_key.split('E')[0][1:])

                            ui_logger.info(f"   - [è¿½æ›´-Trakt] å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ ¡éªŒ...", task_category=task_cat)
                            if tmdb_latest_season_num == trakt_season_num:
                                ui_logger.info(f"     - âœ… å­£å·ä¸€è‡´ (å‡ä¸º S{tmdb_latest_season_num})ï¼Œæ ¡éªŒé€šè¿‡ã€‚", task_category=task_cat)
                                
                                tmdb_episode_count = latest_season_summary.get("episode_count", 0)
                                # --- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ä» Trakt è·å–çš„å£°æ˜å€¼è¿›è¡Œæ¯”è¾ƒ ---
                                if tmdb_episode_count == trakt_episode_count:
                                    ui_logger.info(f"     - âœ… æ€»é›†æ•°ä¸€è‡´ (å‡ä¸º {tmdb_episode_count} é›†)ï¼Œæ•°æ®å®Œç¾åŒ¹é…ã€‚", task_category=task_cat)
                                else:
                                    ui_logger.warning(f"     - âš ï¸ æ€»é›†æ•°ä¸ä¸€è‡´ (TMDB: {tmdb_episode_count} é›†, Trakt: {trakt_episode_count} é›†)ã€‚å°†ç»§ç»­åˆå¹¶å¯ç”¨æ•°æ®ã€‚", task_category=task_cat)
                                # --- ä¿®æ”¹ç»“æŸ ---

                                ui_logger.info(f"   - [è¿½æ›´-Trakt] å¼€å§‹åˆå¹¶ç²¾ç¡®æ’­å‡ºæ—¶é—´...", task_category=task_cat)
                                for s_num, eps in chasing_season_details.items():
                                    for ep in eps:
                                        trakt_key = f"S{ep.get('season_number')}E{ep.get('episode_number')}"
                                        if trakt_key in trakt_episodes_map and trakt_episodes_map[trakt_key]:
                                            try:
                                                utc_time = datetime.fromisoformat(trakt_episodes_map[trakt_key].replace('Z', '+00:00'))
                                                local_tz = pytz.timezone(os.environ.get('TZ', 'Asia/Shanghai'))
                                                local_time = utc_time.astimezone(local_tz)
                                                ep['air_date'] = local_time.strftime('%Y-%m-%d %H:%M')
                                            except Exception as e:
                                                logging.warning(f"   - [è¿½æ›´-Trakt] è§£ææ—¶é—´æˆ³å¤±è´¥: {trakt_episodes_map[trakt_key]}, é”™è¯¯: {e}")
                            else:
                                ui_logger.warning(f"   - [è¿½æ›´-Trakt] âŒ å­£å·ä¸åŒ¹é… (TMDB æœ€æ–°ä¸º S{tmdb_latest_season_num}, Trakt æœ€æ–°ä¸º S{trakt_season_num})ã€‚å°†è·³è¿‡ Trakt æ•°æ®åˆå¹¶ã€‚", task_category=task_cat)
                        
                        tmdb_cache_data["chasing_season_details"] = {
                            s_num: [{"season_number": ep.get("season_number"), "episode_number": ep.get("episode_number"), "air_date": ep.get("air_date")} for ep in eps]
                            for s_num, eps in chasing_season_details.items()
                        }
                    else:
                        ui_logger.debug(f"   - [è¿½æ›´-API] å‰§é›†å·²å®Œç»“ï¼Œé‡‡ç”¨è½»é‡çº§æ‘˜è¦ç¼“å­˜ç­–ç•¥ã€‚")
                        last_ep = tmdb_details_full.get("last_episode_to_air")
                        latest_season_summary = max(
                            (s for s in tmdb_details_full.get("seasons", []) if s.get("season_number", 0) > 0 and s.get("episode_count", 0) > 0),
                            key=lambda x: x.get("season_number", 0),
                            default=None
                        )
                        tmdb_cache_data["chasing_season_summary"] = {
                            "status": new_status,
                            "total_episodes": latest_season_summary.get("episode_count", 0) if latest_season_summary else 0,
                            "last_episode": {
                                "season_number": last_ep.get("season_number"),
                                "episode_number": last_ep.get("episode_number"),
                                "air_date": last_ep.get("air_date")
                            } if last_ep else None
                        }

                    updates_to_apply[tmdb_id] = {"timestamp": datetime.utcnow().isoformat() + "Z", "data": tmdb_cache_data}
                    self.memory_cache[tmdb_id] = {"timestamp": time.time(), "data": tmdb_cache_data}
                    items_to_resave = True

                latest_episode_info = {}
                missing_info = {"count": 0, "status": "synced"}
                
                chasing_season_number = None
                tmdb_chasing_season_total_episodes = 0
                
                if tmdb_cache_data.get("chasing_season_summary"):
                    summary = tmdb_cache_data["chasing_season_summary"]
                    last_ep = summary.get("last_episode")
                    if last_ep:
                        chasing_season_number = last_ep.get("season_number")
                        tmdb_chasing_season_total_episodes = summary.get("total_episodes", 0)
                        latest_episode_info = {
                            "season_number": last_ep.get("season_number"),
                            "episode_number": last_ep.get("episode_number"),
                            "air_date": last_ep.get("air_date"),
                            "is_next": False
                        }
                
                elif tmdb_cache_data.get("chasing_season_details"):
                    chasing_season_details = tmdb_cache_data["chasing_season_details"]
                    if chasing_season_details:
                        chasing_season_number = int(list(chasing_season_details.keys())[0])
                        chasing_episodes = list(chasing_season_details.values())[0]
                        tmdb_chasing_season_total_episodes = len(chasing_episodes)
                        
                        chasing_episodes.sort(key=lambda x: x.get("episode_number", 0))
                        
                        emby_chasing_season_episode_count = sum(1 for ep in emby_episodes_full_list if ep.get("ParentIndexNumber") == chasing_season_number)
                        
                        has_precise_time = any(":" in (ep.get("air_date") or "") for ep in chasing_episodes)

                        if has_precise_time:
                            now = datetime.now(pytz.timezone(os.environ.get('TZ', 'Asia/Shanghai')))
                            
                            def parse_air_datetime(air_date_str, common_time_str=None):
                                try:
                                    return datetime.strptime(air_date_str, '%Y-%m-%d %H:%M').replace(tzinfo=now.tzinfo)
                                except ValueError:
                                    dt = datetime.strptime(air_date_str, '%Y-%m-%d')
                                    if common_time_str:
                                        h, m = map(int, common_time_str.split(':'))
                                        dt = dt.replace(hour=h, minute=m)
                                    return dt.replace(tzinfo=now.tzinfo)

                            time_parts = [ep.get("air_date").split(" ")[1] for ep in chasing_episodes if ep.get("air_date") and ":" in ep.get("air_date", "")]
                            common_time = Counter(time_parts).most_common(1)[0][0] if time_parts else None

                            aired_episodes = [ep for ep in chasing_episodes if ep.get("air_date") and parse_air_datetime(ep["air_date"], common_time) < now]
                            missing_count = len(aired_episodes) - emby_chasing_season_episode_count
                            missing_info = {"count": max(0, missing_count), "status": "missing" if missing_count > 0 else "synced"}

                            future_next_episode = next((ep for ep in chasing_episodes if ep.get("air_date") and parse_air_datetime(ep["air_date"], common_time) >= now), None)
                        
                        else:
                            today = datetime.now().date()
                            emby_latest_ep_in_tmdb = chasing_episodes[emby_chasing_season_episode_count - 1] if emby_chasing_season_episode_count > 0 and emby_chasing_season_episode_count <= len(chasing_episodes) else None
                            emby_latest_air_date_str = emby_latest_ep_in_tmdb.get("air_date") if emby_latest_ep_in_tmdb else None
                            
                            cutoff_date = today
                            if emby_latest_air_date_str:
                                try:
                                    if datetime.strptime(emby_latest_air_date_str, "%Y-%m-%d").date() == today:
                                        cutoff_date = today + timedelta(days=1)
                                except ValueError: pass
                            
                            aired_episodes = [ep for ep in chasing_episodes if ep.get("air_date") and datetime.strptime(ep["air_date"], "%Y-%m-%d").date() < cutoff_date]
                            missing_count = len(aired_episodes) - emby_chasing_season_episode_count
                            missing_info = {"count": max(0, missing_count), "status": "missing" if missing_count > 0 else "synced"}

                            future_next_episode = next((ep for ep in chasing_episodes if ep.get("air_date") and datetime.strptime(ep["air_date"], "%Y-%m-%d").date() >= cutoff_date), None)

                        if future_next_episode:
                            target_ep = future_next_episode
                        else:
                            # æŸ¥æ‰¾æœ€åä¸€ä¸ªæœ‰æ’­å‡ºæ—¥æœŸçš„åˆ†é›†
                            episodes_with_air_date = [ep for ep in chasing_episodes if ep.get("air_date")]
                            target_ep = episodes_with_air_date[-1] if episodes_with_air_date else None


                        is_next = bool(future_next_episode)

                        if target_ep:
                            latest_episode_info = {
                                "season_number": target_ep.get("season_number"),
                                "episode_number": target_ep.get("episode_number"),
                                "air_date": target_ep.get("air_date"),
                                "is_next": is_next
                            }

                if chasing_season_number is not None:
                    emby_chasing_season_episode_count = sum(1 for ep in emby_episodes_full_list if ep.get("ParentIndexNumber") == chasing_season_number)
                    
                    if tmdb_cache_data.get("chasing_season_summary"):
                        tmdb_chasing_season_total_episodes = tmdb_cache_data["chasing_season_summary"].get("total_episodes", 0)
                        missing_count = tmdb_chasing_season_total_episodes - emby_chasing_season_episode_count
                        missing_info = {"count": max(0, missing_count), "status": "complete" if missing_count <= 0 else "missing"}
                
                image_tags = emby_details.get("ImageTags", {})
                if backdrop_tag := emby_details.get("BackdropImageTags", []):
                    image_tags['Backdrop'] = backdrop_tag[0]

                emby_episode_count_display = sum(1 for ep in emby_episodes_full_list if ep.get("ParentIndexNumber") == chasing_season_number) if chasing_season_number is not None else emby_total_episodes_count

                detailed_list.append({
                    "emby_id": emby_id,
                    "tmdb_id": tmdb_id,
                    "name": emby_details.get("Name"),
                    "year": emby_details.get("ProductionYear"),
                    "image_tags": image_tags,
                    "tmdb_status": tmdb_cache_data.get("details", {}).get("status"),
                    "tmdb_total_episodes": tmdb_chasing_season_total_episodes,
                    "tmdb_first_air_date": tmdb_cache_data.get("details", {}).get("first_air_date"),
                    "emby_episode_count": emby_episode_count_display,
                    "latest_episode": latest_episode_info,
                    "missing_info": missing_info,
                    "chasing_season_number": chasing_season_number
                })

            except Exception as e:
                logging.error(f"âŒ [è¿½æ›´] è·å–å‰§é›† {emby_id} çš„è¯¦ç»†ä¿¡æ¯æ—¶å¤±è´¥: {e}", exc_info=True)
                continue
        
        if items_to_resave:
            # --- æ–°å¢ï¼šåœ¨å›å†™å‰ï¼Œå…ˆæ‰§è¡Œæ¸…ç†æ“ä½œ ---
            if ids_to_remove:
                ui_logger.info(f"âœ… [è¿½æ›´] æ­£åœ¨ä»è¿½æ›´åˆ—è¡¨ä¸­ç§»é™¤ {len(ids_to_remove)} ä¸ªæ— æ•ˆæ¡ç›®...", task_category=task_cat)
                chasing_items_in_memory = [item for item in chasing_items_in_memory if item.get("emby_id") not in ids_to_remove]
            # --- æ–°å¢ç»“æŸ ---

            ui_logger.info("âœ… [è¿½æ›´] æ£€æµ‹ç¼“å­˜æœ‰å˜æ›´ï¼Œæ­£åœ¨å›å†™åˆ°è¿½æ›´åˆ—è¡¨æ–‡ä»¶...", task_category=task_cat)
            for item in chasing_items_in_memory:
                if item.get("tmdb_id") in updates_to_apply:
                    item["cache"] = updates_to_apply[item["tmdb_id"]]
            self._save_chasing_list(chasing_items_in_memory)

        return detailed_list

    def add_to_chasing_list(self, series_id: str, series_name: str):
        """å°†ä¸€ä¸ªå‰§é›†IDå’ŒTMDB IDæ·»åŠ åˆ°è¿½æ›´åˆ—è¡¨ï¼Œå¹¶å‘é€é€šçŸ¥"""
        task_cat = "è¿½æ›´ä¸­å¿ƒ"
        chasing_list = self._get_chasing_list()
        
        if any(item.get("emby_id") == series_id for item in chasing_list):
            ui_logger.debug(f"å‰§é›†ã€Š{series_name}ã€‹å·²å­˜åœ¨äºè¿½æ›´åˆ—è¡¨ä¸­ï¼Œæ— éœ€é‡å¤æ·»åŠ ã€‚", task_category=task_cat)
            return

        emby_details = self.episode_refresher._get_emby_item_details(series_id, fields="ProviderIds")
        if not emby_details:
            ui_logger.error(f"âŒ [è¿½æ›´] æ·»åŠ ã€Š{series_name}ã€‹å¤±è´¥ï¼šæ— æ³•è·å–å…¶ Emby è¯¦æƒ…ã€‚", task_category=task_cat)
            return
            
        provider_ids_lower = {k.lower(): v for k, v in emby_details.get("ProviderIds", {}).items()}
        tmdb_id = provider_ids_lower.get("tmdb")

        if not tmdb_id:
            ui_logger.warning(f"âš ï¸ [è¿½æ›´] æ·»åŠ ã€Š{series_name}ã€‹å¤±è´¥ï¼šè¯¥å‰§é›†ç¼ºå°‘ TMDB IDã€‚", task_category=task_cat)
            return

        existing_item = next((item for item in chasing_list if item.get("tmdb_id") == tmdb_id), None)

        if existing_item:
            # å¦‚æœ TMDB ID å­˜åœ¨ï¼Œä»…æ›´æ–° Emby ID
            old_emby_id = existing_item.get("emby_id")
            existing_item["emby_id"] = series_id
            ui_logger.info(f"ğŸ”„ [è¿½æ›´] æ£€æµ‹åˆ°å‰§é›†ã€Š{series_name}ã€‹(TMDB: {tmdb_id}) å·²åœ¨åˆ—è¡¨ä¸­ï¼Œæ›´æ–° Emby ID: {old_emby_id} -> {series_id}", task_category=task_cat)
        else:
            # å¦‚æœ TMDB ID ä¸å­˜åœ¨ï¼Œåˆ™æ–°å¢
            chasing_list.append({"emby_id": series_id, "tmdb_id": tmdb_id, "cache": None})
            ui_logger.info(f"â¡ï¸ [è¿½æ›´] å·²å°†å‰§é›†ã€Š{series_name}ã€‹åŠ å…¥è¿½æ›´åˆ—è¡¨ã€‚", task_category=task_cat)

        self._save_chasing_list(chasing_list)
        

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šç»Ÿä¸€çš„ã€è‡ªç»™è‡ªè¶³çš„é€šçŸ¥é€»è¾‘ ---
        if self.config.telegram_config.enabled:
            ui_logger.info(f"ğŸ”” å‡†å¤‡ä¸ºã€Š{series_name}ã€‹å‘é€è¿½æ›´æ·»åŠ é€šçŸ¥...", task_category=task_cat)
            
            # ä¸»åŠ¨è·å–é€šçŸ¥æ‰€éœ€çš„å…¨éƒ¨ä¿¡æ¯
            details_for_noti = self.episode_refresher._get_emby_item_details(series_id, fields="ProductionYear,Overview,BackdropImageTags")
            if not details_for_noti:
                ui_logger.error(f"   - âŒ æ— æ³•è·å–ã€Š{series_name}ã€‹çš„è¯¦ç»†ä¿¡æ¯ä»¥å‘é€é€šçŸ¥ã€‚", task_category=task_cat)
                return

            series_year = details_for_noti.get("ProductionYear")
            overview = details_for_noti.get("Overview")
            backdrop_tags = details_for_noti.get("BackdropImageTags")

            image_source = None
            if backdrop_tags and len(backdrop_tags) > 0:
                server = self.config.server_config.server.rstrip('/')
                api_key = self.config.server_config.api_key
                image_url = f"{server}/Items/{series_id}/Images/Backdrop/0?api_key={api_key}&tag={backdrop_tags[0]}&maxWidth=1280&quality=80"
                
                try:
                    ui_logger.debug(f"   - æ­£åœ¨ä» Emby ä¸‹è½½èƒŒæ™¯å›¾: {image_url}", task_category=task_cat)
                    proxies = self.episode_refresher.tmdb_logic.proxy_manager.get_proxies(image_url)
                    response = self.episode_refresher.session.get(image_url, timeout=20, proxies=proxies)
                    response.raise_for_status()
                    image_source = response.content
                    ui_logger.debug(f"   - èƒŒæ™¯å›¾ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_source) / 1024:.2f} KB", task_category=task_cat)
                except Exception as e:
                    ui_logger.error(f"   - âŒ ä¸‹è½½èƒŒæ™¯å›¾å¤±è´¥: {e}", task_category=task_cat)

            if not image_source:
                ui_logger.warning("âš ï¸ æ— æ³•è·å–èƒŒæ™¯å›¾ï¼Œå°†ä¸å‘é€å¸¦å›¾é€šçŸ¥ã€‚", task_category=task_cat)
                return

            year_str = f"({series_year})" if series_year else ""
            title_line = escape_markdown(f"{series_name} {year_str} æ·»åŠ è¿½æ›´å‰§é›†æˆåŠŸ")
            
            time_line = escape_markdown(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            overview_line = ""
            if overview:
                max_len = 300
                truncated_overview = overview[:max_len] + '...' if len(overview) > max_len else overview
                overview_line = escape_markdown(f"å‰§æƒ…: {truncated_overview}")

            caption = f"*{title_line}*\n\n`{time_line}`\n\n{overview_line}"
            
            notification_manager.send_telegram_photo_notification(image_source, caption, self.config)
        

    def remove_from_chasing_list(self, series_id: str, series_name: str, reason: str):
        """ä»è¿½æ›´åˆ—è¡¨ä¸­ç§»é™¤ä¸€ä¸ªå‰§é›†"""
        task_cat = "è¿½æ›´ä¸­å¿ƒ"
        chasing_list = self._get_chasing_list()
        
        original_length = len(chasing_list)
        # æ ¹æ® emby_id è¿‡æ»¤æ‰è¦ç§»é™¤çš„é¡¹
        updated_list = [item for item in chasing_list if item.get("emby_id") != series_id]

        if len(updated_list) < original_length:
            self._save_chasing_list(updated_list)
            ui_logger.info(f"âœ… [è¿½æ›´] å·²å°†å‰§é›†ã€Š{series_name}ã€‹ä»è¿½æ›´åˆ—è¡¨ç§»é™¤ã€‚åŸå› : {reason}", task_category=task_cat)

    def _check_and_remove_if_series_complete(self, series_id: str, cancellation_event: threading.Event):
        """
        æ‰§è¡Œä¼˜åŒ–åçš„å®Œç»“æ£€æµ‹é€»è¾‘ (V2.0)ã€‚
        """
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥ä»è¿½æ›´åˆ—è¡¨ä¸­è·å– tmdb_id ---
        chasing_item = next((item for item in self._get_chasing_list() if item.get("emby_id") == series_id), None)
        if not chasing_item: return # å¦‚æœåœ¨åˆ—è¡¨ä¸­æ‰¾ä¸åˆ°ï¼Œç›´æ¥è¿”å›
        tmdb_id = chasing_item.get("tmdb_id")
        # --- ä¿®æ”¹ç»“æŸ ---

        emby_series_details = self.episode_refresher._get_emby_item_details(series_id, fields="ProviderIds,Name")
        if not emby_series_details: return
        
        series_name = emby_series_details.get("Name", f"ID {series_id}")
        task_cat = f"è¿½æ›´-å®Œç»“æ£€æµ‹({series_name})"

        if not tmdb_id:
            ui_logger.warning(f"å‰§é›†ã€Š{series_name}ã€‹ç¼ºå°‘ TMDB IDï¼Œæ— æ³•è¿›è¡Œå®Œç»“æ£€æµ‹ã€‚", task_category=task_cat)
            return

        try:
            tmdb_series_details = self.tmdb_logic._tmdb_request(f"tv/{tmdb_id}")
            
            episodes_url = f"{self.config.server_config.server}/Items"
            episodes_params = {
                "api_key": self.config.server_config.api_key,
                "ParentId": series_id, "IncludeItemTypes": "Episode", "Recursive": "true",
                "Fields": "Name,Overview,ImageTags,ProviderIds"
            }
            emby_episodes = self.episode_refresher.session.get(episodes_url, params=episodes_params, timeout=30).json().get("Items", [])
            
            # ç»´åº¦ä¸€ï¼šæ•°é‡å®Œæ•´æ€§
            total_episodes_on_tmdb = tmdb_series_details.get("number_of_episodes")
            if not total_episodes_on_tmdb:
                ui_logger.info(f"å‰§é›†ã€Š{series_name}ã€‹åœ¨ TMDB ä¸Šçš„æ€»é›†æ•°æœªçŸ¥ï¼Œè·³è¿‡æ•°é‡å®Œæ•´æ€§æ£€æŸ¥ã€‚", task_category=task_cat)
                return

            if len(emby_episodes) < total_episodes_on_tmdb:
                ui_logger.info(f"å‰§é›†ã€Š{series_name}ã€‹å°šæœªå®Œç»“ï¼šEmby ä¸­æœ‰ {len(emby_episodes)} é›†ï¼ŒTMDB æ˜¾ç¤ºæ€»å…± {total_episodes_on_tmdb} é›†ã€‚", task_category=task_cat)
                return

            # ç»´åº¦äºŒï¼šè´¨é‡å®Œæ•´æ€§
            all_metadata_complete = True
            for ep in emby_episodes:
                is_title_ok = bool(ep.get("Name")) and not self.episode_refresher._is_generic_episode_title(ep.get("Name"))
                is_overview_ok = bool(ep.get("Overview"))
                
                ep_provider_ids_lower = {k.lower(): v for k, v in ep.get("ProviderIds", {}).items()}
                image_source = ep_provider_ids_lower.get("toolboximagesource")
                has_official_image = bool(ep.get("ImageTags", {}).get("Primary")) and image_source != "screenshot"

                if not (is_title_ok and is_overview_ok and has_official_image):
                    all_metadata_complete = False
                    break
            
            # æœ€ç»ˆå†³ç­–
            if all_metadata_complete:
                self.remove_from_chasing_list(series_id, series_name, "æ•°é‡ä¸å…ƒæ•°æ®è´¨é‡å‡å®Œæ•´")
                return
            else:
                # ç»´åº¦ä¸‰ï¼šè¶…æ—¶å®¹é”™
                last_air_date_str = tmdb_series_details.get("last_episode_to_air", {}).get("air_date")
                if not last_air_date_str:
                    ui_logger.warning(f"å‰§é›†ã€Š{series_name}ã€‹å…ƒæ•°æ®ä¸å®Œæ•´ï¼Œä¸”æ— æ³•è·å– TMDB æœ€åä¸€é›†æ’­å‡ºæ—¥æœŸï¼Œæš‚æ—¶ä¸ç§»é™¤ã€‚", task_category=task_cat)
                    return

                last_air_date = datetime.strptime(last_air_date_str, "%Y-%m-%d")
                deadline = last_air_date + timedelta(days=self.chasing_config.completion_deadline_days)
                
                if datetime.now() > deadline:
                    self.remove_from_chasing_list(series_id, series_name, f"è¶…å‡ºæœ€ç»ˆæ’­å‡ºæ—¥æœŸ {self.chasing_config.completion_deadline_days} å¤©ï¼Œå¼ºåˆ¶å®Œç»“")
                else:
                    # --- ä¿®æ”¹ï¼šä¼˜åŒ–æ—¥å¿—è¾“å‡º ---
                    time_left = deadline - datetime.now()
                    days_left = time_left.days
                    
                    remaining_str = ""
                    if days_left > 0:
                        remaining_str = f" (è¿˜å‰© {days_left} å¤©)"
                    else:
                        hours_left = time_left.total_seconds() / 3600
                        if hours_left > 1:
                            remaining_str = f" (è¿˜å‰© {hours_left:.0f} å°æ—¶)"
                        else:
                            minutes_left = time_left.total_seconds() / 60
                            remaining_str = f" (è¿˜å‰© {minutes_left:.0f} åˆ†é’Ÿ)"

                    ui_logger.info(f"å‰§é›†ã€Š{series_name}ã€‹å…ƒæ•°æ®ä¸å®Œæ•´ï¼Œä»åœ¨ {self.chasing_config.completion_deadline_days} å¤©çš„ç­‰å¾…æœŸå†…{remaining_str}ï¼Œæœ¬æ¬¡ä¸ç§»é™¤ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ åœ¨ä¸ºã€Š{series_name}ã€‹æ‰§è¡Œå®Œç»“æ£€æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat, exc_info=True)

    def run_chasing_workflow_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        å†…ç½®çš„æ¯æ—¥è¿½æ›´å·¥ä½œæµã€‚
        """
        task_cat = "è¿½æ›´-æ¯æ—¥ç»´æŠ¤"
        ui_logger.info(f"ğŸ‰ å¼€å§‹æ‰§è¡Œæ¯æ—¥è¿½æ›´ç»´æŠ¤ä»»åŠ¡...", task_category=task_cat)
        
        chasing_list = self._get_chasing_list()
        if not chasing_list:
            ui_logger.info("âœ… è¿½æ›´åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€æ‰§è¡Œã€‚", task_category=task_cat)
            return

        ui_logger.info(f"ğŸ” å‘ç° {len(chasing_list)} ä¸ªè¿½æ›´å‰§é›†ï¼Œå¼€å§‹é€ä¸€å¤„ç†...", task_category=task_cat)
        task_manager.update_task_progress(task_id, 0, len(chasing_list))

        for i, series_item in enumerate(chasing_list):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«å–æ¶ˆã€‚", task_category=task_cat)
                return
            
            series_id = series_item.get("emby_id")
            if not series_id:
                ui_logger.warning(f"   - [è·³è¿‡] è¿½æ›´åˆ—è¡¨ä¸­çš„ç¬¬ {i+1} é¡¹ç¼ºå°‘ 'emby_id'ï¼Œæ— æ³•å¤„ç†ã€‚", task_category=task_cat)
                task_manager.update_task_progress(task_id, i + 1, len(chasing_list))
                continue
            
            series_details = self.episode_refresher._get_emby_item_details(series_id, fields="Name")
            series_name = series_details.get("Name", f"ID {series_id}") if series_details else f"ID {series_id}"
            ui_logger.info(f"â¡ï¸ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(chasing_list)} ä¸ªå‰§é›†: ã€Š{series_name}ã€‹", task_category=task_cat)

            # 1. åˆ·æ–°å…ƒæ•°æ®
            ui_logger.info(f"   - [æ­¥éª¤1/2] æ­£åœ¨åˆ·æ–°å…ƒæ•°æ®...", task_category=task_cat)
            try:
                episodes_url = f"{self.config.server_config.server}/Items"
                episodes_params = {
                    "api_key": self.config.server_config.api_key,
                    "ParentId": series_id, "IncludeItemTypes": "Episode", "Recursive": "true", "Fields": "Id"
                }
                episodes = self.episode_refresher.session.get(episodes_url, params=episodes_params, timeout=30).json().get("Items", [])
                episode_ids = [ep['Id'] for ep in episodes]
                
                if episode_ids:
                    self.episode_refresher.run_refresh_for_episodes(
                        episode_ids, self.config.episode_refresher_config, cancellation_event, 
                        task_id=None, task_manager=None, task_category=f"è¿½æ›´-åˆ·æ–°({series_name})"
                    )
                else:
                    ui_logger.info(f"   - ã€Š{series_name}ã€‹ä¸‹æš‚æ— åˆ†é›†ï¼Œè·³è¿‡åˆ·æ–°ã€‚", task_category=task_cat)
            except Exception as e:
                ui_logger.error(f"   - âŒ åˆ·æ–°ã€Š{series_name}ã€‹æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat)

            # 2. å®Œç»“æ£€æµ‹
            ui_logger.info(f"   - [æ­¥éª¤2/2] æ­£åœ¨è¿›è¡Œå®Œç»“çŠ¶æ€æ£€æµ‹...", task_category=task_cat)
            self._check_and_remove_if_series_complete(series_id, cancellation_event)
            
            task_manager.update_task_progress(task_id, i + 1, len(chasing_list))
            time.sleep(1) # çŸ­æš‚é—´éš”

        ui_logger.info("ğŸ‰ æ¯æ—¥è¿½æ›´ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚", task_category=task_cat)

        self.run_orphaned_cache_cleanup_task(cancellation_event, task_id, task_manager)

    def _scan_and_cleanup_orphaned_cache_for_series(self, series_id: str, task_category: str) -> int:
        """
        æ‰«ææŒ‡å®šå‰§é›†ï¼Œæ¸…ç†é‚£äº› TMDB å·²æœ‰å›¾ï¼ˆEmbyæ— æ ‡è®°ï¼‰ä½†æœ¬åœ°ä»æ®‹ç•™çš„æˆªå›¾ç¼“å­˜ã€‚
        å®ç°äº†è¿œç¨‹ç´¢å¼•çš„æŒ‰éœ€åŠ è½½ï¼ˆLazy Loadï¼‰ã€‚
        """
        cleaned_count = 0
        try:
            # 1. è·å–å‰§é›†è¯¦æƒ…ä¸æ ‡ç­¾æ£€æŸ¥
            series_details = self.episode_refresher._get_emby_item_details(series_id, fields="ProviderIds,Name,Tags,TagItems")
            if not series_details:
                return 0
            
            series_name = series_details.get("Name", "æœªçŸ¥å‰§é›†")
            
            # æ£€æŸ¥å¼ºåˆ¶åˆ·æ–°æ ‡ç­¾ (è±å…æƒ)
            tags = []
            if 'TagItems' in series_details and isinstance(series_details['TagItems'], list):
                tags = [t.get('Name') for t in series_details.get('TagItems', []) if isinstance(t, dict)]
            elif 'Tags' in series_details and isinstance(series_details['Tags'], list):
                tags = series_details.get("Tags", [])
            
            for t in tags:
                if str(t).lower() in ["forceimagerefresh", "forcelmagerefresh"]:
                    ui_logger.info(f"   - [è·³è¿‡] å‰§é›†ã€Š{series_name}ã€‹æ‹¥æœ‰å¼ºåˆ¶åˆ·æ–°æ ‡ç­¾ï¼Œè·³è¿‡æ¸…ç†ã€‚", task_category=task_category)
                    return 0

            # è·å– TMDB ID
            provider_ids_lower = {k.lower(): v for k, v in series_details.get("ProviderIds", {}).items()}
            series_tmdb_id = provider_ids_lower.get("tmdb")
            if not series_tmdb_id:
                return 0

            # 2. è·å–æ‰€æœ‰åˆ†é›†
            episodes_url = f"{self.config.server_config.server}/Items"
            episodes_params = {
                "api_key": self.config.server_config.api_key,
                "ParentId": series_id,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "Fields": "Id,Name,ParentIndexNumber,IndexNumber,ProviderIds"
            }
            episodes_resp = self.episode_refresher.session.get(episodes_url, params=episodes_params, timeout=30)
            episodes_resp.raise_for_status()
            all_episodes = episodes_resp.json().get("Items", [])

            remote_db = None
            remote_db_loaded = False # æ ‡è®°æ˜¯å¦å°è¯•åŠ è½½è¿‡

            # 3. éå†æ£€æŸ¥
            for ep in all_episodes:
                # æ£€æŸ¥ Emby æ ‡è®°
                ep_provider_ids = {k.lower(): v for k, v in ep.get("ProviderIds", {}).items()}
                if ep_provider_ids.get("toolboximagesource"):
                    continue # æœ‰æ ‡è®°ï¼Œè¯´æ˜æ˜¯æœ‰æ•ˆæˆªå›¾ï¼Œä¿ç•™

                # æ„å»ºæœ¬åœ°è·¯å¾„
                s_num = ep.get("ParentIndexNumber")
                e_num = ep.get("IndexNumber")
                if s_num is None or e_num is None: continue

                # è°ƒç”¨ Refresher çš„è¾…åŠ©æ–¹æ³•æ„å»ºè·¯å¾„
                local_path = self.episode_refresher._get_local_screenshot_path(series_tmdb_id, s_num, e_num, series_name)
                if not local_path: continue

                # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                # æ³¨æ„ï¼š_get_local_screenshot_path è¿”å›çš„æ˜¯ç†è®ºè·¯å¾„ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥å®é™…æ–‡ä»¶
                # è¿™é‡Œä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬ä½¿ç”¨ _find_screenshot_cache_dir_by_tmdbid æ¥å®šä½çœŸå®ç›®å½•
                real_cache_dir = self.episode_refresher._find_screenshot_cache_dir_by_tmdbid(series_tmdb_id)
                if not real_cache_dir: continue
                
                real_file_path = os.path.join(real_cache_dir, os.path.basename(local_path))

                if os.path.exists(real_file_path):
                    # å‘½ä¸­ï¼æ— æ ‡è®° + æœ¬åœ°æœ‰æ–‡ä»¶ = åƒåœ¾æ–‡ä»¶
                    ui_logger.info(f"   - ğŸ—‘ï¸ [æ¸…ç†] å‘ç°æ— æ•ˆç¼“å­˜: S{s_num:02d}E{e_num:02d} (Embyå·²ç”¨å®˜æ–¹å›¾)ï¼Œæ­£åœ¨åˆ é™¤...", task_category=task_category)
                    
                    try:
                        os.remove(real_file_path)
                        cleaned_count += 1
                        
                        # å°è¯•æ¸…ç†ç©ºç›®å½•
                        try:
                            if not os.listdir(real_cache_dir):
                                os.rmdir(real_cache_dir)
                        except: pass

                        # 4. è”åŠ¨è¿œç¨‹æ£€æŸ¥ (æŒ‰éœ€åŠ è½½)
                        if not remote_db_loaded:
                            ui_logger.debug(f"   - [è¿œç¨‹] é¦–æ¬¡è§¦å‘æ¸…ç†ï¼Œæ­£åœ¨åŠ è½½è¿œç¨‹ç´¢å¼•ä»¥æ£€æŸ¥å¤‡ä»½çŠ¶æ€...", task_category=task_category)
                            remote_db, _ = self.episode_refresher._get_remote_db(self.config.episode_refresher_config)
                            remote_db_loaded = True
                        
                        if remote_db:
                            episode_key = f"{s_num}-{e_num}"
                            if remote_db.get("series", {}).get(str(series_tmdb_id), {}).get(episode_key):
                                ui_logger.info(f"   - ğŸ“ [è¿œç¨‹] è¯¥æˆªå›¾å­˜åœ¨äºè¿œç¨‹å¤‡ä»½ä¸­ï¼Œå·²åŠ å…¥å¾…åˆ é™¤æ—¥å¿—ã€‚", task_category=task_category)
                                self.episode_refresher._log_screenshot_for_deletion(
                                    series_tmdb_id=series_tmdb_id,
                                    series_name=series_name,
                                    emby_series_id=series_id,
                                    season_number=s_num,
                                    episode_number=e_num
                                )

                    except Exception as e:
                        ui_logger.error(f"   - âŒ åˆ é™¤æœ¬åœ°æ–‡ä»¶å¤±è´¥: {e}", task_category=task_category)

        except Exception as e:
            ui_logger.error(f"   - âŒ æ¸…ç†å‰§é›† {series_id} ç¼“å­˜æ—¶å‡ºé”™: {e}", task_category=task_category)
        
        return cleaned_count

    def run_orphaned_cache_cleanup_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        æ‰«æè¿½æ›´åˆ—è¡¨ä¸­çš„å‰§é›†ï¼Œæ¸…ç†é‚£äº›å·²è¢«å®˜æ–¹å›¾æ›¿æ¢çš„æœ¬åœ°æ— æ•ˆæˆªå›¾ç¼“å­˜ã€‚
        """
        task_cat = "è¿½æ›´-ç¼“å­˜æ¸…ç†"
        ui_logger.info(f"ğŸ§¹ å¼€å§‹æ‰§è¡Œæ— æ•ˆç¼“å­˜æ¸…ç†ä»»åŠ¡...", task_category=task_cat)
        
        chasing_list = self._get_chasing_list()
        if not chasing_list:
            ui_logger.info("âœ… è¿½æ›´åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†ã€‚", task_category=task_cat)
            return

        total_cleaned = 0
        
        for i, series_item in enumerate(chasing_list):
            if cancellation_event.is_set(): return
            
            series_id = series_item.get("emby_id")
            if not series_id: continue
            
            cleaned = self._scan_and_cleanup_orphaned_cache_for_series(series_id, task_cat)
            total_cleaned += cleaned
            
            if task_manager:
                task_manager.update_task_progress(task_id, i + 1, len(chasing_list))

        if total_cleaned > 0:
            ui_logger.info(f"ğŸ‰ æ¸…ç†å®Œæˆã€‚å…±åˆ é™¤äº† {total_cleaned} ä¸ªæ— æ•ˆçš„æœ¬åœ°æˆªå›¾ç¼“å­˜æ–‡ä»¶ã€‚", task_category=task_cat)
        else:
            ui_logger.info(f"âœ… æ¸…ç†å®Œæˆã€‚æœªå‘ç°æ— æ•ˆçš„æœ¬åœ°ç¼“å­˜ã€‚", task_category=task_cat)


    def send_calendar_notification_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        ç”Ÿæˆå¹¶å‘é€è¿½å‰§æ—¥å†é€šçŸ¥ (V2.5 - ä¿®æ­£ â€¢ ç¬¦å·è½¬ä¹‰é—®é¢˜)ã€‚
        """
        task_cat = "è¿½æ›´-æ—¥å†é€šçŸ¥"
        ui_logger.info(f"ğŸ“… å¼€å§‹åŸºäºæœ¬åœ°ç¼“å­˜ç”Ÿæˆè¿½å‰§æ—¥å†...", task_category=task_cat)

        ui_logger.info(f"   - [æ­¥éª¤1/2] æ­£åœ¨é¢„çƒ­ç¼“å­˜ï¼Œç¡®ä¿æ•°æ®ä¸ºæœ€æ–°...", task_category=task_cat)
        self.get_detailed_chasing_list()
        ui_logger.info(f"   - âœ… ç¼“å­˜é¢„çƒ­å®Œæˆã€‚", task_category=task_cat)
        
        ui_logger.info(f"   - [æ­¥éª¤2/2] å¼€å§‹ç”Ÿæˆæ—¥å†å†…å®¹...", task_category=task_cat)

        chasing_list_data = self._get_chasing_list()
        if not chasing_list_data:
            ui_logger.info("âœ… è¿½æ›´åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€å‘é€é€šçŸ¥ã€‚", task_category=task_cat)
            return

        calendar_days = self.chasing_config.calendar_days
        today = datetime.now().date()
        end_date = today + timedelta(days=calendar_days)
        
        upcoming_episodes = []
        
        for series_data in chasing_list_data:
            if cancellation_event.is_set(): return
            
            series_name = "æœªçŸ¥å‰§é›†"
            series_year = ""
            try:
                emby_details = self.episode_refresher._get_emby_item_details(series_data.get("emby_id"), fields="Name,ProductionYear")
                if emby_details:
                    series_name = emby_details.get("Name")
                    series_year = emby_details.get("ProductionYear")

                cache = series_data.get("cache", {})
                if not cache:
                    ui_logger.debug(f"   - [è·³è¿‡] å‰§é›†ã€Š{series_name}ã€‹ç¼ºå°‘ç¼“å­˜æ•°æ®ã€‚", task_category=task_cat)
                    continue

                tmdb_status = cache.get("data", {}).get("details", {}).get("status")
                if tmdb_status not in ["Returning Series", "In Production"]:
                    ui_logger.debug(f"   - [è·³è¿‡] å‰§é›†ã€Š{series_name}ã€‹çŠ¶æ€ä¸º '{tmdb_status}'ï¼Œéæ’­å‡ºä¸­ã€‚", task_category=task_cat)
                    continue

                chasing_season_details = cache.get("data", {}).get("chasing_season_details", {})
                if not chasing_season_details:
                    continue

                for season_number_str, episodes in chasing_season_details.items():
                    for episode in episodes:
                        air_date_str = episode.get("air_date")
                        if not air_date_str or air_date_str == "null":
                            continue
                        
                        try:
                            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¢å¼ºæ•°æ®ç»“æ„ï¼ŒåŒæ—¶ä¿ç•™æ—¥æœŸå¯¹è±¡å’ŒåŸå§‹å­—ç¬¦ä¸² ---
                            air_date_part = air_date_str.split(' ')[0]
                            air_date = datetime.strptime(air_date_part, "%Y-%m-%d").date()
                            
                            if today <= air_date < end_date:
                                upcoming_episodes.append({
                                    "series_name": series_name,
                                    "series_year": series_year,
                                    "air_date": air_date, # ç”¨äºæ’åºå’Œåˆ†ç»„
                                    "air_date_str": air_date_str, # ç”¨äºæœ€ç»ˆå±•ç¤º
                                    "season_number": episode.get("season_number"),
                                    "episode_number": episode.get("episode_number"),
                                })
                            # --- ä¿®æ”¹ç»“æŸ ---
                        except (ValueError, TypeError):
                            continue
            except Exception as e:
                logging.error(f"âŒ å¤„ç†å‰§é›† {series_data.get('emby_id')} çš„æ—¥å†æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)

        if not upcoming_episodes:
            ui_logger.info(f"âœ… æ£€æµ‹åˆ°æœªæ¥ {calendar_days} å¤©å†…æ— æ›´æ–°ï¼Œè·³è¿‡æœ¬æ¬¡é€šçŸ¥ã€‚", task_category=task_cat)
            return

        upcoming_episodes.sort(key=lambda x: (x["air_date"], x["series_name"], x["season_number"], x["episode_number"]))
        
        message_parts = [f"ğŸ“… *Emby è¿½å‰§æ—¥å† \\(æœªæ¥ {escape_markdown(str(calendar_days))} å¤©\\)*\n"]
        
        from collections import defaultdict
        from itertools import groupby

        grouped_by_date = defaultdict(list)
        for ep in upcoming_episodes:
            grouped_by_date[ep["air_date"]].append(ep)
            
        weekdays = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        
        sorted_dates = sorted(grouped_by_date.keys())

        for i, air_date in enumerate(sorted_dates):
            date_str_escaped = escape_markdown(air_date.strftime("%Y-%m-%d"))
            weekday_str = weekdays[air_date.weekday()]
            
            relative_day_raw = ""
            if air_date == today:
                relative_day_raw = " (ä»Šå¤©)"
            elif air_date == today + timedelta(days=1):
                relative_day_raw = " (æ˜å¤©)"
            elif air_date == today + timedelta(days=2):
                relative_day_raw = " (åå¤©)"
            
            relative_day_escaped = escape_markdown(relative_day_raw)
            
            message_parts.append(f"\n*{date_str_escaped} {weekday_str}{relative_day_escaped}*")
            
            keyfunc = lambda x: (x['series_name'], x['series_year'], x['season_number'])
            
            for (series_name, series_year, season_number), group in groupby(grouped_by_date[air_date], key=keyfunc):
                year_str = f"\\({series_year}\\)" if series_year else ""
                
                message_parts.append(
                    f"â— *[{escape_markdown(series_name)}{year_str}]* S{season_number:02d}"
                )
                
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ ¹æ®æ ¼å¼åŠ¨æ€æ‹¼æ¥åˆ†é›†ä¿¡æ¯ ---
                for ep in group:
                    time_str = ""
                    if ' ' in ep['air_date_str']:
                        time_part = ep['air_date_str'].split(' ')[1]
                        time_str = f" `{escape_markdown(time_part)}`" # å¢åŠ ä»£ç å—æ ·å¼ä»¥çªå‡ºæ—¶é—´

                    message_parts.append(f"  \\ ï¼ ç¬¬{ep['episode_number']}é›†{time_str}")
                # --- ä¿®æ”¹ç»“æŸ ---
            
        final_message = "\n".join(message_parts)
        
        ui_logger.info("â¡ï¸ æ­£åœ¨å‘é€ Telegram é€šçŸ¥...", task_category=task_cat)
        notification_manager.send_telegram_message(final_message, self.config)

    def get_calendar_data_for_series(self, series_id: str) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªå‰§é›†ç”Ÿæˆæ—¥å†æ•°æ®"""
        task_cat = "è¿½æ›´-æ—¥å†"
        chasing_list = self._get_chasing_list()
        
        target_series = next((item for item in chasing_list if item.get("emby_id") == series_id), None)
        
        if not target_series:
            ui_logger.warning(f"âš ï¸ [æ—¥å†] åœ¨è¿½æ›´åˆ—è¡¨ä¸­æœªæ‰¾åˆ° Emby ID ä¸º {series_id} çš„å‰§é›†ã€‚", task_category=task_cat)
            return {}

        cache = target_series.get("cache", {})
        if not cache:
            ui_logger.debug(f"   - [æ—¥å†] å‰§é›† {series_id} ç¼ºå°‘ç¼“å­˜æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ—¥å†ã€‚", task_category=task_cat)
            return {}

        chasing_season_details = cache.get("data", {}).get("chasing_season_details", {})
        if not chasing_season_details:
            ui_logger.debug(f"   - [æ—¥å†] å‰§é›† {series_id} çš„ç¼“å­˜ä¸­ç¼ºå°‘ 'chasing_season_details'ï¼Œæ— æ³•ç”Ÿæˆæ—¥å†ã€‚", task_category=task_cat)
            return {}

        # ä½¿ç”¨ defaultdict ç®€åŒ–åˆ†ç»„é€»è¾‘
        from collections import defaultdict
        grouped_by_date = defaultdict(list)

        for season_number_str, episodes in chasing_season_details.items():
            for episode in episodes:
                air_date_str = episode.get("air_date")
                if air_date_str and air_date_str != "null":
                    date_key = air_date_str.split(' ')[0]
                    grouped_by_date[date_key].append(episode)
        
        return dict(grouped_by_date)
    
    