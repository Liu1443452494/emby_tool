# backend/upcoming_logic.py (å®Œæ•´æ–‡ä»¶è¦†ç›–)

import logging
import os
import json
import time
from typing import Dict, Any, Optional, List, Literal, Tuple
from datetime import datetime, timedelta, timezone
from filelock import FileLock, Timeout

from models import AppConfig
from log_manager import ui_logger
from trakt_manager import TraktManager
from tmdb_logic import TmdbLogic
from notification_manager import notification_manager, escape_markdown

# --- ä¿®æ”¹ï¼šç§»é™¤è®¢é˜…æ–‡ä»¶å¸¸é‡ï¼Œä¿®æ”¹ç¼“å­˜æ–‡ä»¶å¸¸é‡ ---
UPCOMING_DB_FILE = os.path.join('/app/data', 'upcoming_database.json')
# --- ä¿®æ”¹ç»“æŸ ---
CACHE_DURATION_HOURS = 12

class UpcomingLogic:
    def __init__(self, app_config: AppConfig):
        self.app_config = app_config
        self.config = app_config.upcoming_config
        self.trakt_manager = TraktManager(app_config)
        self.tmdb_logic = TmdbLogic(app_config)

    def _read_db(self) -> Dict:
        """å®‰å…¨åœ°è¯»å–æ•°æ®åº“æ–‡ä»¶"""
        if not os.path.exists(UPCOMING_DB_FILE):
            return {"timestamp": None, "data": {}}
        try:
            with open(UPCOMING_DB_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                if not content:
                    return {"timestamp": None, "data": {}}
                return json.loads(content)
        except (IOError, json.JSONDecodeError):
            return {"timestamp": None, "data": {}}

    

    def _write_db(self, db_content: Dict):
        """å®‰å…¨åœ°å†™å…¥æ•°æ®åº“æ–‡ä»¶"""
        task_cat = "å³å°†ä¸Šæ˜ -æ•°æ®åº“"
        try:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šç§»é™¤è¿™é‡Œçš„ with FileLock ---
            with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                json.dump(db_content, f, ensure_ascii=False, indent=4)
        except Exception as e:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒæ•´æ—¥å¿—ï¼Œå› ä¸ºé”çš„é”™è¯¯ä¼šåœ¨è°ƒç”¨æ–¹è¢«æ•è· ---
            ui_logger.error(f"âŒ å†™å…¥æ•°æ®åº“æ—¶å‘ç”ŸIOé”™è¯¯: {e}", task_category=task_cat)
            raise # æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†

    def _is_cache_valid(self, db_content: Dict) -> Tuple[bool, str]:
        """æ£€æŸ¥ Trakt ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        timestamp_str = db_content.get("timestamp")
        if not timestamp_str:
            return False, "æ— æœ‰æ•ˆæ—¶é—´æˆ³"
        
        try:
            timestamp = datetime.fromisoformat(timestamp_str)
            age = datetime.now(timezone.utc) - timestamp
            
            if age < timedelta(hours=CACHE_DURATION_HOURS):
                remaining_time = timedelta(hours=CACHE_DURATION_HOURS) - age
                remaining_hours = int(remaining_time.total_seconds() // 3600)
                remaining_minutes = int((remaining_time.total_seconds() % 3600) // 60)
                if remaining_hours > 0:
                    return True, f"æœ‰æ•ˆæœŸå‰©ä½™çº¦ {remaining_hours} å°æ—¶ {remaining_minutes} åˆ†é’Ÿ"
                else:
                    return True, f"æœ‰æ•ˆæœŸå‰©ä½™çº¦ {remaining_minutes} åˆ†é’Ÿ"
            else:
                return False, f"ç¼“å­˜å·²äºçº¦ {int(age.total_seconds() // 3600 - CACHE_DURATION_HOURS)} å°æ—¶å‰è¿‡æœŸ"
        except ValueError:
            return False, "æ—¶é—´æˆ³æ ¼å¼æ— æ•ˆ"

    def _apply_3d_filtering(self, raw_items: List[Dict], filters: Dict) -> List[Dict]:
        task_cat = "å³å°†ä¸Šæ˜ -ç­›é€‰"
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 2/3] å¼€å§‹åº”ç”¨ä¸‰ç»´åˆ†å±‚é¢„ç­›é€‰ç­–ç•¥...", task_category=task_cat)
        
        verified_items = []
        processed_ids = set()

        for item in raw_items:
            media_type = item.get('media_type')
            media_info = item.get('movie') if media_type == 'movie' else item.get('show')
            if not media_info: continue

            tmdb_id = media_info.get('ids', {}).get('tmdb')
            if not tmdb_id or tmdb_id in processed_ids: continue
            
            title = media_info.get('original_title') or media_info.get('title', 'N/A')
            
            genres = media_info.get('genres', [])
            if any(genre in filters['genre_blacklist'] for genre in genres):
                logging.debug(f"  - [ä¸¢å¼ƒ] {title}: ç±»å‹åœ¨é»‘åå•ä¸­ ({genres})")
                continue

            country = media_info.get('country', '')
            language = media_info.get('language', '')
            translations = media_info.get('available_translations', [])

            is_p0 = (country in filters['p0_countries']) or (language in filters['p0_languages'])
            is_p1 = (country in filters['p1_countries']) and ('zh' in translations)

            if is_p0 or is_p1:
                reason = "æ ¸å¿ƒå¸‚åœº" if is_p0 else "æ½œåŠ›å¸‚åœº"
                logging.debug(f"  - [ä¿ç•™] {title}: {reason}")
                
                release_date = item.get('released') or item.get('first_aired')
                if release_date:
                    release_date_str = datetime.fromisoformat(release_date.replace('Z', '+00:00')).strftime('%Y-%m-%d')
                    verified_items.append({'tmdb_id': tmdb_id, 'media_type': media_type, 'release_date': release_date_str})
                    processed_ids.add(tmdb_id)
            else:
                logging.debug(f"  - [ä¸¢å¼ƒ] {title}: ä½ä¼˜å…ˆçº§ (å›½å®¶: {country}, è¯­è¨€: {language})")

        ui_logger.info(f"âœ… [æ­¥éª¤ 2/3] é¢„ç­›é€‰å®Œæˆã€‚å€™é€‰æ¡ç›®ä» {len(raw_items)} ä¸ªå‡å°‘åˆ° {len(verified_items)} ä¸ªã€‚", task_category=task_cat)
        return verified_items

    def get_upcoming_list(self, dynamic_filters: Optional[Dict] = None) -> List[Dict]:
        task_cat = "å³å°†ä¸Šæ˜ -è·å–"
        ui_logger.info(f"â¡ï¸ [æ ¸å¿ƒå…¥å£] get_upcoming_list è¢«è°ƒç”¨ã€‚å¼ºåˆ¶åˆ·æ–°: {bool(dynamic_filters and not dynamic_filters.get('use_defaults', True))}", task_category=task_cat)
        filters = self.config.filters.model_dump()
        force_refresh = False
        if dynamic_filters and not dynamic_filters.get('use_defaults', True):
            ui_logger.info("ğŸ” æ£€æµ‹åˆ°åŠ¨æ€ç­›é€‰æ¡ä»¶ï¼Œå°†å¼ºåˆ¶åˆ·æ–°ã€‚", task_category=task_cat)
            force_refresh = True
            for key, value in dynamic_filters.items():
                if key in filters:
                    filters[key] = value
        
        db_content = self._read_db()
        is_valid, reason = self._is_cache_valid(db_content)

        if is_valid and not force_refresh:
            ui_logger.info(f"âœ… å‘½ä¸­ Trakt æ—¥å†ç¼“å­˜ï¼{reason}ã€‚", task_category=task_cat)
        else:
            if force_refresh:
                ui_logger.info("ğŸ”„ ç”¨æˆ·è¯·æ±‚åº”ç”¨æ–°ç­›é€‰æ¡ä»¶ï¼Œå¼ºåˆ¶ä» Trakt åˆ·æ–°...", task_category=task_cat)
            else:
                ui_logger.warning(f"âš ï¸ Trakt æ—¥å†ç¼“å­˜å·²å¤±æ•ˆ ({reason})ï¼Œå¼€å§‹ä» Trakt åˆ·æ–°...", task_category=task_cat)

            ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 1/3] å¼€å§‹ä» Trakt è·å–æœªæ¥ {filters['fetch_days']} å¤©çš„æ—¥å†æ•°æ®...", task_category=task_cat)
            start_date = datetime.now().strftime('%Y-%m-%d')
            raw_items = []
            
            movies = self.trakt_manager.get_upcoming_calendar_raw('movies', start_date, filters['fetch_days'])
            if movies:
                for item in movies: item['media_type'] = 'movie'
                raw_items.extend(movies)
            
            shows = self.trakt_manager.get_upcoming_calendar_raw('shows', start_date, filters['fetch_days'])
            if shows:
                new_shows = [item for item in shows if item.get('episode', {}).get('episode_type') == 'series_premiere']
                for item in new_shows: item['media_type'] = 'tv'
                raw_items.extend(new_shows)
            
            ui_logger.info(f"âœ… [æ­¥éª¤ 1/3] å®Œæˆã€‚å…±è·å–åˆ° {len(raw_items)} æ¡åŸå§‹è®°å½•ã€‚", task_category=task_cat)

            filtered_items = self._apply_3d_filtering(raw_items, filters)

            ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 3/3] å¼€å§‹ä» TMDB è·å– {len(filtered_items)} ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¸­æ–‡ä¿¡æ¯ (å°†è·³è¿‡å·²æœ‰ç¼“å­˜)...", task_category=task_cat)
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¼•å…¥è®¡æ•°å™¨ ---
            new_items_count = 0
            skipped_items_count = 0
            # --- ä¿®æ”¹ç»“æŸ ---
            for item in filtered_items:
                tmdb_id_str = str(item['tmdb_id'])
                if tmdb_id_str in db_content['data']:
                    logging.debug(f"  - [è·³è¿‡] TMDB ID: {tmdb_id_str} å·²å­˜åœ¨äºæœ¬åœ°æ•°æ®åº“ã€‚")
                    # æ›´æ–°ä¸Šæ˜ æ—¥æœŸï¼Œä»¥é˜² Trakt æ•°æ®æœ‰å˜
                    db_content['data'][tmdb_id_str]['release_date'] = item['release_date']
                    continue
                
                try:
                    endpoint = f"{item['media_type']}/{item['tmdb_id']}"
                    params = {'language': 'zh-CN', 'append_to_response': 'images'}
                    details = self.tmdb_logic._tmdb_request(endpoint, params)
                    
                    if not details.get('poster_path'):
                        skipped_items_count += 1
                        item_title = details.get('title') or details.get('name', f"ID: {tmdb_id_str}")
                        logging.debug(f"  - [ä¸¢å¼ƒ-è°ƒè¯•] TMDB ID: {tmdb_id_str} (ã€Š{item_title}ã€‹) å› ç¼ºå°‘ poster_path è€Œè¢«å¿½ç•¥ã€‚")
                        continue
                    
                    raw_genres = [genre['name'] for genre in details.get('genres', [])]
                    genres = [
                        "ç§‘å¹»å¥‡å¹»" if g == "Sci-Fi & Fantasy" else g
                        for g in raw_genres
                    ]
                    origin_country = details.get('origin_country', [])
                    popularity = details.get('popularity', 0)
                    # --- æ–°å¢ç»“æŸ ---

                    db_content['data'][tmdb_id_str] = {
                        "tmdb_id": details['id'],
                        "media_type": item['media_type'],
                        "title": details.get('title') or details.get('name'),
                        "overview": details.get('overview'),
                        "poster_path": details.get('poster_path'),
                        "release_date": item['release_date'],
                        "is_subscribed": False,
                        "subscribed_at": None,
                        # --- æ–°å¢ï¼šä¿å­˜æ–°å­—æ®µ ---
                        "genres": genres,
                        "origin_country": origin_country,
                        "popularity": popularity
                        # --- æ–°å¢ç»“æŸ ---
                    }
                    new_items_count += 1
                    logging.debug(f"  - [æ–°å¢] æˆåŠŸè·å– TMDB ID: {tmdb_id_str} çš„æ•°æ®ã€‚")
                    time.sleep(0.1)
                except Exception as e:
                    logging.error(f"è·å– TMDB è¯¦æƒ…å¤±è´¥ (ID: {item['tmdb_id']}): {e}")
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ„å»ºæœ€ç»ˆçš„æ±‡æ€»æ—¥å¿— ---
            summary_log = f"âœ… [æ­¥éª¤ 3/3] å®Œæˆã€‚æ–°å¢äº† {new_items_count} æ¡é«˜è´¨é‡ç»“æœåˆ°æ•°æ®åº“ã€‚"
            if skipped_items_count > 0:
                summary_log += f" è·³è¿‡äº† {skipped_items_count} æ¡ (å› TMDBæ•°æ®ä¸å®Œæ•´)ã€‚"
            ui_logger.info(summary_log, task_category=task_cat)
            # --- ä¿®æ”¹ç»“æŸ ---
            
            db_content['timestamp'] = datetime.now(timezone.utc).isoformat()
            self._write_db(db_content)
            ui_logger.info(f"ğŸ‰ æ•°æ®åº“æ›´æ–°å®Œæ¯•ï¼Trakt æ—¥å†ç¼“å­˜æ—¶é—´æˆ³å·²åˆ·æ–°ã€‚", task_category=task_cat)

        today_str = datetime.now().strftime('%Y-%m-%d')
        final_list = [
            item for item in db_content['data'].values() 
            if item.get('release_date') and item['release_date'] >= today_str
        ]
        return sorted(final_list, key=lambda x: (x['release_date'], -x.get('popularity', 0)))

    def get_all_data(self) -> List[Dict]:
        """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æœªè¿‡æœŸçš„é¡¹ç›®"""
        # --- æ–°å¢ ---
        task_cat = "å³å°†ä¸Šæ˜ -è·å–"
        ui_logger.info("â¡ï¸ [æ ¸å¿ƒå…¥å£] get_all_data è¢«è°ƒç”¨ (ä»…è¯»å–æœ¬åœ°æ•°æ®åº“)ã€‚", task_category=task_cat)
        # --- æ–°å¢ç»“æŸ ---
        db_content = self._read_db()
        today_str = datetime.now().strftime('%Y-%m-%d')
        final_list = [
            item for item in db_content['data'].values() 
            if item.get('release_date') and item['release_date'] >= today_str
        ]
        return sorted(final_list, key=lambda x: (x['release_date'], -x.get('popularity', 0)))


    def update_subscription(self, tmdb_id: int, subscribe: bool) -> bool:
        task_cat = "å³å°†ä¸Šæ˜ -è®¢é˜…"
        try:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°† FileLock ç§»åˆ°è¿™é‡Œï¼Œå¹¶ç®¡ç†å®Œæ•´çš„è¯»-æ”¹-å†™äº‹åŠ¡ ---
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=10):
                db_content = self._read_db()
                tmdb_id_str = str(tmdb_id)
                
                if tmdb_id_str not in db_content['data']:
                    ui_logger.error(f"âŒ æ“ä½œå¤±è´¥ï¼šæ•°æ®åº“ä¸­æœªæ‰¾åˆ° TMDB ID ä¸º {tmdb_id} çš„é¡¹ç›®ã€‚", task_category=task_cat)
                    return False
                
                item = db_content['data'][tmdb_id_str]
                item['is_subscribed'] = subscribe
                item['subscribed_at'] = datetime.now(timezone.utc).isoformat() if subscribe else None
                
                # ç›´æ¥åœ¨è¿™é‡Œå†™å…¥ï¼Œè€Œä¸æ˜¯è°ƒç”¨ _write_db
                with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                    json.dump(db_content, f, ensure_ascii=False, indent=4)
            # --- ä¿®æ”¹ç»“æŸ ---
                
            action_text = "è®¢é˜…" if subscribe else "å–æ¶ˆè®¢é˜…"
            ui_logger.info(f"âœ… æˆåŠŸ{action_text}ã€Š{item['title']}ã€‹ï¼", task_category=task_cat)
            return True
        except Timeout:
            ui_logger.error("âŒ æ“ä½œå¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€è¿›ç¨‹å¯èƒ½æ­£åœ¨æ“ä½œæ•°æ®åº“ã€‚", task_category=task_cat)
            return False
        except Exception as e:
            ui_logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", task_category=task_cat)
            return False

    def check_and_notify(self):
        task_cat = "å®šæ—¶ä»»åŠ¡-è®¢é˜…é€šçŸ¥"
        ui_logger.info("â¡ï¸ å¼€å§‹æ£€æŸ¥è®¢é˜…åˆ—è¡¨å¹¶å‘é€é€šçŸ¥...", task_category=task_cat)
        
        if not self.app_config.telegram_config.enabled:
            ui_logger.warning("âš ï¸ Telegram é€šçŸ¥æœªå¯ç”¨ï¼Œä»»åŠ¡è·³è¿‡ã€‚", task_category=task_cat)
            return

        db_content = self._read_db()
        subs = [item for item in db_content['data'].values() if item.get('is_subscribed')]
        
        if not subs:
            ui_logger.info("âœ… è®¢é˜…åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€å‘é€é€šçŸ¥ã€‚", task_category=task_cat)
            return

        today = datetime.now().date()
        notifications = {0: [], 1: [], 2: [], 3: []}

        for item_info in subs:
            try:
                release_date = datetime.strptime(item_info['release_date'], '%Y-%m-%d').date()
                delta_days = (release_date - today).days
                
                if 0 <= delta_days <= 3:
                    notifications[delta_days].append(item_info['title'])
            except (ValueError, KeyError):
                continue
        
        message_parts = []
        if notifications[0]:
            titles = "ã€".join([f"ã€Š{escape_markdown(t)}ã€‹" for t in notifications[0]])
            message_parts.append(f"ğŸ‰ *ä»Šæ—¥é¦–æ˜ *\n{titles}")
        
        upcoming_parts = []
        if notifications[1]:
            titles = "ã€".join([f"ã€Š{escape_markdown(t)}ã€‹" for t in notifications[1]])
            upcoming_parts.append(f"æ˜å¤©: {titles}")
        if notifications[2]:
            titles = "ã€".join([f"ã€Š{escape_markdown(t)}ã€‹" for t in notifications[2]])
            upcoming_parts.append(f"åå¤©: {titles}")
        if notifications[3]:
            titles = "ã€".join([f"ã€Š{escape_markdown(t)}ã€‹" for t in notifications[3]])
            upcoming_parts.append(f"3å¤©å: {titles}")
        
        if upcoming_parts:
            message_parts.append(f"ğŸ“… *å³å°†ä¸Šæ˜ *\n- " + "\n- ".join(upcoming_parts))

        if not message_parts:
            ui_logger.info("âœ… æ£€æŸ¥å®Œæ¯•ï¼Œæœªæ¥3å¤©å†…æ²¡æœ‰å³å°†ä¸Šæ˜ çš„è®¢é˜…é¡¹ç›®ã€‚", task_category=task_cat)
            return
            
        final_message = "ğŸ”” *è®¢é˜…æ—¥å†æé†’*\n\n" + "\n\n".join(message_parts)
        notification_manager.send_telegram_message(final_message, self.app_config)
        ui_logger.info("âœ… æˆåŠŸå‘é€è®¢é˜…é€šçŸ¥ï¼", task_category=task_cat)

    # backend/upcoming_logic.py (å‡½æ•°æ›¿æ¢)

    def prune_expired_items(self):
        """å®šæ—¶æ¸…ç†ä»»åŠ¡çš„æ‰§è¡Œé€»è¾‘"""
        task_cat = "å®šæ—¶ä»»åŠ¡-è®¢é˜…æ¸…ç†"
        ui_logger.info("â¡ï¸ å¼€å§‹æ‰§è¡Œè®¢é˜…åˆ—è¡¨è¿‡æœŸé¡¹ç›®æ¸…ç†ä»»åŠ¡...", task_category=task_cat)
        
        try:
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=30):
                db_content = self._read_db()
                if not db_content['data']:
                    ui_logger.info("âœ… æ•°æ®åº“ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†ã€‚", task_category=task_cat)
                    return

                original_count = len(db_content['data'])
                today_str = datetime.now().strftime('%Y-%m-%d')
                
                items_to_keep = {
                    tmdb_id: item for tmdb_id, item in db_content['data'].items()
                    if item.get('release_date') and item['release_date'] >= today_str
                }
                
                pruned_count = original_count - len(items_to_keep)
                
                if pruned_count > 0:
                    db_content['data'] = items_to_keep
                    # --- æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥å†™å…¥ï¼Œä¸å†è°ƒç”¨ _write_db ---
                    with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                        json.dump(db_content, f, ensure_ascii=False, indent=4)
                    ui_logger.info(f"âœ… æ¸…ç†å®Œæˆï¼å…±ç§»é™¤äº† {pruned_count} ä¸ªå·²ä¸Šæ˜ çš„è¿‡æœŸé¡¹ç›®ã€‚", task_category=task_cat)
                else:
                    ui_logger.info("âœ… æ£€æŸ¥å®Œæˆï¼Œæ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„è¿‡æœŸé¡¹ç›®ã€‚", task_category=task_cat)

        except Timeout:
            ui_logger.error("âŒ æ¸…ç†ä»»åŠ¡å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒ æ¸…ç†ä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)