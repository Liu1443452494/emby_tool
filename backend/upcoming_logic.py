# backend/upcoming_logic.py (å®Œæ•´æ–‡ä»¶è¦†ç›–)

import logging
import os
import json
import time
from typing import Dict, Any, Optional, List, Literal, Tuple
from datetime import datetime, timedelta, timezone
from filelock import FileLock, Timeout

from models import AppConfig
from log_manager import ui_logger
from trakt_manager import TraktManager
from tmdb_logic import TmdbLogic
from notification_manager import notification_manager, escape_markdown

# --- ä¿®æ”¹ï¼šç§»é™¤è®¢é˜…æ–‡ä»¶å¸¸é‡ï¼Œä¿®æ”¹ç¼“å­˜æ–‡ä»¶å¸¸é‡ ---
UPCOMING_DB_FILE = os.path.join('/app/data', 'upcoming_database.json')
# --- ä¿®æ”¹ç»“æŸ ---
CACHE_DURATION_HOURS = 12

class UpcomingLogic:
    def __init__(self, app_config: AppConfig):
        self.app_config = app_config
        self.config = app_config.upcoming_config
        self.trakt_manager = TraktManager(app_config)
        self.tmdb_logic = TmdbLogic(app_config)

    def _read_db(self) -> Dict:
        """å®‰å…¨åœ°è¯»å–æ•°æ®åº“æ–‡ä»¶"""
        if not os.path.exists(UPCOMING_DB_FILE):
            return {"timestamp": None, "data": {}}
        try:
            with open(UPCOMING_DB_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                if not content:
                    return {"timestamp": None, "data": {}}
                return json.loads(content)
        except (IOError, json.JSONDecodeError):
            return {"timestamp": None, "data": {}}

    

    def _write_db(self, db_content: Dict):
        """å®‰å…¨åœ°å†™å…¥æ•°æ®åº“æ–‡ä»¶"""
        task_cat = "å³å°†ä¸Šæ˜ -æ•°æ®åº“"
        try:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šç§»é™¤è¿™é‡Œçš„ with FileLock ---
            with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                json.dump(db_content, f, ensure_ascii=False, indent=4)
        except Exception as e:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒæ•´æ—¥å¿—ï¼Œå› ä¸ºé”çš„é”™è¯¯ä¼šåœ¨è°ƒç”¨æ–¹è¢«æ•è· ---
            ui_logger.error(f"âŒ å†™å…¥æ•°æ®åº“æ—¶å‘ç”ŸIOé”™è¯¯: {e}", task_category=task_cat)
            raise # æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†

    def _is_cache_valid(self, db_content: Dict) -> Tuple[bool, str]:
        """æ£€æŸ¥ Trakt ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        timestamp_str = db_content.get("timestamp")
        if not timestamp_str:
            return False, "æ— æœ‰æ•ˆæ—¶é—´æˆ³"
        
        try:
            timestamp = datetime.fromisoformat(timestamp_str)
            age = datetime.now(timezone.utc) - timestamp
            
            if age < timedelta(hours=CACHE_DURATION_HOURS):
                remaining_time = timedelta(hours=CACHE_DURATION_HOURS) - age
                remaining_hours = int(remaining_time.total_seconds() // 3600)
                remaining_minutes = int((remaining_time.total_seconds() % 3600) // 60)
                if remaining_hours > 0:
                    return True, f"æœ‰æ•ˆæœŸå‰©ä½™çº¦ {remaining_hours} å°æ—¶ {remaining_minutes} åˆ†é’Ÿ"
                else:
                    return True, f"æœ‰æ•ˆæœŸå‰©ä½™çº¦ {remaining_minutes} åˆ†é’Ÿ"
            else:
                return False, f"ç¼“å­˜å·²äºçº¦ {int(age.total_seconds() // 3600 - CACHE_DURATION_HOURS)} å°æ—¶å‰è¿‡æœŸ"
        except ValueError:
            return False, "æ—¶é—´æˆ³æ ¼å¼æ— æ•ˆ"

    def _apply_3d_filtering(self, raw_items: List[Dict], filters: Dict) -> List[Dict]:
        task_cat = "å³å°†ä¸Šæ˜ -ç­›é€‰"
        ui_logger.info("â¡ï¸ [æ­¥éª¤ 2/3] å¼€å§‹åº”ç”¨ä¸‰ç»´åˆ†å±‚é¢„ç­›é€‰ç­–ç•¥...", task_category=task_cat)
        
        verified_items = []
        processed_ids = set()

        for item in raw_items:
            media_type = item.get('media_type')
            media_info = item.get('movie') if media_type == 'movie' else item.get('show')
            if not media_info: continue

            tmdb_id = media_info.get('ids', {}).get('tmdb')
            if not tmdb_id or tmdb_id in processed_ids: continue
            
            title = media_info.get('original_title') or media_info.get('title', 'N/A')
            
            genres = media_info.get('genres', [])
            if any(genre in filters['genre_blacklist'] for genre in genres):
                logging.debug(f"  - [ä¸¢å¼ƒ] {title}: ç±»å‹åœ¨é»‘åå•ä¸­ ({genres})")
                continue

            country = media_info.get('country', '')
            language = media_info.get('language', '')
            translations = media_info.get('available_translations', [])

            is_p0 = (country in filters['p0_countries']) or (language in filters['p0_languages'])
            is_p1 = (country in filters['p1_countries']) and ('zh' in translations)

            if is_p0 or is_p1:
                reason = "æ ¸å¿ƒå¸‚åœº" if is_p0 else "æ½œåŠ›å¸‚åœº"
                logging.debug(f"  - [ä¿ç•™] {title}: {reason}")
                
                release_date = item.get('released') or item.get('first_aired')
                if release_date:
                    release_date_str = datetime.fromisoformat(release_date.replace('Z', '+00:00')).strftime('%Y-%m-%d')
                    verified_items.append({'tmdb_id': tmdb_id, 'media_type': media_type, 'release_date': release_date_str, 'is_ignored': False})
                    processed_ids.add(tmdb_id)
            else:
                logging.debug(f"  - [ä¸¢å¼ƒ] {title}: ä½ä¼˜å…ˆçº§ (å›½å®¶: {country}, è¯­è¨€: {language})")

        ui_logger.info(f"âœ… [æ­¥éª¤ 2/3] é¢„ç­›é€‰å®Œæˆã€‚å€™é€‰æ¡ç›®ä» {len(raw_items)} ä¸ªå‡å°‘åˆ° {len(verified_items)} ä¸ªã€‚", task_category=task_cat)
        return verified_items

    def get_upcoming_list(self, dynamic_filters: Optional[Dict] = None) -> List[Dict]:
        task_cat = "å³å°†ä¸Šæ˜ -è·å–"
        ui_logger.info(f"â¡ï¸ [æ ¸å¿ƒå…¥å£] get_upcoming_list è¢«è°ƒç”¨ã€‚å¼ºåˆ¶åˆ·æ–°: {bool(dynamic_filters and not dynamic_filters.get('use_defaults', True))}", task_category=task_cat)
        filters = self.config.filters.model_dump()
        force_refresh = False
        if dynamic_filters and not dynamic_filters.get('use_defaults', True):
            ui_logger.info("ğŸ” æ£€æµ‹åˆ°åŠ¨æ€ç­›é€‰æ¡ä»¶ï¼Œå°†å¼ºåˆ¶åˆ·æ–°ã€‚", task_category=task_cat)
            force_refresh = True
            for key, value in dynamic_filters.items():
                if key in filters:
                    filters[key] = value
        
        db_content = self._read_db()
        is_valid, reason = self._is_cache_valid(db_content)

        if is_valid and not force_refresh:
            ui_logger.info(f"âœ… å‘½ä¸­ Trakt æ—¥å†ç¼“å­˜ï¼{reason}ã€‚", task_category=task_cat)
        else:
            if force_refresh:
                ui_logger.info("ğŸ”„ ç”¨æˆ·è¯·æ±‚åº”ç”¨æ–°ç­›é€‰æ¡ä»¶ï¼Œå¼ºåˆ¶ä» Trakt åˆ·æ–°...", task_category=task_cat)
            else:
                ui_logger.warning(f"âš ï¸ Trakt æ—¥å†ç¼“å­˜å·²å¤±æ•ˆ ({reason})ï¼Œå¼€å§‹ä» Trakt åˆ·æ–°...", task_category=task_cat)

            ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 1/3] å¼€å§‹ä» Trakt è·å–æœªæ¥ {filters['fetch_days']} å¤©çš„æ—¥å†æ•°æ®...", task_category=task_cat)
            start_date = datetime.now().strftime('%Y-%m-%d')
            raw_items = []
            
            movies = self.trakt_manager.get_upcoming_calendar_raw('movies', start_date, filters['fetch_days'])
            if movies:
                for item in movies: item['media_type'] = 'movie'
                raw_items.extend(movies)
            
            shows = self.trakt_manager.get_upcoming_calendar_raw('shows', start_date, filters['fetch_days'])
            if shows:
                new_shows = [item for item in shows if item.get('episode', {}).get('episode_type') == 'series_premiere']
                for item in new_shows: item['media_type'] = 'tv'
                raw_items.extend(new_shows)
            
            ui_logger.info(f"âœ… [æ­¥éª¤ 1/3] å®Œæˆã€‚å…±è·å–åˆ° {len(raw_items)} æ¡åŸå§‹è®°å½•ã€‚", task_category=task_cat)

            filtered_items = self._apply_3d_filtering(raw_items, filters)

            ui_logger.info(f"â¡ï¸ [æ­¥éª¤ 3/3] å¼€å§‹ä» TMDB è·å– {len(filtered_items)} ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¸­æ–‡ä¿¡æ¯ (å°†è·³è¿‡å·²æœ‰ç¼“å­˜)...", task_category=task_cat)
            new_items_count = 0
            skipped_items_count = 0
            

            for item in filtered_items:
                tmdb_id_str = str(item['tmdb_id'])
                if tmdb_id_str in db_content['data']:
                    logging.debug(f"  - [è·³è¿‡] TMDB ID: {tmdb_id_str} å·²å­˜åœ¨äºæœ¬åœ°æ•°æ®åº“ã€‚")
                    db_content['data'][tmdb_id_str]['release_date'] = item['release_date']
                    continue
                
                try:
                    endpoint = f"{item['media_type']}/{item['tmdb_id']}"
                    params = {'language': 'zh-CN', 'append_to_response': 'images,credits'}
                    details = self.tmdb_logic._tmdb_request(endpoint, params)
                    
                    if not details.get('poster_path'):
                        skipped_items_count += 1
                        item_title = details.get('title') or details.get('name', f"ID: {tmdb_id_str}")
                        logging.debug(f"  - [ä¸¢å¼ƒ-è°ƒè¯•] TMDB ID: {tmdb_id_str} (ã€Š{item_title}ã€‹) å› ç¼ºå°‘ poster_path è€Œè¢«å¿½ç•¥ã€‚")
                        continue
                    
                    raw_genres = [genre['name'] for genre in details.get('genres', [])]
                    genres = [
                        "ç§‘å¹»å¥‡å¹»" if g == "Sci-Fi & Fantasy" else g
                        for g in raw_genres
                    ]
                    origin_country = details.get('origin_country', [])
                    popularity = details.get('popularity', 0)
                    cast = details.get('credits', {}).get('cast', [])
                    actors = [actor['name'] for actor in cast[:6]]

                    db_content['data'][tmdb_id_str] = {
                        "tmdb_id": details['id'],
                        "media_type": item['media_type'],
                        "title": details.get('title') or details.get('name'),
                        "overview": details.get('overview'),
                        "poster_path": details.get('poster_path'),
                        "release_date": item['release_date'],
                        "is_subscribed": False,
                        "subscribed_at": None,
                        "genres": genres,
                        "origin_country": origin_country,
                        "popularity": popularity,
                        "actors": actors,
                        "is_permanent": False,
                        "is_ignored": False
                    }
                    new_items_count += 1
                    logging.debug(f"  - [æ–°å¢] æˆåŠŸè·å– TMDB ID: {tmdb_id_str} çš„æ•°æ®ã€‚")
                    time.sleep(0.1)
                except Exception as e:
                    logging.error(f"è·å– TMDB è¯¦æƒ…å¤±è´¥ (ID: {item['tmdb_id']}): {e}")
            
            summary_log = f"âœ… [æ­¥éª¤ 3/3] å®Œæˆã€‚æ–°å¢äº† {new_items_count} æ¡é«˜è´¨é‡ç»“æœåˆ°æ•°æ®åº“ã€‚"
            if skipped_items_count > 0:
                summary_log += f" è·³è¿‡äº† {skipped_items_count} æ¡ (å› TMDBæ•°æ®ä¸å®Œæ•´)ã€‚"
            ui_logger.info(summary_log, task_category=task_cat)

            rules = self.config.auto_subscribe_rules
            if rules.enabled:
                ui_logger.info("â¡ï¸ [æ­¥éª¤ 4/4] å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–è®¢é˜…...", task_category=task_cat)
                auto_subscribed_count = 0
                
                rule_actors = {actor.strip().lower() for actor in rules.actors if actor.strip()}
                rule_countries = {country.strip().lower() for country in rules.countries if country.strip()}

                if not rule_actors and (not rule_countries or rules.min_popularity <= 0):
                     ui_logger.warning("   - [è·³è¿‡] è‡ªåŠ¨åŒ–è®¢é˜…å·²å¯ç”¨ï¼Œä½†æœªé…ç½®ä»»ä½•æœ‰æ•ˆè§„åˆ™ã€‚", task_category=task_cat)
                else:
                    today = datetime.now(timezone.utc).date()
                    for item in db_content['data'].values():
                        if item.get('is_subscribed'):
                            continue

                        try:
                            release_date_str = item.get('release_date')
                            if not release_date_str:
                                logging.debug(f"   - [è·³è¿‡-è‡ªåŠ¨è®¢é˜…]ã€Š{item.get('title', 'æœªçŸ¥')}ã€‹å› ç¼ºå°‘ä¸Šæ˜ æ—¥æœŸè€Œè¢«å¿½ç•¥ã€‚")
                                continue
                            
                            item_release_date = datetime.fromisoformat(release_date_str).date()
                            
                            if item_release_date < today:
                                logging.debug(f"   - [è·³è¿‡-è‡ªåŠ¨è®¢é˜…]ã€Š{item.get('title', 'æœªçŸ¥')}ã€‹å› å·²ä¸Šæ˜  (æ—¥æœŸ: {release_date_str}) è€Œè¢«å¿½ç•¥ã€‚")
                                continue
                        except (ValueError, TypeError):
                            logging.debug(f"   - [è·³è¿‡-è‡ªåŠ¨è®¢é˜…]ã€Š{item.get('title', 'æœªçŸ¥')}ã€‹å› æ—¥æœŸæ ¼å¼æ— æ•ˆ ({item.get('release_date')}) è€Œè¢«å¿½ç•¥ã€‚")
                            continue

                        if rule_actors:
                            item_actors_lower = {actor.lower() for actor in item.get('actors', [])}
                            matched_actors = rule_actors.intersection(item_actors_lower)
                            if matched_actors:
                                item['is_subscribed'] = True
                                item['subscribed_at'] = datetime.now(timezone.utc).isoformat()
                                auto_subscribed_count += 1
                                ui_logger.info(f"   - âœ… è‡ªåŠ¨è®¢é˜…ã€Š{item['title']}ã€‹ï¼ŒåŸå› ï¼šåŒ¹é…åˆ°æ¼”å‘˜å…³é”®è¯ '{next(iter(matched_actors))}'ã€‚", task_category=task_cat)
                                continue

                        if rule_countries and rules.min_popularity > 0:
                            item_countries_lower = {country.lower() for country in item.get('origin_country', [])}
                            if item_countries_lower.intersection(rule_countries):
                                if item.get('popularity', 0) >= rules.min_popularity:
                                    item['is_subscribed'] = True
                                    item['subscribed_at'] = datetime.now(timezone.utc).isoformat()
                                    auto_subscribed_count += 1
                                    ui_logger.info(f"   - âœ… è‡ªåŠ¨è®¢é˜…ã€Š{item['title']}ã€‹ï¼ŒåŸå› ï¼šæ»¡è¶³å›½å®¶åŒ¹é…ä¸”çƒ­é—¨åº¦ ({item.get('popularity', 0):.2f}) >= {rules.min_popularity}ã€‚", task_category=task_cat)
                    
                    if auto_subscribed_count > 0:
                        ui_logger.info(f"ğŸ‰ [æ­¥éª¤ 4/4] è‡ªåŠ¨åŒ–è®¢é˜…å®Œæˆï¼Œå…±æ–°å¢ {auto_subscribed_count} ä¸ªè®¢é˜…ã€‚", task_category=task_cat)
                    else:
                        ui_logger.info("   - [æ­¥éª¤ 4/4] è‡ªåŠ¨åŒ–è®¢é˜…æ£€æŸ¥å®Œæˆï¼Œæ²¡æœ‰å‘ç°ç¬¦åˆæ¡ä»¶çš„æ–°é¡¹ç›®ã€‚", task_category=task_cat)
            
            db_content['timestamp'] = datetime.now(timezone.utc).isoformat()
            self._write_db(db_content)
            ui_logger.info(f"ğŸ‰ æ•°æ®åº“æ›´æ–°å®Œæ¯•ï¼Trakt æ—¥å†ç¼“å­˜æ—¶é—´æˆ³å·²åˆ·æ–°ã€‚", task_category=task_cat)

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåº”ç”¨ä¸¤æ­¥è¿‡æ»¤ ---
        # æ­¥éª¤ 1: é¢„è¿‡æ»¤ï¼Œç§»é™¤ä¸æ„Ÿå…´è¶£çš„é¡¹ç›®
        pre_filtered_data = [
            item for item in db_content['data'].values()
            if not item.get('is_ignored', False)
        ]
        
        # æ­¥éª¤ 2: åœ¨é¢„è¿‡æ»¤ç»“æœä¸Šåº”ç”¨ç°æœ‰çš„ä¿ç•™é€»è¾‘
        today_str = datetime.now().strftime('%Y-%m-%d')
        final_list = [
            item for item in pre_filtered_data
            if item.get('is_permanent', False) or (item.get('release_date') and item['release_date'] >= today_str)
        ]
        # --- ä¿®æ”¹ç»“æŸ ---
        
        return sorted(final_list, key=lambda x: (x['release_date'], -x.get('popularity', 0)))


    def get_all_data(self) -> List[Dict]:
        """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰å¯¹å‰ç«¯å¯è§çš„é¡¹ç›®"""
        task_cat = "å³å°†ä¸Šæ˜ -è·å–"
        ui_logger.info("â¡ï¸ [æ ¸å¿ƒå…¥å£] get_all_data è¢«è°ƒç”¨ (ä»…è¯»å–æœ¬åœ°æ•°æ®åº“)ã€‚", task_category=task_cat)
        db_content = self._read_db()
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåº”ç”¨ä¸¤æ­¥è¿‡æ»¤ ---
        # æ­¥éª¤ 1: é¢„è¿‡æ»¤ï¼Œç§»é™¤ä¸æ„Ÿå…´è¶£çš„é¡¹ç›®
        pre_filtered_data = [
            item for item in db_content['data'].values()
            if not item.get('is_ignored', False)
        ]
        
        # æ­¥éª¤ 2: åœ¨é¢„è¿‡æ»¤ç»“æœä¸Šåº”ç”¨ç°æœ‰çš„ä¿ç•™é€»è¾‘
        today_str = datetime.now().strftime('%Y-%m-%d')
        final_list = [
            item for item in pre_filtered_data
            if item.get('is_permanent', False) or (item.get('release_date') and item['release_date'] >= today_str)
        ]
        # --- ä¿®æ”¹ç»“æŸ ---
        
        return sorted(final_list, key=lambda x: (x['release_date'], -x.get('popularity', 0)))


    def update_subscription(self, tmdb_id: int, subscribe: bool) -> bool:
        task_cat = "å³å°†ä¸Šæ˜ -è®¢é˜…"
        try:
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°† FileLock ç§»åˆ°è¿™é‡Œï¼Œå¹¶ç®¡ç†å®Œæ•´çš„è¯»-æ”¹-å†™äº‹åŠ¡ ---
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=10):
                db_content = self._read_db()
                tmdb_id_str = str(tmdb_id)
                
                if tmdb_id_str not in db_content['data']:
                    ui_logger.error(f"âŒ æ“ä½œå¤±è´¥ï¼šæ•°æ®åº“ä¸­æœªæ‰¾åˆ° TMDB ID ä¸º {tmdb_id} çš„é¡¹ç›®ã€‚", task_category=task_cat)
                    return False
                
                item = db_content['data'][tmdb_id_str]
                item['is_subscribed'] = subscribe
                item['subscribed_at'] = datetime.now(timezone.utc).isoformat() if subscribe else None
                
                # ç›´æ¥åœ¨è¿™é‡Œå†™å…¥ï¼Œè€Œä¸æ˜¯è°ƒç”¨ _write_db
                with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                    json.dump(db_content, f, ensure_ascii=False, indent=4)
            # --- ä¿®æ”¹ç»“æŸ ---
                
            action_text = "è®¢é˜…" if subscribe else "å–æ¶ˆè®¢é˜…"
            ui_logger.info(f"âœ… æˆåŠŸ{action_text}ã€Š{item['title']}ã€‹ï¼", task_category=task_cat)
            return True
        except Timeout:
            ui_logger.error("âŒ æ“ä½œå¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€è¿›ç¨‹å¯èƒ½æ­£åœ¨æ“ä½œæ•°æ®åº“ã€‚", task_category=task_cat)
            return False
        except Exception as e:
            ui_logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", task_category=task_cat)
            return False

    def update_permanence(self, tmdb_id: int, is_permanent: bool) -> bool:
        task_cat = "å³å°†ä¸Šæ˜ -æ”¶è—"
        try:
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=10):
                db_content = self._read_db()
                tmdb_id_str = str(tmdb_id)
                
                if tmdb_id_str not in db_content['data']:
                    ui_logger.error(f"âŒ æ“ä½œå¤±è´¥ï¼šæ•°æ®åº“ä¸­æœªæ‰¾åˆ° TMDB ID ä¸º {tmdb_id} çš„é¡¹ç›®ã€‚", task_category=task_cat)
                    return False
                
                item = db_content['data'][tmdb_id_str]
                item['is_permanent'] = is_permanent
                
                with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                    json.dump(db_content, f, ensure_ascii=False, indent=4)
            
            action_text = "æ°¸ä¹…æ”¶è—" if is_permanent else "å–æ¶ˆæ”¶è—"
            ui_logger.info(f"âœ… æˆåŠŸ{action_text}ã€Š{item['title']}ã€‹ï¼", task_category=task_cat)
            return True
        except Timeout:
            ui_logger.error("âŒ æ“ä½œå¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ã€‚", task_category=task_cat)
            return False
        except Exception as e:
            ui_logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", task_category=task_cat)
            return False
        

    def update_ignore_status(self, tmdb_id: int) -> bool:
        """å°†æŒ‡å®šé¡¹ç›®æ ‡è®°ä¸ºä¸æ„Ÿå…´è¶£"""
        task_cat = "å³å°†ä¸Šæ˜ -å¿½ç•¥"
        try:
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=10):
                db_content = self._read_db()
                tmdb_id_str = str(tmdb_id)
                
                if tmdb_id_str not in db_content['data']:
                    ui_logger.error(f"âŒ æ“ä½œå¤±è´¥ï¼šæ•°æ®åº“ä¸­æœªæ‰¾åˆ° TMDB ID ä¸º {tmdb_id} çš„é¡¹ç›®ã€‚", task_category=task_cat)
                    return False
                
                item = db_content['data'][tmdb_id_str]
                item['is_ignored'] = True
                
                with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                    json.dump(db_content, f, ensure_ascii=False, indent=4)
            
            ui_logger.info(f"âœ… å·²å°†ã€Š{item['title']}ã€‹æ ‡è®°ä¸ºä¸æ„Ÿå…´è¶£ï¼Œå®ƒå°†ä¸å†æ˜¾ç¤ºã€‚", task_category=task_cat)
            return True
        except Timeout:
            ui_logger.error("âŒ æ“ä½œå¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€è¿›ç¨‹å¯èƒ½æ­£åœ¨æ“ä½œæ•°æ®åº“ã€‚", task_category=task_cat)
            return False
        except Exception as e:
            ui_logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", task_category=task_cat)
            return False

    def check_and_notify(self):
        task_cat = "å®šæ—¶ä»»åŠ¡-è®¢é˜…é€šçŸ¥"
        ui_logger.info("â¡ï¸ å¼€å§‹æ£€æŸ¥è®¢é˜…åˆ—è¡¨å¹¶å‘é€é€šçŸ¥...", task_category=task_cat)

        ui_logger.info("   - [æ­¥éª¤ 1/3] è‡ªåŠ¨æ£€æŸ¥å¹¶æŒ‰éœ€æ›´æ–°â€œå³å°†ä¸Šæ˜ â€æ•°æ®...", task_category=task_cat)
        # ä¼ å…¥ use_defaults: True æ¥è§¦å‘æ ‡å‡†çš„ç¼“å­˜æ£€æŸ¥é€»è¾‘
        self.get_upcoming_list(dynamic_filters={'use_defaults': True})
        ui_logger.info("   - [æ­¥éª¤ 1/3] æ•°æ®æ›´æ–°æ£€æŸ¥å®Œæˆã€‚", task_category=task_cat)
        
        if not self.app_config.telegram_config.enabled:
            ui_logger.warning("âš ï¸ Telegram é€šçŸ¥æœªå¯ç”¨ï¼Œä»»åŠ¡è·³è¿‡ã€‚", task_category=task_cat)
            return

        db_content = self._read_db()
        subs = [item for item in db_content['data'].values() if item.get('is_subscribed')]
        
        if not subs:
            ui_logger.info("âœ… è®¢é˜…åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€å‘é€é€šçŸ¥ã€‚", task_category=task_cat)
            return

        today = datetime.now().date()
        notifications = {0: [], 1: [], 2: [], 3: []}
        all_notified_items = []

        for item_info in subs:
            try:
                release_date = datetime.strptime(item_info['release_date'], '%Y-%m-%d').date()
                delta_days = (release_date - today).days
                
                if 0 <= delta_days <= 3:
                    notifications[delta_days].append(item_info)
                    all_notified_items.append(item_info)
            except (ValueError, KeyError):
                continue
        
        if not all_notified_items:
            ui_logger.info("âœ… æ£€æŸ¥å®Œæ¯•ï¼Œæœªæ¥3å¤©å†…æ²¡æœ‰å³å°†ä¸Šæ˜ çš„è®¢é˜…é¡¹ç›®ã€‚", task_category=task_cat)
            return

        hottest_item = max(all_notified_items, key=lambda x: x.get('popularity', 0))
        poster_url = f"https://image.tmdb.org/t/p/w780{hottest_item['poster_path']}" if hottest_item.get('poster_path') else None
        ui_logger.info(f"ğŸ–¼ï¸ å·²é€‰æ‹©ã€Š{hottest_item['title']}ã€‹ä½œä¸ºå°é¢æµ·æŠ¥ (çƒ­åº¦: {hottest_item.get('popularity', 0):.2f})ã€‚", task_category=task_cat)

        message_parts = []
        day_map = {0: "ä»Šæ—¥é¦–æ˜ ", 1: "æ˜æ—¥ä¸Šæ˜ ", 2: "åå¤©ä¸Šæ˜ ", 3: "3å¤©åä¸Šæ˜ "}
        
        for day, items in notifications.items():
            if not items:
                continue
            
            date_obj = today + timedelta(days=day)
            date_str = date_obj.strftime('%Y-%m-%d')
            
            header = f"ğŸ‰ *{day_map[day]}* `({date_str})`"
            
            item_details_parts = []
            for item in sorted(items, key=lambda x: -x.get('popularity', 0)):
                title = escape_markdown(item['title'])
                year = escape_markdown(f"({item['release_date'][:4]})") if item.get('release_date') else ""
                actors = " / ".join(item.get('actors', []))
                actors_line = f" \- {escape_markdown(actors)}" if actors else ""
                
                item_details_parts.append(f"ã€Š{title}ã€‹{year}{actors_line}")

            message_parts.append(header + "\n" + "\n".join(item_details_parts))

        final_caption = "ğŸ”” *è®¢é˜…æ—¥å†æé†’*\n\n" + "\n\n".join(message_parts)
        
        result = None
        if poster_url:
            try:
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨æ­¤å¤„ä¸‹è½½å›¾ç‰‡ ---
                import requests
                from proxy_manager import ProxyManager
                proxy_manager = ProxyManager(self.app_config)
                image_proxies = proxy_manager.get_proxies(poster_url)
                ui_logger.debug(f"   - [è°ƒè¯•] æ­£åœ¨ä¸‹è½½å°é¢å›¾ç‰‡: {poster_url}", task_category=task_cat)
                response_img = requests.get(poster_url, timeout=30, proxies=image_proxies)
                response_img.raise_for_status()
                image_bytes = response_img.content
                # --- ä¸‹è½½ç»“æŸ ---

                # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°†ä¸‹è½½å¥½çš„äºŒè¿›åˆ¶æ•°æ®ä¼ é€’ç»™é€šçŸ¥å‡½æ•° ---
                result = notification_manager.send_telegram_photo_notification(
                    image_source=image_bytes,
                    caption=final_caption,
                    app_config=self.app_config
                )
            except Exception as e:
                ui_logger.error(f"âŒ ä¸‹è½½å°é¢å›¾ç‰‡æˆ–å‘é€é€šçŸ¥æ—¶å¤±è´¥: {e}ã€‚å°†é™çº§ä¸ºçº¯æ–‡æœ¬é€šçŸ¥ã€‚", task_category=task_cat, exc_info=True)
                # å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œresult ä¿æŒä¸º Noneï¼Œä¼šè§¦å‘ä¸‹é¢çš„é™çº§é€»è¾‘
        
        # å¦‚æœæ²¡æœ‰æµ·æŠ¥URLï¼Œæˆ–è€…å›¾ç‰‡ä¸‹è½½/å‘é€å¤±è´¥ï¼Œåˆ™é™çº§ä¸ºçº¯æ–‡æœ¬
        if result is None:
            if poster_url: # ä»…åœ¨ä¸‹è½½å¤±è´¥æ—¶æ‰“å°é™çº§æ—¥å¿—
                 ui_logger.warning("âš ï¸ å°é¢é¡¹ç›®å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬é€šçŸ¥ã€‚", task_category=task_cat)
            else: # ä»…åœ¨é¡¹ç›®æœ¬èº«æ— æµ·æŠ¥æ—¶æ‰“å°
                 ui_logger.warning("âš ï¸ å°é¢é¡¹ç›®ç¼ºå°‘æµ·æŠ¥ï¼Œå°†å‘é€çº¯æ–‡æœ¬é€šçŸ¥ã€‚", task_category=task_cat)
            result = notification_manager.send_telegram_message(final_caption, self.app_config)

        if result.get("success"):
            ui_logger.info("âœ… æˆåŠŸå‘é€è®¢é˜…é€šçŸ¥ï¼", task_category=task_cat)
        else:
            ui_logger.error(f"âŒ å‘é€è®¢é˜…é€šçŸ¥å¤±è´¥ï¼ŒåŸå› : {result.get('message', 'æœªçŸ¥é”™è¯¯')}", task_category=task_cat)


    def prune_expired_items(self):
        """å®šæ—¶æ¸…ç†ä»»åŠ¡çš„æ‰§è¡Œé€»è¾‘"""
        task_cat = "å®šæ—¶ä»»åŠ¡-è®¢é˜…æ¸…ç†"
        ui_logger.info("â¡ï¸ å¼€å§‹æ‰§è¡Œè®¢é˜…åˆ—è¡¨è¿‡æœŸé¡¹ç›®æ¸…ç†ä»»åŠ¡...", task_category=task_cat)
        
        try:
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=30):
                db_content = self._read_db()
                if not db_content['data']:
                    ui_logger.info("âœ… æ•°æ®åº“ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†ã€‚", task_category=task_cat)
                    return

                original_count = len(db_content['data'])
                today_str = datetime.now().strftime('%Y-%m-%d')
                
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¼•å…¥è¯¦ç»†çš„åˆ†ç±»å’Œè®¡æ•° ---
                items_to_keep = {}
                items_to_prune = []
                exempted_count = 0

                for tmdb_id, item in db_content['data'].items():
                    is_expired = item.get('release_date') and item['release_date'] < today_str
                    is_permanent = item.get('is_permanent', False)

                    if is_expired and not is_permanent:
                        items_to_prune.append(item)
                    else:
                        if is_expired and is_permanent:
                            exempted_count += 1
                            logging.debug(f"  - [è±å…]ã€Š{item.get('title', tmdb_id)}ã€‹å·²è¿‡æœŸä½†å› æ°¸ä¹…æ”¶è—è¢«ä¿ç•™ã€‚")
                        items_to_keep[tmdb_id] = item
                
                pruned_count = len(items_to_prune)
                
                if pruned_count > 0:
                    db_content['data'] = items_to_keep
                    with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                        json.dump(db_content, f, ensure_ascii=False, indent=4)
                    
                    summary_log = f"âœ… æ¸…ç†å®Œæˆï¼å…±ç§»é™¤äº† {pruned_count} ä¸ªå·²ä¸Šæ˜ çš„è¿‡æœŸé¡¹ç›®ã€‚"
                    if exempted_count > 0:
                        summary_log += f" (å¦æœ‰ {exempted_count} ä¸ªé¡¹ç›®å› æ°¸ä¹…æ”¶è—è¢«è±å…)"
                    ui_logger.info(summary_log, task_category=task_cat)
                    
                    # æ‰“å°è¢«åˆ é™¤çš„é¡¹ç›®çš„è¯¦ç»†æ—¥å¿—
                    pruned_titles = "ã€".join([f"ã€Š{item.get('title', 'æœªçŸ¥')}ã€‹" for item in items_to_prune])
                    logging.info(f"  - [è¯¦æƒ…] è¢«ç§»é™¤çš„é¡¹ç›®: {pruned_titles}")

                else:
                    summary_log = "âœ… æ£€æŸ¥å®Œæˆï¼Œæ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„è¿‡æœŸé¡¹ç›®ã€‚"
                    if exempted_count > 0:
                        summary_log += f" (æœ‰ {exempted_count} ä¸ªæ—¥æœŸè¿‡æœŸé¡¹ç›®å› æ°¸ä¹…æ”¶è—è¢«ä¿ç•™)"
                    ui_logger.info(summary_log, task_category=task_cat)
                # --- ä¿®æ”¹ç»“æŸ ---

        except Timeout:
            ui_logger.error("âŒ æ¸…ç†ä»»åŠ¡å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒ æ¸…ç†ä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)

    # backend/upcoming_logic.py (å‡½æ•°æ›¿æ¢)

    def search_tmdb(self, media_type: str, query: str) -> List[Dict]:
        """æ ¹æ®å…³é”®è¯æˆ–IDåœ¨TMDBä¸­æœç´¢åª’ä½“"""
        task_cat = "å³å°†ä¸Šæ˜ -æ‰‹åŠ¨æœç´¢"
        ui_logger.info(f"ğŸ” æ­£åœ¨ä¸º [{media_type}] æœç´¢ '{query}'...", task_category=task_cat)
        
        results = []
        # ä¼˜å…ˆå°è¯•æŒ‰ ID æœç´¢
        if query.isdigit():
            try:
                endpoint = f"{media_type}/{query}"
                params = {'language': 'zh-CN'}
                details = self.tmdb_logic._tmdb_request(endpoint, params)
                results.append(details)
                ui_logger.info(f"âœ… æŒ‰ TMDB ID '{query}' ç²¾ç¡®åŒ¹é…æˆåŠŸã€‚", task_category=task_cat)
            except Exception:
                ui_logger.warning(f"âš ï¸ æŒ‰ TMDB ID '{query}' æŸ¥æ‰¾å¤±è´¥ï¼Œå°†å°è¯•ä½œä¸ºæ ‡é¢˜è¿›è¡Œæ¨¡ç³Šæœç´¢ã€‚", task_category=task_cat)
                results = [] # æ¸…ç©ºï¼Œä»¥ä¾¿è¿›è¡Œåç»­æœç´¢

        # å¦‚æœ ID æœç´¢æ— æœæˆ– query ä¸æ˜¯æ•°å­—ï¼Œåˆ™æŒ‰æ ‡é¢˜æœç´¢
        if not results:
            try:
                endpoint = f"search/{media_type}"
                params = {'language': 'zh-CN', 'query': query}
                search_data = self.tmdb_logic._tmdb_request(endpoint, params)
                results = search_data.get('results', [])
                ui_logger.info(f"âœ… æŒ‰æ ‡é¢˜ '{query}' æœç´¢åˆ° {len(results)} ä¸ªç»“æœã€‚", task_category=task_cat)
            except Exception as e:
                ui_logger.error(f"âŒ æŒ‰æ ‡é¢˜ '{query}' æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat)
                return []
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šè¿”å›å®Œæ•´æ—¥æœŸï¼Œè€Œä¸æ˜¯åªè¿”å›å¹´ä»½ ---
        candidates = []
        for item in results:
            title = item.get('title') or item.get('name')
            release_date = item.get('release_date') or item.get('first_air_date')
            
            candidates.append({
                "tmdb_id": item.get('id'),
                "title": title,
                "release_date": release_date, # ç›´æ¥ä¼ é€’å®Œæ•´æ—¥æœŸ
                "poster_path": item.get('poster_path'),
                "overview": item.get('overview')
            })
        return candidates

    def add_permanent_item(self, tmdb_id: int, media_type: str) -> Tuple[bool, str]:
        """è·å–å•ä¸ªTMDBé¡¹ç›®çš„å®Œæ•´ä¿¡æ¯å¹¶å°†å…¶ä½œä¸ºæ°¸ä¹…æ”¶è—æ·»åŠ åˆ°æ•°æ®åº“"""
        task_cat = "å³å°†ä¸Šæ˜ -æ‰‹åŠ¨æ·»åŠ "
        try:
            # 1. è·å–å®Œæ•´ä¿¡æ¯
            ui_logger.info(f"â¡ï¸ æ­£åœ¨è·å– TMDB ID: {tmdb_id} çš„å®Œæ•´ä¿¡æ¯...", task_category=task_cat)
            endpoint = f"{media_type}/{tmdb_id}"
            params = {'language': 'zh-CN', 'append_to_response': 'images,credits'}
            details = self.tmdb_logic._tmdb_request(endpoint, params)

            # 2. æ£€æŸ¥æµ·æŠ¥
            if not details.get('poster_path'):
                msg = f"åª’ä½“ã€Š{details.get('title') or details.get('name')}ã€‹å› ç¼ºå°‘æµ·æŠ¥å›¾è€Œæ— æ³•æ·»åŠ ã€‚"
                ui_logger.warning(f"âš ï¸ {msg}", task_category=task_cat)
                return False, msg

            # 3. æ„å»ºæ•°æ®å¯¹è±¡
            raw_genres = [genre['name'] for genre in details.get('genres', [])]
            genres = ["ç§‘å¹»å¥‡å¹»" if g == "Sci-Fi & Fantasy" else g for g in raw_genres]
            origin_country = details.get('origin_country', [])
            popularity = details.get('popularity', 0)
            cast = details.get('credits', {}).get('cast', [])
            actors = [actor['name'] for actor in cast[:5]]
            release_date = details.get('release_date') or details.get('first_air_date')

            item_data = {
                "tmdb_id": details['id'],
                "media_type": media_type,
                "title": details.get('title') or details.get('name'),
                "overview": details.get('overview'),
                "poster_path": details.get('poster_path'),
                "release_date": release_date,
                "is_subscribed": False,
                "subscribed_at": None,
                "genres": genres,
                "origin_country": origin_country,
                "popularity": popularity,
                "actors": actors,
                "is_permanent": True,
                "is_ignored": False 
            }

            # 4. å†™å…¥æ•°æ®åº“
            with FileLock(UPCOMING_DB_FILE + ".lock", timeout=10):
                db_content = self._read_db()
                tmdb_id_str = str(tmdb_id)
                
                if tmdb_id_str in db_content['data']:
                    ui_logger.info(f"æ•°æ®åº“ä¸­å·²å­˜åœ¨ã€Š{item_data['title']}ã€‹ï¼Œå°†ç›´æ¥å°†å…¶è®¾ç½®ä¸ºæ°¸ä¹…æ”¶è—ã€‚", task_category=task_cat)
                    db_content['data'][tmdb_id_str]['is_permanent'] = True
                else:
                    db_content['data'][tmdb_id_str] = item_data
                
                with open(UPCOMING_DB_FILE, 'w', encoding='utf-8') as f:
                    json.dump(db_content, f, ensure_ascii=False, indent=4)
            
            msg = f"ğŸ‰ æˆåŠŸå°†ã€Š{item_data['title']}ã€‹æ·»åŠ åˆ°æ°¸ä¹…æ”¶è—ï¼"
            ui_logger.info(msg, task_category=task_cat)
            return True, msg

        except Timeout:
            msg = "æ“ä½œå¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ã€‚"
            ui_logger.error(f"âŒ {msg}", task_category=task_cat)
            return False, msg
        except Exception as e:
            msg = f"æ“ä½œå¤±è´¥: {e}"
            ui_logger.error(f"âŒ {msg}", task_category=task_cat, exc_info=True)
            return False, msg