# backend/actor_role_mapper_logic.py (æ–°æ–‡ä»¶)

import logging
import os
import json
import threading
import time
import re
import hmac
import hashlib
import base64
import subprocess
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from filelock import FileLock, Timeout

from log_manager import ui_logger
from models import AppConfig, ScheduledTasksTargetScope
from task_manager import TaskManager
from media_selector import MediaSelector
from proxy_manager import ProxyManager

ACTOR_ROLE_MAP_FILE = os.path.join('/app/data', 'actor_role_map.json')
ACTOR_ROLE_MAP_LOCK_FILE = ACTOR_ROLE_MAP_FILE + ".lock"
GITHUB_MAP_PATH = "database/actor_role_map.json"


def _contains_chinese(text: str) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    if not text: return False
    return bool(re.search(r'[\u4e00-\u9fa5]', text))



class ActorRoleMapperLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.server_config = config.server_config
        self.github_config = config.episode_refresher_config.github_config
        self.proxy_manager = ProxyManager(config)
        self.session = self._create_session()

    def _create_session(self):
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        session = requests.Session()
        retry_strategy = Retry(
            total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session

    def _get_emby_item_details(self, item_id: str, fields: str) -> Dict:
        url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
        params = {"api_key": self.server_config.api_key, "Fields": fields}
        proxies = self.proxy_manager.get_proxies(url)
        response = self.session.get(url, params=params, timeout=20, proxies=proxies)
        response.raise_for_status()
        return response.json()

    # backend/actor_role_mapper_logic.py (æ–°å¢ä»£ç å—)

    def _search_persons_by_name(self, name: str) -> List[Dict]:
        """åœ¨ Emby ä¸­æŒ‰å§“åæœç´¢æ‰€æœ‰ Person Item"""
        try:
            url = f"{self.server_config.server}/Items"
            params = {
                "api_key": self.server_config.api_key,
                "IncludeItemTypes": "Person",
                "Recursive": "true",
                "SearchTerm": name,
                "Fields": "ProviderIds" 
            }
            proxies = self.proxy_manager.get_proxies(url)
            response = self.session.get(url, params=params, timeout=20, proxies=proxies)
            response.raise_for_status()
            items = response.json().get("Items", [])
            # ç²¾ç¡®åŒ¹é…ï¼Œé˜²æ­¢è¿”å› "å¼ èµ«" æ—¶ä¹Ÿè¿”å› "å¼ èµ«ä¸€"
            return [p for p in items if p.get("Name") == name]
        except Exception as e:
            logging.error(f"ã€è°ƒè¯•ã€‘æŒ‰å§“å '{name}' æœç´¢æ¼”å‘˜æ—¶å¤±è´¥: {e}")
            return []

    def _rename_person_by_id(self, person_id: str, new_name: str, task_category: str) -> bool:
        """é€šè¿‡ Person ID é‡å‘½åä¸€ä¸ªæ¼”å‘˜ï¼ŒåŒ…å«é‡è¯•é€»è¾‘"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                person_details = self._get_emby_item_details(person_id, "ProviderIds")
                if person_details.get("Name") == new_name:
                    return True # å·²ç»æ˜¯ç›®æ ‡åç§°ï¼Œæ— éœ€ä¿®æ”¹
                
                person_details['Name'] = new_name
                
                update_url = f"{self.server_config.server}/Items/{person_id}"
                headers = {'Content-Type': 'application/json'}
                params = {"api_key": self.server_config.api_key}
                proxies = self.proxy_manager.get_proxies(update_url)

                resp = self.session.post(update_url, params=params, json=person_details, headers=headers, timeout=30, proxies=proxies)
                resp.raise_for_status()
                
                if resp.status_code == 204:
                    return True
                else:
                    # è®°å½•è­¦å‘Šä½†ç»§ç»­å°è¯•
                    ui_logger.warning(f"       - âš ï¸ æ¼”å‘˜é‡å‘½åè¯·æ±‚è¿”å›çŠ¶æ€ç  {resp.status_code} (å°è¯• {attempt + 1}/{max_retries})", task_category=task_category)

            except Exception as e:
                ui_logger.error(f"       - âŒ æ¼”å‘˜é‡å‘½åAPIè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}", task_category=task_category)
            
            time.sleep(2) # æ¯æ¬¡å¤±è´¥åç­‰å¾…2ç§’
        
        return False

    

    def generate_map_task(self, scope: ScheduledTasksTargetScope, generation_mode: str, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ç”Ÿæˆ"
        actor_limit = self.config.actor_role_mapper_config.actor_limit
        
        mode_map = {
            'overwrite': 'è¦†ç›–æ¨¡å¼',
            'incremental': 'å¢é‡æ¨¡å¼',
            'update_selected': 'æ›´æ–°æŒ‡å®šæ¨¡å¼'
        }
        mode_text = mode_map.get(generation_mode, 'æœªçŸ¥æ¨¡å¼')

        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ ({mode_text})ï¼ŒèŒƒå›´: {scope.mode}ï¼Œæ¼”å‘˜ä¸Šé™: {actor_limit}", task_category=task_cat)

        try:
            actor_role_map = {}
            if generation_mode in ['incremental', 'update_selected']:
                ui_logger.info(f"â¡ï¸ [é˜¶æ®µ1/6] {mode_text}ï¼šæ­£åœ¨åŠ è½½ç°æœ‰æ˜ å°„è¡¨...", task_category=task_cat)
                if os.path.exists(ACTOR_ROLE_MAP_FILE):
                    try:
                        with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                            actor_role_map = json.load(f)
                        ui_logger.info(f"  - âœ… å·²æˆåŠŸåŠ è½½ {len(actor_role_map)} æ¡ç°æœ‰è®°å½•ã€‚", task_category=task_cat)
                    except (json.JSONDecodeError, IOError) as e:
                        ui_logger.warning(f"  - âš ï¸ åŠ è½½ç°æœ‰æ˜ å°„è¡¨å¤±è´¥ï¼Œå°†ä½œä¸ºé¦–æ¬¡ç”Ÿæˆå¤„ç†ã€‚é”™è¯¯: {e}", task_category=task_cat)
                else:
                    ui_logger.info("  - æœ¬åœ°æ˜ å°„è¡¨ä¸å­˜åœ¨ï¼Œå°†ä½œä¸ºé¦–æ¬¡ç”Ÿæˆå¤„ç†ã€‚", task_category=task_cat)

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/6] æ­£åœ¨è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
            selector = MediaSelector(self.config)
            media_ids = selector.get_item_ids(scope)
            if not media_ids:
                ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
                return
            
            ui_logger.info(f"ğŸ” å·²è·å– {len(media_ids)} ä¸ªåª’ä½“é¡¹ï¼Œå¼€å§‹é¢„å¤„ç†...", task_category=task_cat)

            media_ids_to_process = []
            # --- ä¿®æ”¹ 1: é‡å‘½å mapï¼Œä½¿å…¶æ›´æ¸…æ™° ---
            tmdb_key_to_item_id_map = {}
            skipped_count = 0
            
            ui_logger.info("â¡ï¸ [é˜¶æ®µ3/6] æ­£åœ¨å¹¶å‘è·å–æ‰€æœ‰åª’ä½“çš„ TMDB ID åŠç±»å‹å¹¶è¿›è¡Œé¢„è¿‡æ»¤...", task_category=task_cat)
            with ThreadPoolExecutor(max_workers=10) as executor:
                # --- ä¿®æ”¹ 2: è¯·æ±‚çš„å­—æ®µä¸­å¢åŠ  Type ---
                future_to_id = {executor.submit(self._get_emby_item_details, item_id, "ProviderIds,Type"): item_id for item_id in media_ids}
                for future in as_completed(future_to_id):
                    if cancellation_event.is_set(): return
                    item_id = future_to_id[future]
                    try:
                        details = future.result()
                        provider_ids_lower = {k.lower(): v for k, v in details.get("ProviderIds", {}).items()}
                        tmdb_id = provider_ids_lower.get("tmdb")
                        item_type = details.get("Type") # "Movie" or "Series"
                        
                        if not tmdb_id or not item_type:
                            continue
                        
                        # --- ä¿®æ”¹ 3: æ„å»ºå¸¦å‰ç¼€çš„ map_key ---
                        type_prefix = 'tv' if item_type == 'Series' else 'movie'
                        map_key = f"{type_prefix}-{tmdb_id}"
                        
                        if generation_mode == 'incremental' and map_key in actor_role_map:
                            skipped_count += 1
                            continue
                        
                        media_ids_to_process.append(item_id)
                        tmdb_key_to_item_id_map[item_id] = map_key
                    except Exception as e:
                        logging.error(f"ã€è°ƒè¯•ã€‘é¢„å¤„ç†åª’ä½“ {item_id} æ—¶å‡ºé”™: {e}")

            if not media_ids_to_process:
                if generation_mode == 'incremental':
                    ui_logger.info(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œæ‰€æœ‰ {len(media_ids)} ä¸ªåª’ä½“é¡¹å‡å·²å­˜åœ¨äºæ˜ å°„è¡¨ä¸­ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
                else:
                    ui_logger.info(f"âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„åª’ä½“é¡¹ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
                return
            
            ui_logger.info(f"  - é¢„å¤„ç†å®Œæˆï¼Œéœ€è¦æ–°å¢/æ›´æ–° {len(media_ids_to_process)} ä¸ªåª’ä½“é¡¹ (å·²è·³è¿‡ {skipped_count} ä¸ª)ã€‚", task_category=task_cat)

            total_items = len(media_ids_to_process)
            task_manager.update_task_progress(task_id, 0, total_items)
            
            processed_count = 0

            with ThreadPoolExecutor(max_workers=10) as executor:
                ui_logger.info("â¡ï¸ [é˜¶æ®µ4/6] æ­£åœ¨å¹¶å‘è·å–å¾…å¤„ç†åª’ä½“é¡¹çš„åŸºç¡€è¯¦æƒ…å¹¶è£åˆ‡æ¼”å‘˜...", task_category=task_cat)
                future_to_id = {executor.submit(self._get_emby_item_details, item_id, "People,Name"): item_id for item_id in media_ids_to_process}
                
                all_actors_to_fetch_details = []
                media_details_map = {}

                for future in as_completed(future_to_id):
                    if cancellation_event.is_set(): return
                    item_id = future_to_id[future]
                    try:
                        details = future.result()
                        media_details_map[item_id] = details
                        
                        people = details.get("People", [])
                        if people:
                            actors = [p for p in people if p.get('Type') == 'Actor']
                            limited_actors = actors[:actor_limit]
                            
                            if len(actors) > len(limited_actors):
                                ui_logger.debug(f"  - [æ¼”å‘˜è£åˆ‡] åª’ä½“ã€{details.get('Name')}ã€‘æ¼”å‘˜æ€»æ•°: {len(actors)}ï¼Œæ ¹æ®è®¾ç½®å°†å¤„ç†å‰ {len(limited_actors)} ä½ã€‚", task_category=task_cat)
                            
                            all_actors_to_fetch_details.extend(limited_actors)

                    except Exception as e:
                        ui_logger.error(f"   - âŒ è·å–åª’ä½“ {item_id} åŸºç¡€è¯¦æƒ…æ—¶å‡ºé”™: {e}", task_category=task_cat)

                if cancellation_event.is_set(): return
                
                unique_actors_to_fetch_details = {actor['Id']: actor for actor in all_actors_to_fetch_details}.values()
                ui_logger.info(f"â¡ï¸ [é˜¶æ®µ5/6] åª’ä½“è¯¦æƒ…è·å–å®Œæ¯•ï¼Œå¼€å§‹ä¸º {len(unique_actors_to_fetch_details)} ä¸ªå”¯ä¸€æ¼”å‘˜å¹¶å‘è·å– ProviderIds...", task_category=task_cat)
                
                person_details_map = {}
                future_to_person_id = {executor.submit(self._get_emby_item_details, person['Id'], "ProviderIds"): person for person in unique_actors_to_fetch_details}

                for future in as_completed(future_to_person_id):
                    if cancellation_event.is_set(): return
                    person = future_to_person_id[future]
                    try:
                        person_details_map[person['Id']] = future.result()
                    except Exception as e:
                        logging.debug(f"ã€è°ƒè¯•ã€‘è·å–æ¼”å‘˜ {person.get('Name')} (ID: {person.get('Id')}) çš„ ProviderIds å¤±è´¥: {e}")

                if cancellation_event.is_set(): return

                ui_logger.info("â¡ï¸ [é˜¶æ®µ6/6] å¼€å§‹æ„å»ºæœ€ç»ˆæ˜ å°„è¡¨...", task_category=task_cat)
                for item_id, details in media_details_map.items():
                    item_name = details.get("Name", f"ID {item_id}")
                    # --- ä¿®æ”¹ 4: ä½¿ç”¨æ–°çš„ map è·å–å¸¦å‰ç¼€çš„ key ---
                    map_key = tmdb_key_to_item_id_map.get(item_id)
                    
                    people = details.get("People", [])
                    actors = [p for p in people if p.get('Type') == 'Actor']
                    people_to_process = actors[:actor_limit]
                    
                    if not people_to_process:
                        processed_count += 1
                        task_manager.update_task_progress(task_id, processed_count, total_items)
                        continue

                    work_map = {}
                    for person in people_to_process:
                        actor_name = person.get("Name")
                        if not actor_name:
                            continue

                        person_full_details = person_details_map.get(person.get("Id"))
                        person_tmdb_id = None
                        if person_full_details:
                            provider_ids = person_full_details.get("ProviderIds", {})
                            provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                            person_tmdb_id = provider_ids_lower.get("tmdb")
                        
                        role = person.get("Role", "")
                        logging.debug(f"ã€è°ƒè¯•-æœ€ç»ˆæ•°æ®ã€‘æ¼”å‘˜: {actor_name}, è§’è‰²: {role}, TMDB ID: {person_tmdb_id}")

                        work_map[actor_name] = {
                            "tmdb_id": person_tmdb_id,
                            "role": role
                        }
                    
                    if work_map and map_key:
                        actor_role_map[map_key] = {
                            "title": item_name,
                            "map": work_map
                        }
                    
                    processed_count += 1
                    task_manager.update_task_progress(task_id, processed_count, total_items)

            ui_logger.info("â¡ï¸ [é˜¶æ®µ7/7] æ­£åœ¨å†™å…¥æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            try:
                with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                    with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                        json.dump(actor_role_map, f, ensure_ascii=False, indent=2)
            except Timeout:
                raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")

            total_works = len(actor_role_map)
            total_actors = sum(len(work['map']) for work in actor_role_map.values())
            
            final_log_message = f"âœ… æ˜ å°„è¡¨ç”Ÿæˆå®Œæ¯•ï¼å…±è®°å½• {total_works} éƒ¨ä½œå“ï¼Œ{total_actors} æ¡æ¼”å‘˜è§’è‰²å…³ç³»ã€‚"
            if generation_mode == 'incremental' and skipped_count > 0:
                final_log_message += f" (è·³è¿‡ {skipped_count} ä¸ªå·²å­˜åœ¨çš„ä½œå“)"
            ui_logger.info(final_log_message, task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ç”Ÿæˆæ˜ å°„è¡¨ä»»åŠ¡å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e
        

    # backend/actor_role_mapper_logic.py (å‡½æ•°æ›¿æ¢)

    def generate_map_for_single_item(self, item_id: str, task_category: str, overwrite: bool = False):
        """ä¸ºå•ä¸ªåª’ä½“é¡¹ç”Ÿæˆè§’è‰²æ˜ å°„ï¼Œå¹¶ä»¥å¢é‡æ¨¡å¼æ›´æ–°åˆ°æœ¬åœ°æ–‡ä»¶ã€‚"""
        ui_logger.info(f"â¡ï¸ [å•ä½“æ¨¡å¼] å¼€å§‹ä¸ºåª’ä½“ (ID: {item_id}) ç”Ÿæˆè§’è‰²æ˜ å°„...", task_category=task_category)
        
        try:
            item_details = self._get_emby_item_details(item_id, "ProviderIds,Name,People,Type")
            item_name = item_details.get("Name", f"ID {item_id}")
            provider_ids_lower = {k.lower(): v for k, v in item_details.get("ProviderIds", {}).items()}
            tmdb_id = provider_ids_lower.get("tmdb")
            item_type = item_details.get("Type")

            if not tmdb_id or not item_type:
                ui_logger.warning(f"   - âš ï¸ åª’ä½“ã€{item_name}ã€‘ç¼ºå°‘ TMDB ID æˆ–åª’ä½“ç±»å‹ï¼Œæ— æ³•ç”Ÿæˆæ˜ å°„ã€‚", task_category=task_category)
                return

            type_prefix = 'tv' if item_type == 'Series' else 'movie'
            map_key = f"{type_prefix}-{tmdb_id}"

            with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                actor_role_map = {}
                if os.path.exists(ACTOR_ROLE_MAP_FILE):
                    try:
                        with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                            actor_role_map = json.load(f)
                    except (json.JSONDecodeError, IOError):
                        pass

                # è®¡ç®—æ–°çš„ work_map
                actor_limit = self.config.actor_role_mapper_config.actor_limit
                people = item_details.get("People", [])
                actors = [p for p in people if p.get('Type') == 'Actor']
                people_to_process = actors[:actor_limit]

                if not people_to_process:
                    ui_logger.info(f"   - [è·³è¿‡] åª’ä½“ã€{item_name}ã€‘æ²¡æœ‰æ¼”å‘˜ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆæ˜ å°„ã€‚", task_category=task_category)
                    return

                new_work_map = {}
                with ThreadPoolExecutor(max_workers=5) as executor:
                    future_to_person = {executor.submit(self._get_emby_item_details, p['Id'], "ProviderIds"): p for p in people_to_process}
                    for future in as_completed(future_to_person):
                        person = future_to_person[future]
                        actor_name = person.get("Name")
                        if not actor_name: continue
                        
                        person_tmdb_id = None
                        try:
                            person_details = future.result()
                            if person_details:
                                p_ids = person_details.get("ProviderIds", {})
                                p_ids_lower = {k.lower(): v for k, v in p_ids.items()}
                                person_tmdb_id = p_ids_lower.get("tmdb")
                        except Exception:
                            pass

                        new_work_map[actor_name] = {
                            "tmdb_id": person_tmdb_id,
                            "role": person.get("Role", "")
                        }

                # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
                if map_key in actor_role_map:
                    if not overwrite:
                        ui_logger.info(f"   - âœ… åª’ä½“ã€{item_name}ã€‘çš„æ˜ å°„å·²å­˜åœ¨äºæœ¬åœ°æ–‡ä»¶ä¸­ï¼Œè·³è¿‡æœ¬æ¬¡ç”Ÿæˆã€‚", task_category=task_category)
                        return
                    else:
                        old_work_map = actor_role_map[map_key].get('map', {})
                        if old_work_map == new_work_map:
                            ui_logger.info(f"   - [è·³è¿‡å†™å…¥] åª’ä½“ã€{item_name}ã€‘çš„æ–°è§’è‰²æ•°æ®ä¸ç°æœ‰æ˜ å°„ä¸€è‡´ï¼Œæ— éœ€æ›´æ–°æ–‡ä»¶ã€‚", task_category=task_cat)
                            return
                        ui_logger.info(f"   - ğŸ”„ åª’ä½“ã€{item_name}ã€‘çš„æ˜ å°„å·²å­˜åœ¨ä¸”å†…å®¹æœ‰å˜åŒ–ï¼Œå°†æ‰§è¡Œè¦†ç›–æ›´æ–°ã€‚", task_category=task_cat)
                
                if new_work_map:
                    actor_role_map[map_key] = {
                        "title": item_name,
                        "map": new_work_map
                    }
                    ui_logger.info(f"   - ğŸ” å·²ä¸ºã€{item_name}ã€‘æˆåŠŸç”Ÿæˆ {len(new_work_map)} æ¡æ¼”å‘˜è§’è‰²æ˜ å°„ã€‚", task_category=task_cat)
                
                with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                    json.dump(actor_role_map, f, ensure_ascii=False, indent=2)
                
                ui_logger.info(f"   - âœ… æˆåŠŸå°†æ–°æ˜ å°„è¿½åŠ æˆ–æ›´æ–°åˆ°æœ¬åœ°æ–‡ä»¶ã€‚", task_category=task_cat)

        except Timeout:
            ui_logger.error(f"   - âŒ è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"   - âŒ ä¸ºåª’ä½“ {item_id} ç”Ÿæˆå•ä½“æ˜ å°„æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_category, exc_info=True)

    def _get_github_api_url(self) -> str:
        match = re.match(r"https?://github\.com/([^/]+)/([^/]+)", self.github_config.repo_url)
        if not match:
            raise ValueError("æ— æ•ˆçš„ GitHub ä»“åº“ URLã€‚")
        owner, repo = match.groups()
        repo = repo.replace('.git', '')
        return f"https://api.github.com/repos/{owner}/{repo}/contents/{GITHUB_MAP_PATH}"

    def _github_request(self, method: str, url: str, **kwargs) -> Any:
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "Authorization": f"token {self.github_config.personal_access_token}"
        }
        proxies = self.proxy_manager.get_proxies(url)
        response = self.session.request(method, url, headers=headers, timeout=30, proxies=proxies, **kwargs)
        response.raise_for_status()
        return response.json() if response.content else None
    
    def _execute_github_write_request(self, method: str, url: str, pat: str, payload: Optional[Dict] = None) -> Dict:
        """é€šè¿‡ curl æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼ˆæ— é‡è¯•ï¼‰"""
        command = [
            'curl', '-L', '-X', method,
            '-H', 'Accept: application/vnd.github.v3+json',
            '-H', f'Authorization: token {pat}',
            '-H', 'Content-Type: application/json'
        ]
        
        json_payload_str = ""
        if payload:
            command.extend(['--data-binary', '@-'])
            json_payload_str = json.dumps(payload)

        proxies = self.proxy_manager.get_proxies(url)
        if proxies.get('https'):
            command.extend(['--proxy', proxies['https']])

        command.append(url)

        result = subprocess.run(command, input=json_payload_str, capture_output=True, text=True, check=False)
        
        response_data = {}
        try:
            if result.stdout:
                response_data = json.loads(result.stdout)
        except json.JSONDecodeError:
            raise Exception(f"cURL è¿”å›äº†éJSONå“åº”: {result.stdout or 'æ— è¾“å‡º'} | é”™è¯¯: {result.stderr or 'æ— é”™è¯¯ä¿¡æ¯'}")

        if result.returncode != 0 or (response_data.get("message") and response_data.get("documentation_url")):
            error_message = response_data.get('message', f"cURL é”™è¯¯: {result.stderr}")
            if response_data.get('status') == '422' and "sha" in error_message:
                error_message = f"æ— æ•ˆè¯·æ±‚ (422)ã€‚æœåŠ¡å™¨æç¤º 'sha' å‚æ•°æœ‰é—®é¢˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºåœ¨æ‚¨æ“ä½œæœŸé—´ï¼Œæ–‡ä»¶è¢«å…¶ä»–è¿›ç¨‹ä¿®æ”¹ã€‚è¯·é‡è¯•ã€‚({error_message})"
            elif "409 Conflict" in result.stderr:
                error_message = "GitHub API è¿”å› 409 Conflict é”™è¯¯ï¼Œè¿™é€šå¸¸æ˜¯å¹¶å‘å†™å…¥å†²çªå¯¼è‡´çš„ã€‚è¯·ç¨åé‡è¯•ã€‚"
            elif "schannel: failed to receive handshake" in result.stderr or "curl: (35)" in result.stderr:
                error_message = f"SSL/TLS æ¡æ‰‹å¤±è´¥ã€‚è¿™é€šå¸¸æ˜¯ä¸´æ—¶çš„ç½‘ç»œæˆ–ä»£ç†é—®é¢˜ã€‚é”™è¯¯: {result.stderr}"
            raise Exception(f"GitHub API é”™è¯¯: {error_message}")

        return response_data
    
    def _execute_github_write_request_with_retry(self, method: str, url: str, pat: str, payload: Optional[Dict] = None, task_cat: str = "GitHubå†™å…¥") -> Dict:
        """
        æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼Œå¹¶å¢åŠ äº†é’ˆå¯¹ç½‘ç»œé”™è¯¯çš„é‡è¯•é€»è¾‘ã€‚
        """
        max_retries = 3
        retry_delay = 5  # seconds
        for attempt in range(max_retries):
            try:
                return self._execute_github_write_request(method, url, pat, payload)
            except Exception as e:
                error_str = str(e).lower()
                if "ssl/tls" in error_str or "handshake" in error_str or "curl: (35)" in error_str:
                    if attempt < max_retries - 1:
                        ui_logger.warning(f"  - âš ï¸ ç½‘ç»œæ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•... åŸå› : {e}", task_category=task_cat)
                        time.sleep(retry_delay)
                        continue
                raise e
        raise Exception("é‡è¯•é€»è¾‘æ‰§è¡Œå®Œæ¯•ä½†æœªèƒ½æˆåŠŸã€‚")

    def upload_to_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ä¸Šä¼ "
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä¸Šä¼ æ˜ å°„è¡¨åˆ° GitHub...", task_category=task_cat)

        if not self.github_config.repo_url or not self.github_config.personal_access_token:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URL æˆ–ä¸ªäººè®¿é—®ä»¤ç‰Œ (PAT)ã€‚")

        if not os.path.exists(ACTOR_ROLE_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°æ˜ å°„è¡¨æ–‡ä»¶ actor_role_map.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆã€‚")

        try:
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/3] æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            content_b64 = base64.b64encode(content.encode('utf-8')).decode('utf-8')
            api_url = self._get_github_api_url()

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/3] æ­£åœ¨æ£€æŸ¥è¿œç¨‹æ–‡ä»¶çŠ¶æ€...", task_category=task_cat)
            sha = None
            try:
                remote_file = self._github_request("GET", api_url)
                if remote_file:
                    sha = remote_file.get('sha')
                    ui_logger.info("  - æ£€æµ‹åˆ°è¿œç¨‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†æ‰§è¡Œè¦†ç›–æ“ä½œã€‚", task_category=task_cat)
            except Exception:
                ui_logger.info("  - è¿œç¨‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†æ‰§è¡Œåˆ›å»ºæ“ä½œã€‚", task_category=task_cat)

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ3/3] æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...", task_category=task_cat)
            payload = {
                "message": f"feat: Update actor role map ({time.strftime('%Y-%m-%d %H:%M:%S')})",
                "content": content_b64,
                "branch": self.github_config.branch
            }
            if sha:
                payload["sha"] = sha
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨æ–°çš„åŸºäº curl çš„ä¸Šä¼ æ–¹æ³• ---
            self._execute_github_write_request_with_retry("PUT", api_url, self.github_config.personal_access_token, payload, task_cat=task_cat)
            # --- ä¿®æ”¹ç»“æŸ ---
            
            ui_logger.info("âœ… ä¸Šä¼ æˆåŠŸï¼æ˜ å°„è¡¨å·²åŒæ­¥åˆ° GitHub ä»“åº“ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä¸Šä¼ åˆ° GitHub å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e

    # backend/actor_role_mapper_logic.py (å‡½æ•°æ›¿æ¢)

    def download_from_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ä¸‹è½½"
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä» GitHub ä¸‹è½½æ˜ å°„è¡¨...", task_category=task_cat)

        if not self.github_config.repo_url:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URLã€‚")

        try:
            api_url = self._get_github_api_url()
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/2] æ­£åœ¨è¯·æ±‚è¿œç¨‹æ–‡ä»¶å…ƒæ•°æ®...", task_category=task_cat)
            
            # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œè·å–æ–‡ä»¶å…ƒæ•°æ®
            remote_file_meta = self._github_request("GET", api_url)
            if not remote_file_meta:
                raise ValueError("ä» GitHub è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ã€‚")

            content = ""
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šåˆ¤æ–­æ–‡ä»¶å¤§å°ï¼Œé€‰æ‹©ä¸åŒä¸‹è½½ç­–ç•¥ ---
            if 'content' in remote_file_meta and remote_file_meta['content']:
                # æ–‡ä»¶å°äº1MBï¼Œç›´æ¥ä»å…ƒæ•°æ®ä¸­è§£ç 
                ui_logger.info("   - æ–‡ä»¶å°äº 1MBï¼Œç›´æ¥è§£ç å†…å®¹...", task_category=task_cat)
                content = base64.b64decode(remote_file_meta['content']).decode('utf-8')
            elif 'download_url' in remote_file_meta and remote_file_meta['download_url']:
                # æ–‡ä»¶å¤§äº1MBï¼Œéœ€è¦é€šè¿‡ download_url å†æ¬¡è¯·æ±‚
                download_url = remote_file_meta['download_url']
                file_size_mb = remote_file_meta.get('size', 0) / (1024 * 1024)
                ui_logger.info(f"   - æ–‡ä»¶å¤§å°ä¸º {file_size_mb:.2f} MB (>1MB)ï¼Œå°†é€šè¿‡ä¸‹è½½é“¾æ¥è·å–...", task_category=task_cat)
                
                proxies = self.proxy_manager.get_proxies(download_url)
                response = self.session.get(download_url, timeout=60, proxies=proxies) # å¢åŠ å¤§æ–‡ä»¶ä¸‹è½½è¶…æ—¶
                response.raise_for_status()
                content = response.text
            else:
                raise ValueError("GitHub API å“åº”ä¸­æ—¢æ—  'content' ä¹Ÿæ—  'download_url'ï¼Œæ— æ³•ä¸‹è½½æ–‡ä»¶ã€‚")
            # --- ä¿®æ”¹ç»“æŸ ---

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/2] æ­£åœ¨å†™å…¥æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            try:
                with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                    with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                        f.write(content)
            except Timeout:
                raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")

            ui_logger.info("âœ… ä¸‹è½½æˆåŠŸï¼æœ¬åœ°æ˜ å°„è¡¨å·²æ›´æ–°ä¸º GitHub ç‰ˆæœ¬ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä» GitHub ä¸‹è½½å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e
        
    # backend/actor_role_mapper_logic.py (å‡½æ•°æ›¿æ¢)

    def restore_single_map_task(self, item_ids: List[str], role_map: Dict, title: str, cancellation_event: threading.Event, task_id: str, task_manager: Optional[TaskManager] = None, task_category: Optional[str] = None):
        """
        æ ¹æ®æ˜ å°„å…³ç³»ï¼Œæ¢å¤æŒ‡å®š Emby åª’ä½“é¡¹åˆ—è¡¨çš„æ¼”å‘˜è§’è‰²åã€‚
        é‡‡ç”¨ã€åå‘é”å®šã€‘ç­–ç•¥ï¼Œèåˆã€æ¼”å‘˜åä¿®æ­£ã€‘é€»è¾‘ï¼Œå¹¶ä½¿ç”¨æœ€ç»ˆä¼˜åŒ–çš„æ—¥å¿—é£æ ¼ã€‚
        """
        task_cat = task_category if task_category else "æ¼”å‘˜è§’è‰²æ˜ å°„-æ¢å¤"
        
        if not item_ids or not role_map:
            ui_logger.error(f"âŒ ä»»åŠ¡å¤±è´¥ï¼šä¼ å…¥çš„æ˜ å°„æ•°æ®ä¸å®Œæ•´ã€‚ä½œå“: {title}", task_category=task_cat)
            raise ValueError("æ˜ å°„æ•°æ®ä¸å®Œæ•´")

        total_items = len(item_ids)
        if task_manager:
            pass
        ui_logger.info(f"  â¡ï¸ å¼€å§‹ä¸ºä½œå“ã€Š{title}ã€‹æ¢å¤æ¼”å‘˜è§’è‰²ï¼Œå…±æ¶‰åŠ {total_items} ä¸ªEmbyåª’ä½“é¡¹ã€‚", task_category=task_cat)

        for i, item_id in enumerate(item_ids):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                return

            isolated_persons = {} 
            
            try:
                ui_logger.info(f"     - æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_items} ä¸ªåª’ä½“é¡¹ (ID: {item_id})...", task_category=task_cat)
                
                item_details_base = self._get_emby_item_details(item_id, "People")
                current_people_base = item_details_base.get("People", [])
                if not current_people_base:
                    ui_logger.info(f"       - [è·³è¿‡] åª’ä½“é¡¹ {item_id} æ²¡æœ‰æ¼”èŒå‘˜ä¿¡æ¯ã€‚", task_category=task_cat)
                    continue
                
                emby_actors_base = [p for p in current_people_base if p.get("Type") == "Actor"]
                emby_actors_by_id = {}
                emby_actors_by_name = {}
                
                with ThreadPoolExecutor(max_workers=10) as executor:
                    future_to_person = {executor.submit(self._get_emby_item_details, p['Id'], "ProviderIds"): p for p in emby_actors_base}
                    for future in as_completed(future_to_person):
                        original_person = future_to_person[future]
                        try:
                            full_person_details = future.result()
                            original_person.update(full_person_details)
                            provider_ids_lower = {k.lower(): v for k, v in full_person_details.get("ProviderIds", {}).items()}
                            person_tmdb_id = provider_ids_lower.get("tmdb")
                            if person_tmdb_id:
                                emby_actors_by_id[str(person_tmdb_id)] = original_person
                            emby_actors_by_name[original_person.get("Name")] = original_person
                        except Exception:
                            emby_actors_by_name[original_person.get("Name")] = original_person

                actors_to_update_map = {}
                for map_actor_name, map_actor_data in role_map.items():
                    map_tmdb_id = map_actor_data.get("tmdb_id")
                    target_emby_person = None
                    match_source = ""
                    if map_tmdb_id and str(map_tmdb_id) != "null":
                        target_emby_person = emby_actors_by_id.get(str(map_tmdb_id))
                        if target_emby_person: match_source = "ID"
                    if not target_emby_person:
                        target_emby_person = emby_actors_by_name.get(map_actor_name)
                        if target_emby_person: match_source = "åç§°"
                    
                    if target_emby_person:
                        current_role = target_emby_person.get("Role", "")
                        target_role = map_actor_data.get("role", "")
                        current_name = target_emby_person.get("Name")
                        target_name = map_actor_name

                        if current_role != target_role or (current_name != target_name and _contains_chinese(target_name)):
                            actors_to_update_map[target_emby_person.get("Id")] = {
                                'target_role': target_role, 'current_role': current_role,
                                'target_name': target_name, 'current_name': current_name,
                                'match_source': match_source,
                                'source': map_actor_data.get('source')
                            }

                if not actors_to_update_map:
                    ui_logger.info(f"       - è§’è‰²åä¸æ¼”å‘˜åå‡ä¸æ˜ å°„è¡¨ä¸€è‡´ï¼Œæ— éœ€æ›´æ–°ã€‚", task_category=task_cat)
                    continue

                ui_logger.info(f"       - ğŸ” æ‰«æå‘ç° {len(actors_to_update_map)} ä½æ¼”å‘˜ä¿¡æ¯éœ€è¦æ›´æ–°ã€‚", task_category=task_cat)
                
                ui_logger.info(f"       - [éš”ç¦»] æ­£åœ¨ä¸º {len(actors_to_update_map)} ä¸ªå¾…æ›´æ–°æ¼”å‘˜è¿›è¡Œä¸´æ—¶æ”¹å...", task_category=task_cat)
                for person_id, update_info in actors_to_update_map.items():
                    current_name = update_info['current_name']
                    unique_name = f"{current_name}_embytoolkit_update_{person_id}"
                    
                    logging.debug(f"ã€è°ƒè¯•ã€‘éš”ç¦»: {current_name} (ID: {person_id}) -> {unique_name}")
                    if self._rename_person_by_id(person_id, unique_name, task_cat):
                        isolated_persons[person_id] = (current_name, update_info['target_name'])
                        person_in_list = next((p for p in current_people_base if p.get("Id") == person_id), None)
                        if person_in_list:
                            person_in_list["Name"] = unique_name
                    else:
                        raise Exception(f"éš”ç¦»æ¼”å‘˜ {current_name} (ID: {person_id}) å¤±è´¥ï¼Œä¸­æ­¢æ“ä½œã€‚")

                ui_logger.info(f"       - [æ›´æ–°] éš”ç¦»å®Œæˆï¼Œå¼€å§‹å°†å˜æ›´å†™å…¥ Emby...", task_category=task_cat)
                for person in current_people_base:
                    person_id = person.get("Id")
                    if person_id in actors_to_update_map:
                        person["Role"] = actors_to_update_map[person_id]['target_role']
                
                item_details_base["People"] = current_people_base
                update_url = f"{self.server_config.server}/Items/{item_id}"
                headers = {'Content-Type': 'application/json'}
                params = {"api_key": self.server_config.api_key}
                proxies = self.proxy_manager.get_proxies(update_url)
                response = self.session.post(update_url, params=params, json=item_details_base, headers=headers, timeout=30, proxies=proxies)
                response.raise_for_status()
                ui_logger.info(f"       - âœ… åª’ä½“é¡¹ (ID: {item_id}) æ›´æ–°æˆåŠŸï¼", task_category=task_cat)

                ui_logger.info(f"     - ğŸ”„ [å˜æ›´è¯¦æƒ…]", task_category=task_cat)
                for update_info in actors_to_update_map.values():
                    current_name, target_name = update_info['current_name'], update_info['target_name']
                    current_role, target_role = update_info['current_role'], update_info['target_role']
                    
                    # --- æ ¸å¿ƒä¿®æ­£ï¼šç›´æ¥ä½¿ç”¨ sourceï¼Œå¦åˆ™å›é€€ ---
                    source_text = update_info.get('source') or f"(é€šè¿‡{update_info['match_source']}åŒ¹é…)"

                    if current_name != target_name and _contains_chinese(target_name):
                        ui_logger.info(f"       - âœ… æ¼”å‘˜åä¿®æ­£: '{current_name}' -> '{target_name}' {source_text}", task_category=task_cat)
                    
                    if current_role != target_role:
                        actor_display_name = target_name if current_name == target_name else f"[{target_name}]"
                        # å¦‚æœæ¼”å‘˜åä¹Ÿè¢«ä¿®æ­£äº†ï¼Œè§’è‰²æ—¥å¿—å°±ä¸å†é‡å¤æ˜¾ç¤ºæ¥æº
                        if current_name != target_name and _contains_chinese(target_name):
                            ui_logger.info(f"       - âœ… è§’è‰²åæ›´æ–°: {actor_display_name} '{current_role}' -> '{target_role}'", task_category=task_cat)
                        else:
                            ui_logger.info(f"       - âœ… è§’è‰²åæ›´æ–°: {actor_display_name} '{current_role}' -> '{target_role}' {source_text}", task_category=task_cat)

            except Exception as e:
                ui_logger.error(f"  - âŒ å¤„ç†åª’ä½“é¡¹ {item_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            
            finally:
                if isolated_persons:
                    ui_logger.info(f"       - [æ¢å¤] å¼€å§‹å°† {len(isolated_persons)} ä¸ªæ¼”å‘˜æ¢å¤åˆ°ç›®æ ‡åç§°...", task_category=task_cat)
                    for person_id, (original_name, target_name) in isolated_persons.items():
                        log_msg = f"         - ğŸ”“ æ¢å¤: (ID: {person_id}) -> {target_name}"
                        if original_name != target_name:
                            log_msg += f" (åŸå: '{original_name}')"
                        logging.debug(log_msg)
                        
                        if not self._rename_person_by_id(person_id, target_name, task_cat):
                            ui_logger.error(f"         - âŒ æ¢å¤æ¼”å‘˜ (ID: {person_id}) åç§°å¤±è´¥ï¼è¯·æ‰‹åŠ¨å°†å…¶åç§°ä¿®æ”¹ä¸º `{target_name}`ã€‚", task_category=task_cat)
                
                ui_logger.info(f"     - ğŸ‰ ä½œå“ã€Š{title}ã€‹å¤„ç†å®Œæ¯•ã€‚", task_category=task_cat)

    def update_single_map_file(self, single_map_data: Dict):
        """
        æ ¹æ®ä¼ å…¥çš„å•æ¡æ˜ å°„æ•°æ®ï¼Œæ›´æ–°æœ¬åœ°çš„ actor_role_map.json æ–‡ä»¶ã€‚
        """
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-æ–‡ä»¶æ›´æ–°"
        # --- ä¿®æ”¹ 1: å­—æ®µåä» tmdb_id æ”¹ä¸º map_keyï¼Œæ›´å‡†ç¡® ---
        map_key = single_map_data.get("map_key")
        if not map_key:
            raise ValueError("ä¼ å…¥çš„æ•°æ®ç¼ºå°‘ map_key")

        ui_logger.info(f"â¡ï¸ å‡†å¤‡æ›´æ–°æ˜ å°„æ–‡ä»¶ï¼Œç›®æ ‡ä½œå“ Key: {map_key}", task_category=task_cat)
        
        try:
            with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                if os.path.exists(ACTOR_ROLE_MAP_FILE):
                    with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                        full_map = json.load(f)
                else:
                    full_map = {}
                
                # --- ä¿®æ”¹ 2: ä½¿ç”¨æ–°çš„ map_key ä½œä¸ºä¸»é”® ---
                full_map[map_key] = {
                    "title": single_map_data.get("title", "æœªçŸ¥ä½œå“"),
                    "map": single_map_data.get("map", {})
                }

                with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                    json.dump(full_map, f, ensure_ascii=False, indent=2)
                
                ui_logger.info(f"âœ… æˆåŠŸæ›´æ–°æ˜ å°„æ–‡ä»¶ï¼Œä½œå“: {single_map_data.get('title')}", task_category=task_cat)
                return {"status": "success", "message": "æ˜ å°„å…³ç³»å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼"}

        except Timeout:
            ui_logger.error("âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚", task_category=task_cat)
            raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")
        except Exception as e:
            ui_logger.error(f"âŒ æ›´æ–°æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            raise e
        
    # backend/actor_role_mapper_logic.py (å‡½æ•°æ›¿æ¢)

    def restore_roles_from_map_task(self, scope: ScheduledTasksTargetScope, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        æ ¹æ®é€šç”¨èŒƒå›´å’Œæœ¬åœ°æ˜ å°„è¡¨ï¼Œæ‰¹é‡æ¢å¤æ¼”å‘˜è§’è‰²åã€‚
        æ–°ç‰ˆé€»è¾‘ï¼šä»¥æ˜ å°„è¡¨ä¸ºé©±åŠ¨ï¼Œé€šè¿‡ id_map.json æŸ¥æ‰¾ ItemIdã€‚
        """
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-æ‰¹é‡æ¢å¤"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼ŒèŒƒå›´: {scope.mode}", task_category=task_cat)

        ui_logger.info("â¡ï¸ [é˜¶æ®µ1/4] æ­£åœ¨åŠ è½½æœ¬åœ°è§’è‰²æ˜ å°„è¡¨...", task_category=task_cat)
        if not os.path.exists(ACTOR_ROLE_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°è§’è‰²æ˜ å°„è¡¨æ–‡ä»¶ actor_role_map.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆã€‚")
        
        with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
            role_map = json.load(f)
        
        if not role_map:
            ui_logger.warning("âš ï¸ æœ¬åœ°è§’è‰²æ˜ å°„è¡¨ä¸ºç©ºï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return

        ui_logger.info("â¡ï¸ [é˜¶æ®µ2/4] æ­£åœ¨åŠ è½½ TMDB-Emby ID æ˜ å°„è¡¨...", task_category=task_cat)
        id_map_file = os.path.join('/app/data', 'id_map.json')
        if not os.path.exists(id_map_file):
            ui_logger.error("âŒ å…³é”®æ–‡ä»¶ id_map.json ä¸å­˜åœ¨ï¼è¯·å…ˆåœ¨â€œå®šæ—¶ä»»åŠ¡â€é¡µé¢ç”Ÿæˆè¯¥æ˜ å°„è¡¨ã€‚", task_category=task_cat)
            raise FileNotFoundError("IDæ˜ å°„è¡¨ (id_map.json) ä¸å­˜åœ¨ã€‚")
        with open(id_map_file, 'r', encoding='utf-8') as f:
            id_map = json.load(f)
        ui_logger.info("   - â— æç¤ºï¼šæ¢å¤æ“ä½œå°†åŸºäºæ‚¨ä¸Šä¸€æ¬¡ç”Ÿæˆçš„ `id_map.json`ã€‚ä¸ºç¡®ä¿ç»“æœå‡†ç¡®ï¼Œå»ºè®®åœ¨æ¢å¤å‰é‡æ–°ç”ŸæˆIDæ˜ å°„è¡¨ã€‚", task_category=task_cat)

        ui_logger.info("â¡ï¸ [é˜¶æ®µ3/4] æ­£åœ¨æ ¹æ®èŒƒå›´è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
        selector = MediaSelector(self.config)
        media_ids_in_scope = set(selector.get_item_ids(scope))
        if not media_ids_in_scope:
            ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
            return

        ui_logger.info("â¡ï¸ [é˜¶æ®µ4/4] å¼€å§‹æ ¹æ®å¤„ç†è®¡åˆ’ï¼Œé€ä¸€æ¢å¤ä½œå“...", task_category=task_cat)
        total_works_to_process = len(role_map)
        task_manager.update_task_progress(task_id, 0, total_works_to_process)
        processed_works_count = 0

        # --- æ ¸å¿ƒä¿®æ”¹ 1: å˜é‡åä» tmdb_id æ”¹ä¸º map_keyï¼Œå¹¶ç›´æ¥ä½¿ç”¨å®ƒæŸ¥è¯¢ id_map ---
        for map_key, map_data in role_map.items():
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                return
            
            processed_works_count += 1
            task_manager.update_task_progress(task_id, processed_works_count, total_works_to_process)

            emby_ids_from_map = id_map.get(map_key, [])
            item_ids_to_process = list(media_ids_in_scope.intersection(emby_ids_from_map))
            
            if not item_ids_to_process:
                continue

            title = map_data.get("title", f"Map Key {map_key}")
            
            self.restore_single_map_task(
                item_ids=item_ids_to_process,
                role_map=map_data.get("map", {}),
                title=title,
                cancellation_event=cancellation_event,
                task_id=task_id,
                task_manager=task_manager
            )

        ui_logger.info("ğŸ‰ æ‰¹é‡æ¢å¤æ¼”å‘˜è§’è‰²ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚", task_category=task_cat)