# backend/actor_role_mapper_logic.py (æ–°æ–‡ä»¶)

import logging
import os
import json
import threading
import time
import re
import base64
import subprocess
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from filelock import FileLock, Timeout

from log_manager import ui_logger
from models import AppConfig, ScheduledTasksTargetScope
from task_manager import TaskManager
from media_selector import MediaSelector
from proxy_manager import ProxyManager

ACTOR_ROLE_MAP_FILE = os.path.join('/app/data', 'actor_role_map.json')
ACTOR_ROLE_MAP_LOCK_FILE = ACTOR_ROLE_MAP_FILE + ".lock"
GITHUB_MAP_PATH = "database/actor_role_map.json"

class ActorRoleMapperLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.server_config = config.server_config
        self.github_config = config.episode_refresher_config.github_config
        self.proxy_manager = ProxyManager(config)
        self.session = self._create_session()

    def _create_session(self):
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        session = requests.Session()
        retry_strategy = Retry(
            total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session

    def _get_emby_item_details(self, item_id: str, fields: str) -> Dict:
        url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
        params = {"api_key": self.server_config.api_key, "Fields": fields}
        proxies = self.proxy_manager.get_proxies(url)
        response = self.session.get(url, params=params, timeout=20, proxies=proxies)
        response.raise_for_status()
        return response.json()

    def generate_map_task(self, scope: ScheduledTasksTargetScope, actor_limit: int, generation_mode: str, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ç”Ÿæˆ"
        mode_text = "è¦†ç›–æ¨¡å¼" if generation_mode == 'overwrite' else "å¢é‡æ¨¡å¼"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ ({mode_text})ï¼ŒèŒƒå›´: {scope.mode}ï¼Œæ¼”å‘˜ä¸Šé™: {actor_limit}", task_category=task_cat)

        try:
            actor_role_map = {}
            if generation_mode == 'incremental':
                ui_logger.info("â¡ï¸ [é˜¶æ®µ1/6] å¢é‡æ¨¡å¼ï¼šæ­£åœ¨åŠ è½½ç°æœ‰æ˜ å°„è¡¨...", task_category=task_cat)
                if os.path.exists(ACTOR_ROLE_MAP_FILE):
                    try:
                        with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                            actor_role_map = json.load(f)
                        ui_logger.info(f"  - âœ… å·²æˆåŠŸåŠ è½½ {len(actor_role_map)} æ¡ç°æœ‰è®°å½•ã€‚", task_category=task_cat)
                    except (json.JSONDecodeError, IOError) as e:
                        ui_logger.warning(f"  - âš ï¸ åŠ è½½ç°æœ‰æ˜ å°„è¡¨å¤±è´¥ï¼Œå°†ä½œä¸ºé¦–æ¬¡ç”Ÿæˆå¤„ç†ã€‚é”™è¯¯: {e}", task_category=task_cat)
                else:
                    ui_logger.info("  - æœ¬åœ°æ˜ å°„è¡¨ä¸å­˜åœ¨ï¼Œå°†ä½œä¸ºé¦–æ¬¡ç”Ÿæˆå¤„ç†ã€‚", task_category=task_cat)

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/6] æ­£åœ¨è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
            selector = MediaSelector(self.config)
            media_ids = selector.get_item_ids(scope)
            if not media_ids:
                ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
                return
            
            ui_logger.info(f"ğŸ” å·²è·å– {len(media_ids)} ä¸ªåª’ä½“é¡¹ï¼Œå¼€å§‹é¢„å¤„ç†...", task_category=task_cat)

            media_ids_to_process = []
            tmdb_id_to_item_id_map = {}
            skipped_count = 0
            
            ui_logger.info("â¡ï¸ [é˜¶æ®µ3/6] æ­£åœ¨å¹¶å‘è·å–æ‰€æœ‰åª’ä½“çš„ TMDB ID å¹¶è¿›è¡Œé¢„è¿‡æ»¤...", task_category=task_cat)
            with ThreadPoolExecutor(max_workers=10) as executor:
                future_to_id = {executor.submit(self._get_emby_item_details, item_id, "ProviderIds"): item_id for item_id in media_ids}
                for future in as_completed(future_to_id):
                    if cancellation_event.is_set(): return
                    item_id = future_to_id[future]
                    try:
                        details = future.result()
                        provider_ids_lower = {k.lower(): v for k, v in details.get("ProviderIds", {}).items()}
                        tmdb_id = provider_ids_lower.get("tmdb")
                        if not tmdb_id:
                            continue
                        
                        if generation_mode == 'incremental' and str(tmdb_id) in actor_role_map:
                            skipped_count += 1
                            continue
                        
                        media_ids_to_process.append(item_id)
                        tmdb_id_to_item_id_map[item_id] = tmdb_id
                    except Exception as e:
                        logging.error(f"ã€è°ƒè¯•ã€‘é¢„å¤„ç†åª’ä½“ {item_id} æ—¶å‡ºé”™: {e}")

            if not media_ids_to_process:
                ui_logger.info(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œæ‰€æœ‰ {len(media_ids)} ä¸ªåª’ä½“é¡¹å‡å·²å­˜åœ¨äºæ˜ å°„è¡¨ä¸­ï¼Œä»»åŠ¡ç»“æŸã€‚", task_category=task_cat)
                return
            
            ui_logger.info(f"  - é¢„å¤„ç†å®Œæˆï¼Œéœ€è¦æ–°å¢/æ›´æ–° {len(media_ids_to_process)} ä¸ªåª’ä½“é¡¹ (å·²è·³è¿‡ {skipped_count} ä¸ª)ã€‚", task_category=task_cat)

            total_items = len(media_ids_to_process)
            task_manager.update_task_progress(task_id, 0, total_items)
            
            processed_count = 0

            with ThreadPoolExecutor(max_workers=10) as executor:
                ui_logger.info("â¡ï¸ [é˜¶æ®µ4/6] æ­£åœ¨å¹¶å‘è·å–å¾…å¤„ç†åª’ä½“é¡¹çš„åŸºç¡€è¯¦æƒ…å¹¶è£åˆ‡æ¼”å‘˜...", task_category=task_cat)
                future_to_id = {executor.submit(self._get_emby_item_details, item_id, "People,Name"): item_id for item_id in media_ids_to_process}
                
                all_actors_to_fetch_details = []
                media_details_map = {}

                for future in as_completed(future_to_id):
                    if cancellation_event.is_set(): return
                    item_id = future_to_id[future]
                    try:
                        details = future.result()
                        media_details_map[item_id] = details
                        
                        people = details.get("People", [])
                        if people:
                            actors = [p for p in people if p.get('Type') == 'Actor']
                            limited_actors = actors[:actor_limit]
                            
                            if len(actors) > len(limited_actors):
                                ui_logger.debug(f"  - [æ¼”å‘˜è£åˆ‡] åª’ä½“ã€{details.get('Name')}ã€‘æ¼”å‘˜æ€»æ•°: {len(actors)}ï¼Œæ ¹æ®è®¾ç½®å°†å¤„ç†å‰ {len(limited_actors)} ä½ã€‚", task_category=task_cat)
                            
                            all_actors_to_fetch_details.extend(limited_actors)

                    except Exception as e:
                        ui_logger.error(f"   - âŒ è·å–åª’ä½“ {item_id} åŸºç¡€è¯¦æƒ…æ—¶å‡ºé”™: {e}", task_category=task_cat)

                if cancellation_event.is_set(): return
                
                unique_actors_to_fetch_details = {actor['Id']: actor for actor in all_actors_to_fetch_details}.values()
                ui_logger.info(f"â¡ï¸ [é˜¶æ®µ5/6] åª’ä½“è¯¦æƒ…è·å–å®Œæ¯•ï¼Œå¼€å§‹ä¸º {len(unique_actors_to_fetch_details)} ä¸ªå”¯ä¸€æ¼”å‘˜å¹¶å‘è·å– ProviderIds...", task_category=task_cat)
                
                person_details_map = {}
                future_to_person_id = {executor.submit(self._get_emby_item_details, person['Id'], "ProviderIds"): person for person in unique_actors_to_fetch_details}

                for future in as_completed(future_to_person_id):
                    if cancellation_event.is_set(): return
                    person = future_to_person_id[future]
                    try:
                        person_details_map[person['Id']] = future.result()
                    except Exception as e:
                        logging.debug(f"ã€è°ƒè¯•ã€‘è·å–æ¼”å‘˜ {person.get('Name')} (ID: {person.get('Id')}) çš„ ProviderIds å¤±è´¥: {e}")

                if cancellation_event.is_set(): return

                ui_logger.info("â¡ï¸ [é˜¶æ®µ6/6] å¼€å§‹æ„å»ºæœ€ç»ˆæ˜ å°„è¡¨...", task_category=task_cat)
                for item_id, details in media_details_map.items():
                    item_name = details.get("Name", f"ID {item_id}")
                    tmdb_id = tmdb_id_to_item_id_map.get(item_id)
                    
                    people = details.get("People", [])
                    actors = [p for p in people if p.get('Type') == 'Actor']
                    people_to_process = actors[:actor_limit]
                    
                    if not people_to_process:
                        processed_count += 1
                        task_manager.update_task_progress(task_id, processed_count, total_items)
                        continue

                    work_map = {}
                    for person in people_to_process:
                        actor_name = person.get("Name")
                        if not actor_name:
                            continue

                        person_full_details = person_details_map.get(person.get("Id"))
                        person_tmdb_id = None
                        if person_full_details:
                            provider_ids = person_full_details.get("ProviderIds", {})
                            provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                            person_tmdb_id = provider_ids_lower.get("tmdb")
                        
                        role = person.get("Role", "")
                        logging.debug(f"ã€è°ƒè¯•-æœ€ç»ˆæ•°æ®ã€‘æ¼”å‘˜: {actor_name}, è§’è‰²: {role}, TMDB ID: {person_tmdb_id}")

                        work_map[actor_name] = {
                            "tmdb_id": person_tmdb_id,
                            "role": role
                        }
                    
                    if work_map:
                        actor_role_map[str(tmdb_id)] = {
                            "title": item_name,
                            "map": work_map
                        }
                    
                    processed_count += 1
                    task_manager.update_task_progress(task_id, processed_count, total_items)

            ui_logger.info("â¡ï¸ [é˜¶æ®µ7/7] æ­£åœ¨å†™å…¥æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            try:
                with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                    with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                        json.dump(actor_role_map, f, ensure_ascii=False, indent=2)
            except Timeout:
                raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")

            total_works = len(actor_role_map)
            total_actors = sum(len(work['map']) for work in actor_role_map.values())
            
            final_log_message = f"âœ… æ˜ å°„è¡¨ç”Ÿæˆå®Œæ¯•ï¼å…±è®°å½• {total_works} éƒ¨ä½œå“ï¼Œ{total_actors} æ¡æ¼”å‘˜è§’è‰²å…³ç³»ã€‚"
            if generation_mode == 'incremental' and skipped_count > 0:
                final_log_message += f" (è·³è¿‡ {skipped_count} ä¸ªå·²å­˜åœ¨çš„ä½œå“)"
            ui_logger.info(final_log_message, task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ç”Ÿæˆæ˜ å°„è¡¨ä»»åŠ¡å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e

    def _get_github_api_url(self) -> str:
        match = re.match(r"https?://github\.com/([^/]+)/([^/]+)", self.github_config.repo_url)
        if not match:
            raise ValueError("æ— æ•ˆçš„ GitHub ä»“åº“ URLã€‚")
        owner, repo = match.groups()
        repo = repo.replace('.git', '')
        return f"https://api.github.com/repos/{owner}/{repo}/contents/{GITHUB_MAP_PATH}"

    def _github_request(self, method: str, url: str, **kwargs) -> Any:
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "Authorization": f"token {self.github_config.personal_access_token}"
        }
        proxies = self.proxy_manager.get_proxies(url)
        response = self.session.request(method, url, headers=headers, timeout=30, proxies=proxies, **kwargs)
        response.raise_for_status()
        return response.json() if response.content else None
    
    def _execute_github_write_request(self, method: str, url: str, pat: str, payload: Optional[Dict] = None) -> Dict:
        """é€šè¿‡ curl æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼ˆæ— é‡è¯•ï¼‰"""
        command = [
            'curl', '-L', '-X', method,
            '-H', 'Accept: application/vnd.github.v3+json',
            '-H', f'Authorization: token {pat}',
            '-H', 'Content-Type: application/json'
        ]
        
        json_payload_str = ""
        if payload:
            command.extend(['--data-binary', '@-'])
            json_payload_str = json.dumps(payload)

        proxies = self.proxy_manager.get_proxies(url)
        if proxies.get('https'):
            command.extend(['--proxy', proxies['https']])

        command.append(url)

        result = subprocess.run(command, input=json_payload_str, capture_output=True, text=True, check=False)
        
        response_data = {}
        try:
            if result.stdout:
                response_data = json.loads(result.stdout)
        except json.JSONDecodeError:
            raise Exception(f"cURL è¿”å›äº†éJSONå“åº”: {result.stdout or 'æ— è¾“å‡º'} | é”™è¯¯: {result.stderr or 'æ— é”™è¯¯ä¿¡æ¯'}")

        if result.returncode != 0 or (response_data.get("message") and response_data.get("documentation_url")):
            error_message = response_data.get('message', f"cURL é”™è¯¯: {result.stderr}")
            if response_data.get('status') == '422' and "sha" in error_message:
                error_message = f"æ— æ•ˆè¯·æ±‚ (422)ã€‚æœåŠ¡å™¨æç¤º 'sha' å‚æ•°æœ‰é—®é¢˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºåœ¨æ‚¨æ“ä½œæœŸé—´ï¼Œæ–‡ä»¶è¢«å…¶ä»–è¿›ç¨‹ä¿®æ”¹ã€‚è¯·é‡è¯•ã€‚({error_message})"
            elif "409 Conflict" in result.stderr:
                error_message = "GitHub API è¿”å› 409 Conflict é”™è¯¯ï¼Œè¿™é€šå¸¸æ˜¯å¹¶å‘å†™å…¥å†²çªå¯¼è‡´çš„ã€‚è¯·ç¨åé‡è¯•ã€‚"
            elif "schannel: failed to receive handshake" in result.stderr or "curl: (35)" in result.stderr:
                error_message = f"SSL/TLS æ¡æ‰‹å¤±è´¥ã€‚è¿™é€šå¸¸æ˜¯ä¸´æ—¶çš„ç½‘ç»œæˆ–ä»£ç†é—®é¢˜ã€‚é”™è¯¯: {result.stderr}"
            raise Exception(f"GitHub API é”™è¯¯: {error_message}")

        return response_data
    
    def _execute_github_write_request_with_retry(self, method: str, url: str, pat: str, payload: Optional[Dict] = None, task_cat: str = "GitHubå†™å…¥") -> Dict:
        """
        æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼Œå¹¶å¢åŠ äº†é’ˆå¯¹ç½‘ç»œé”™è¯¯çš„é‡è¯•é€»è¾‘ã€‚
        """
        max_retries = 3
        retry_delay = 5  # seconds
        for attempt in range(max_retries):
            try:
                return self._execute_github_write_request(method, url, pat, payload)
            except Exception as e:
                error_str = str(e).lower()
                if "ssl/tls" in error_str or "handshake" in error_str or "curl: (35)" in error_str:
                    if attempt < max_retries - 1:
                        ui_logger.warning(f"  - âš ï¸ ç½‘ç»œæ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•... åŸå› : {e}", task_category=task_cat)
                        time.sleep(retry_delay)
                        continue
                raise e
        raise Exception("é‡è¯•é€»è¾‘æ‰§è¡Œå®Œæ¯•ä½†æœªèƒ½æˆåŠŸã€‚")

    def upload_to_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ä¸Šä¼ "
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä¸Šä¼ æ˜ å°„è¡¨åˆ° GitHub...", task_category=task_cat)

        if not self.github_config.repo_url or not self.github_config.personal_access_token:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URL æˆ–ä¸ªäººè®¿é—®ä»¤ç‰Œ (PAT)ã€‚")

        if not os.path.exists(ACTOR_ROLE_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°æ˜ å°„è¡¨æ–‡ä»¶ actor_role_map.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆã€‚")

        try:
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/3] æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            content_b64 = base64.b64encode(content.encode('utf-8')).decode('utf-8')
            api_url = self._get_github_api_url()

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/3] æ­£åœ¨æ£€æŸ¥è¿œç¨‹æ–‡ä»¶çŠ¶æ€...", task_category=task_cat)
            sha = None
            try:
                remote_file = self._github_request("GET", api_url)
                if remote_file:
                    sha = remote_file.get('sha')
                    ui_logger.info("  - æ£€æµ‹åˆ°è¿œç¨‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†æ‰§è¡Œè¦†ç›–æ“ä½œã€‚", task_category=task_cat)
            except Exception:
                ui_logger.info("  - è¿œç¨‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†æ‰§è¡Œåˆ›å»ºæ“ä½œã€‚", task_category=task_cat)

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ3/3] æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...", task_category=task_cat)
            payload = {
                "message": f"feat: Update actor role map ({time.strftime('%Y-%m-%d %H:%M:%S')})",
                "content": content_b64,
                "branch": self.github_config.branch
            }
            if sha:
                payload["sha"] = sha
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨æ–°çš„åŸºäº curl çš„ä¸Šä¼ æ–¹æ³• ---
            self._execute_github_write_request_with_retry("PUT", api_url, self.github_config.personal_access_token, payload, task_cat=task_cat)
            # --- ä¿®æ”¹ç»“æŸ ---
            
            ui_logger.info("âœ… ä¸Šä¼ æˆåŠŸï¼æ˜ å°„è¡¨å·²åŒæ­¥åˆ° GitHub ä»“åº“ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä¸Šä¼ åˆ° GitHub å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e

    def download_from_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-ä¸‹è½½"
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä» GitHub ä¸‹è½½æ˜ å°„è¡¨...", task_category=task_cat)

        if not self.github_config.repo_url:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URLã€‚")

        try:
            api_url = self._get_github_api_url()
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/2] æ­£åœ¨ä¸‹è½½è¿œç¨‹æ–‡ä»¶...", task_category=task_cat)
            
            remote_file = self._github_request("GET", api_url)
            if not remote_file or 'content' not in remote_file:
                raise ValueError("ä» GitHub è·å–æ–‡ä»¶å†…å®¹å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©ºã€‚")

            content = base64.b64decode(remote_file['content']).decode('utf-8')

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/2] æ­£åœ¨å†™å…¥æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            try:
                with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                    with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                        f.write(content)
            except Timeout:
                raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")

            ui_logger.info("âœ… ä¸‹è½½æˆåŠŸï¼æœ¬åœ°æ˜ å°„è¡¨å·²æ›´æ–°ä¸º GitHub ç‰ˆæœ¬ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä» GitHub ä¸‹è½½å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e
        
    def restore_single_map_task(self, item_ids: List[str], role_map: Dict, title: str, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        æ ¹æ®æ˜ å°„å…³ç³»ï¼Œæ¢å¤æŒ‡å®š Emby åª’ä½“é¡¹åˆ—è¡¨çš„æ¼”å‘˜è§’è‰²åã€‚
        æ–°ç‰ˆé€»è¾‘ï¼šä»¥æ˜ å°„è¡¨ä¸ºé©±åŠ¨ï¼ŒIDä¼˜å…ˆï¼Œåç§°é™çº§ã€‚
        """
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-æ¢å¤"
        
        if not item_ids or not role_map:
            ui_logger.error(f"âŒ ä»»åŠ¡å¤±è´¥ï¼šä¼ å…¥çš„æ˜ å°„æ•°æ®ä¸å®Œæ•´ã€‚ä½œå“: {title}", task_category=task_cat)
            raise ValueError("æ˜ å°„æ•°æ®ä¸å®Œæ•´")

        total_items = len(item_ids)
        # æ³¨æ„ï¼šè¿™é‡Œçš„è¿›åº¦æ¡æ˜¯é’ˆå¯¹å•ä¸ªä½œå“çš„å¤šä¸ªEmbyå®ä¾‹ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ‰¹é‡ä»»åŠ¡
        # task_manager.update_task_progress(task_id, 0, total_items)
        ui_logger.info(f"  â¡ï¸ å¼€å§‹ä¸ºä½œå“ã€Š{title}ã€‹æ¢å¤æ¼”å‘˜è§’è‰²ï¼Œå…±æ¶‰åŠ {total_items} ä¸ªEmbyåª’ä½“é¡¹ã€‚", task_category=task_cat)

        for i, item_id in enumerate(item_ids):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                return

            try:
                ui_logger.info(f"     - æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_items} ä¸ªåª’ä½“é¡¹ (ID: {item_id})...", task_category=task_cat)
                
                # 1. è·å–å¹¶é¢„å¤„ç† Emby æ¼”å‘˜åˆ—è¡¨
                item_details = self._get_emby_item_details(item_id, "People")
                current_people = item_details.get("People", [])
                if not current_people:
                    ui_logger.info(f"       - [è·³è¿‡] åª’ä½“é¡¹ {item_id} æ²¡æœ‰æ¼”èŒå‘˜ä¿¡æ¯ã€‚", task_category=task_cat)
                    continue

                emby_actors_by_id = {}
                emby_actors_by_name = {}
                for person in current_people:
                    if person.get("Type") == "Actor":
                        provider_ids_lower = {k.lower(): v for k, v in person.get("ProviderIds", {}).items()}
                        person_tmdb_id = provider_ids_lower.get("tmdb")
                        if person_tmdb_id:
                            emby_actors_by_id[str(person_tmdb_id)] = person
                        emby_actors_by_name[person.get("Name")] = person

                # 2. éå†æ˜ å°„è¡¨ï¼Œè¿›è¡ŒåŒ¹é…å’Œæ›´æ–°
                has_changes = False
                updated_logs = []
                for map_actor_name, map_actor_data in role_map.items():
                    map_tmdb_id = map_actor_data.get("tmdb_id")
                    target_emby_person = None

                    # a. ID ä¼˜å…ˆåŒ¹é…
                    if map_tmdb_id and str(map_tmdb_id) != "null":
                        target_emby_person = emby_actors_by_id.get(str(map_tmdb_id))
                        if target_emby_person:
                            logging.debug(f"ã€è°ƒè¯•ã€‘[IDåŒ¹é…æˆåŠŸ] æ˜ å°„è¡¨æ¼”å‘˜ [{map_actor_name}] é€šè¿‡ TMDB ID {map_tmdb_id} å…³è”åˆ° Emby æ¼”å‘˜ [{target_emby_person.get('Name')}]ã€‚")

                    # b. åç§°é™çº§åŒ¹é…
                    if not target_emby_person:
                        target_emby_person = emby_actors_by_name.get(map_actor_name)
                        if target_emby_person:
                            logging.debug(f"ã€è°ƒè¯•ã€‘[åç§°åŒ¹é…æˆåŠŸ] æ˜ å°„è¡¨æ¼”å‘˜ [{map_actor_name}] é€šè¿‡åç§°å…³è”åˆ° Emby æ¼”å‘˜ã€‚")
                    
                    # c. å¯¹æ¯”ä¸æ›´æ–°
                    if target_emby_person:
                        current_role = target_emby_person.get("Role", "")
                        target_role = map_actor_data.get("role", "")
                        if current_role != target_role:
                            target_emby_person["Role"] = target_role
                            has_changes = True
                            updated_logs.append(f"       - âœ… æ¼”å‘˜ [{target_emby_person.get('Name')}] è§’è‰²å·²æ›´æ–°: '{current_role}' â†’ '{target_role}'")
                    else:
                        logging.debug(f"ã€è°ƒè¯•ã€‘[åŒ¹é…å¤±è´¥] åœ¨ Emby åª’ä½“é¡¹ {item_id} ä¸­æœªæ‰¾åˆ°æ¼”å‘˜ [{map_actor_name}]ã€‚")

                # 3. å¦‚æœæœ‰å˜æ›´ï¼Œåˆ™å†™å› Emby
                if has_changes:
                    ui_logger.info(f"     - å‘ç°è§’è‰²å˜æ›´ï¼Œæ­£åœ¨å†™å› Emby...", task_category=task_cat)
                    item_details["People"] = current_people
                    
                    update_url = f"{self.server_config.server}/Items/{item_id}"
                    headers = {'Content-Type': 'application/json'}
                    params = {"api_key": self.server_config.api_key}
                    proxies = self.proxy_manager.get_proxies(update_url)
                    
                    response = self.session.post(update_url, params=params, json=item_details, headers=headers, timeout=30, proxies=proxies)
                    response.raise_for_status()
                    
                    for log_line in updated_logs:
                        ui_logger.info(log_line, task_category=task_cat)
                    ui_logger.info(f"     - âœ… åª’ä½“é¡¹ (ID: {item_id}) æ›´æ–°æˆåŠŸï¼", task_category=task_cat)
                else:
                    ui_logger.info(f"     - è§’è‰²åå‡ä¸æ˜ å°„è¡¨ä¸€è‡´ï¼Œæ— éœ€æ›´æ–°ã€‚", task_category=task_cat)

            except Exception as e:
                ui_logger.error(f"  - âŒ å¤„ç†åª’ä½“é¡¹ {item_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat, exc_info=True)


    def update_single_map_file(self, single_map_data: Dict):
        """
        æ ¹æ®ä¼ å…¥çš„å•æ¡æ˜ å°„æ•°æ®ï¼Œæ›´æ–°æœ¬åœ°çš„ actor_role_map.json æ–‡ä»¶ã€‚
        """
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-æ–‡ä»¶æ›´æ–°"
        tmdb_id = single_map_data.get("tmdb_id")
        if not tmdb_id:
            raise ValueError("ä¼ å…¥çš„æ•°æ®ç¼ºå°‘ tmdb_id")

        ui_logger.info(f"â¡ï¸ å‡†å¤‡æ›´æ–°æ˜ å°„æ–‡ä»¶ï¼Œç›®æ ‡ä½œå“ TMDB ID: {tmdb_id}", task_category=task_cat)
        
        try:
            with FileLock(ACTOR_ROLE_MAP_LOCK_FILE, timeout=10):
                # 1. è¯»å–ç°æœ‰æ–‡ä»¶
                if os.path.exists(ACTOR_ROLE_MAP_FILE):
                    with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                        full_map = json.load(f)
                else:
                    full_map = {}
                
                # 2. æ›´æ–°æŒ‡å®šæ¡ç›® (ä¸å†åŒ…å« Emby_itemid)
                full_map[tmdb_id] = {
                    "title": single_map_data.get("title", "æœªçŸ¥ä½œå“"),
                    "map": single_map_data.get("map", {})
                }

                # 3. å†™å›æ–‡ä»¶
                with open(ACTOR_ROLE_MAP_FILE, 'w', encoding='utf-8') as f:
                    json.dump(full_map, f, ensure_ascii=False, indent=2)
                
                ui_logger.info(f"âœ… æˆåŠŸæ›´æ–°æ˜ å°„æ–‡ä»¶ï¼Œä½œå“: {single_map_data.get('title')}", task_category=task_cat)
                return {"status": "success", "message": "æ˜ å°„å…³ç³»å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼"}

        except Timeout:
            ui_logger.error("âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚", task_category=task_cat)
            raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")
        except Exception as e:
            ui_logger.error(f"âŒ æ›´æ–°æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            raise e
        
    def restore_roles_from_map_task(self, scope: ScheduledTasksTargetScope, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        æ ¹æ®é€šç”¨èŒƒå›´å’Œæœ¬åœ°æ˜ å°„è¡¨ï¼Œæ‰¹é‡æ¢å¤æ¼”å‘˜è§’è‰²åã€‚
        æ–°ç‰ˆé€»è¾‘ï¼šä»¥æ˜ å°„è¡¨ä¸ºé©±åŠ¨ï¼Œé€šè¿‡ id_map.json æŸ¥æ‰¾ ItemIdã€‚
        """
        task_cat = "æ¼”å‘˜è§’è‰²æ˜ å°„-æ‰¹é‡æ¢å¤"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼ŒèŒƒå›´: {scope.mode}", task_category=task_cat)

        # 1. åŠ è½½æœ¬åœ°æ˜ å°„è¡¨
        ui_logger.info("â¡ï¸ [é˜¶æ®µ1/4] æ­£åœ¨åŠ è½½æœ¬åœ°è§’è‰²æ˜ å°„è¡¨...", task_category=task_cat)
        if not os.path.exists(ACTOR_ROLE_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°è§’è‰²æ˜ å°„è¡¨æ–‡ä»¶ actor_role_map.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆã€‚")
        
        with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
            role_map = json.load(f)
        
        if not role_map:
            ui_logger.warning("âš ï¸ æœ¬åœ°è§’è‰²æ˜ å°„è¡¨ä¸ºç©ºï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåŠ è½½ id_map.json ---
        ui_logger.info("â¡ï¸ [é˜¶æ®µ2/4] æ­£åœ¨åŠ è½½ TMDB-Emby ID æ˜ å°„è¡¨...", task_category=task_cat)
        id_map_file = os.path.join('/app/data', 'id_map.json')
        if not os.path.exists(id_map_file):
            ui_logger.error("âŒ å…³é”®æ–‡ä»¶ id_map.json ä¸å­˜åœ¨ï¼è¯·å…ˆåœ¨â€œå®šæ—¶ä»»åŠ¡â€é¡µé¢ç”Ÿæˆè¯¥æ˜ å°„è¡¨ã€‚", task_category=task_cat)
            raise FileNotFoundError("IDæ˜ å°„è¡¨ (id_map.json) ä¸å­˜åœ¨ã€‚")
        with open(id_map_file, 'r', encoding='utf-8') as f:
            id_map = json.load(f)
        ui_logger.info("   - â— æç¤ºï¼šæ¢å¤æ“ä½œå°†åŸºäºæ‚¨ä¸Šä¸€æ¬¡ç”Ÿæˆçš„ `id_map.json`ã€‚ä¸ºç¡®ä¿ç»“æœå‡†ç¡®ï¼Œå»ºè®®åœ¨æ¢å¤å‰é‡æ–°ç”ŸæˆIDæ˜ å°„è¡¨ã€‚", task_category=task_cat)
        # --- ä¿®æ”¹ç»“æŸ ---

        # 2. è·å–ç›®æ ‡åª’ä½“é¡¹
        ui_logger.info("â¡ï¸ [é˜¶æ®µ3/4] æ­£åœ¨æ ¹æ®èŒƒå›´è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
        selector = MediaSelector(self.config)
        media_ids_in_scope = set(selector.get_item_ids(scope))
        if not media_ids_in_scope:
            ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
            return

        # 3. éå†æœ¬åœ°æ˜ å°„è¡¨ï¼Œæ‰§è¡Œæ¢å¤
        ui_logger.info("â¡ï¸ [é˜¶æ®µ4/4] å¼€å§‹æ ¹æ®å¤„ç†è®¡åˆ’ï¼Œé€ä¸€æ¢å¤ä½œå“...", task_category=task_cat)
        total_works_to_process = len(role_map)
        task_manager.update_task_progress(task_id, 0, total_works_to_process)
        processed_works_count = 0

        for tmdb_id, map_data in role_map.items():
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                return
            
            processed_works_count += 1
            task_manager.update_task_progress(task_id, processed_works_count, total_works_to_process)

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šé€šè¿‡ id_map æŸ¥æ‰¾ ItemIdï¼Œå¹¶ä¸èŒƒå›´æ±‚äº¤é›† ---
            emby_ids_from_map = id_map.get(str(tmdb_id), [])
            item_ids_to_process = list(media_ids_in_scope.intersection(emby_ids_from_map))
            # --- ä¿®æ”¹ç»“æŸ ---
            
            if not item_ids_to_process:
                continue

            title = map_data.get("title", f"TMDB ID {tmdb_id}")
            
            # å¤ç”¨å•ä½“æ¢å¤çš„é€»è¾‘
            self.restore_single_map_task(
                item_ids=item_ids_to_process,
                role_map=map_data.get("map", {}),
                title=title,
                cancellation_event=cancellation_event,
                task_id=task_id,
                task_manager=task_manager
            )

        ui_logger.info("ğŸ‰ æ‰¹é‡æ¢å¤æ¼”å‘˜è§’è‰²ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚", task_category=task_cat)