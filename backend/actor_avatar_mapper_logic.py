# backend/actor_avatar_mapper_logic.py (æ–°æ–‡ä»¶)

import logging
import os
import json
import threading
import time
import re
import base64
import subprocess
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from filelock import FileLock, Timeout
from datetime import datetime

from log_manager import ui_logger
from models import AppConfig, ScheduledTasksTargetScope
from task_manager import TaskManager
from media_selector import MediaSelector
from proxy_manager import ProxyManager

# --- æ–°å¢å¸¸é‡ ---
ACTOR_AVATAR_MAP_FILE = os.path.join('/app/data', 'actor_avatar_map.json')
ACTOR_AVATAR_MAP_LOCK_FILE = ACTOR_AVATAR_MAP_FILE + ".lock"
GITHUB_AVATAR_MAP_PATH = "database/actor_avatar_map.json"
# --- æ–°å¢ç»“æŸ ---

class ActorAvatarMapperLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.server_config = config.server_config
        self.github_config = config.episode_refresher_config.github_config
        self.proxy_manager = ProxyManager(config)
        self.session = self._create_session()

    def _create_session(self):
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        session = requests.Session()
        retry_strategy = Retry(
            total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session

    # backend/actor_avatar_mapper_logic.py (å‡½æ•°æ›¿æ¢)

    def save_avatar_choice_to_map(self, tmdb_person_id: int, image_info: Dict[str, Any]):
        """
        å°†ç”¨æˆ·çš„å¤´åƒé€‰æ‹©ä¿å­˜åˆ°æœ¬åœ°çš„ JSON æ˜ å°„æ–‡ä»¶ä¸­ã€‚
        è¿™æ˜¯ä¸€ä¸ªæ ¸å¿ƒçš„"è®°å¿†"åŠŸèƒ½ã€‚
        """
        task_cat = "æ¼”å‘˜å¤´åƒæ˜ å°„-ä¿å­˜"
        # --- æ–°å¢ ---
        ui_logger.debug(f"â¡ï¸ [è°ƒè¯•-åç«¯] æ­¥éª¤8: è¿›å…¥æœ€ç»ˆä¿å­˜å‡½æ•°ã€‚æ¥æ”¶åˆ° tmdb_person_id: {tmdb_person_id}", task_category=task_cat)
        # --- æ–°å¢ç»“æŸ ---
        if not tmdb_person_id:
            ui_logger.warning("âš ï¸ ç¼ºå°‘ TMDB Person IDï¼Œæ— æ³•ä¿å­˜å¤´åƒé€‰æ‹©ã€‚", task_category=task_cat)
            return

        ui_logger.info(f"â¡ï¸ å‡†å¤‡ä¸ºæ¼”å‘˜ (TMDB ID: {tmdb_person_id}) ä¿å­˜å¤´åƒé€‰æ‹©...", task_category=task_cat)
        
        try:
            with FileLock(ACTOR_AVATAR_MAP_LOCK_FILE, timeout=10):
                if os.path.exists(ACTOR_AVATAR_MAP_FILE):
                    with open(ACTOR_AVATAR_MAP_FILE, 'r', encoding='utf-8') as f:
                        full_map = json.load(f)
                else:
                    full_map = {}
                
                # æ›´æ–°æˆ–åˆ›å»ºæ¡ç›®
                full_map[str(tmdb_person_id)] = {
                    "actor_name": image_info.get("actor_name", "æœªçŸ¥æ¼”å‘˜"),
                    "source": image_info.get("source"),
                    "image_path": image_info.get("image_path"),
                    "last_updated": datetime.utcnow().isoformat() + "Z"
                }

                with open(ACTOR_AVATAR_MAP_FILE, 'w', encoding='utf-8') as f:
                    json.dump(full_map, f, ensure_ascii=False, indent=2)
                
                ui_logger.info(f"âœ… æˆåŠŸä¸ºæ¼”å‘˜ (TMDB ID: {tmdb_person_id}) æ›´æ–°äº†å¤´åƒæ˜ å°„ã€‚", task_category=task_cat)

        except Timeout:
            ui_logger.error("âŒ æ›´æ–°æ˜ å°„æ–‡ä»¶å¤±è´¥ï¼šè·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒ æ›´æ–°æ˜ å°„æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)

    def _get_github_api_url(self) -> str:
        """æ ¹æ®é…ç½®ç”ŸæˆæŒ‡å‘ actor_avatar_database.json çš„ GitHub API URL"""
        match = re.match(r"https?://github\.com/([^/]+)/([^/]+)", self.github_config.repo_url)
        if not match:
            raise ValueError("æ— æ•ˆçš„ GitHub ä»“åº“ URLã€‚")
        owner, repo = match.groups()
        repo = repo.replace('.git', '')
        return f"https://api.github.com/repos/{owner}/{repo}/contents/{GITHUB_AVATAR_MAP_PATH}"

    def _github_request(self, method: str, url: str, **kwargs) -> Any:
        """é€šç”¨çš„ GitHub API è¯·æ±‚å‡½æ•°"""
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "Authorization": f"token {self.github_config.personal_access_token}"
        }
        proxies = self.proxy_manager.get_proxies(url)
        response = self.session.request(method, url, headers=headers, timeout=30, proxies=proxies, **kwargs)
        response.raise_for_status()
        return response.json() if response.content else None
    
    def _execute_github_write_request(self, method: str, url: str, pat: str, payload: Optional[Dict] = None) -> Dict:
        """é€šè¿‡ curl æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼ˆæ— é‡è¯•ï¼‰"""
        command = [
            'curl', '-L', '-X', method,
            '-H', 'Accept: application/vnd.github.v3+json',
            '-H', f'Authorization: token {pat}',
            '-H', 'Content-Type: application/json'
        ]
        
        json_payload_str = ""
        if payload:
            command.extend(['--data-binary', '@-'])
            json_payload_str = json.dumps(payload)

        proxies = self.proxy_manager.get_proxies(url)
        if proxies.get('https'):
            command.extend(['--proxy', proxies['https']])

        command.append(url)

        result = subprocess.run(command, input=json_payload_str, capture_output=True, text=True, check=False)
        
        response_data = {}
        try:
            if result.stdout:
                response_data = json.loads(result.stdout)
        except json.JSONDecodeError:
            raise Exception(f"cURL è¿”å›äº†éJSONå“åº”: {result.stdout or 'æ— è¾“å‡º'} | é”™è¯¯: {result.stderr or 'æ— é”™è¯¯ä¿¡æ¯'}")

        if result.returncode != 0 or (response_data.get("message") and response_data.get("documentation_url")):
            error_message = response_data.get('message', f"cURL é”™è¯¯: {result.stderr}")
            if response_data.get('status') == '422' and "sha" in error_message:
                error_message = f"æ— æ•ˆè¯·æ±‚ (422)ã€‚æœåŠ¡å™¨æç¤º 'sha' å‚æ•°æœ‰é—®é¢˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºåœ¨æ‚¨æ“ä½œæœŸé—´ï¼Œæ–‡ä»¶è¢«å…¶ä»–è¿›ç¨‹ä¿®æ”¹ã€‚è¯·é‡è¯•ã€‚({error_message})"
            elif "409 Conflict" in result.stderr:
                error_message = "GitHub API è¿”å› 409 Conflict é”™è¯¯ï¼Œè¿™é€šå¸¸æ˜¯å¹¶å‘å†™å…¥å†²çªå¯¼è‡´çš„ã€‚è¯·ç¨åé‡è¯•ã€‚"
            elif "schannel: failed to receive handshake" in result.stderr or "curl: (35)" in result.stderr:
                error_message = f"SSL/TLS æ¡æ‰‹å¤±è´¥ã€‚è¿™é€šå¸¸æ˜¯ä¸´æ—¶çš„ç½‘ç»œæˆ–ä»£ç†é—®é¢˜ã€‚é”™è¯¯: {result.stderr}"
            raise Exception(f"GitHub API é”™è¯¯: {error_message}")

        return response_data
    
    def _execute_github_write_request_with_retry(self, method: str, url: str, pat: str, payload: Optional[Dict] = None, task_cat: str = "GitHubå†™å…¥") -> Dict:
        """
        æ‰§è¡Œ GitHub å†™å…¥æ“ä½œï¼Œå¹¶å¢åŠ äº†é’ˆå¯¹ç½‘ç»œé”™è¯¯çš„é‡è¯•é€»è¾‘ã€‚
        """
        max_retries = 3
        retry_delay = 5  # seconds
        for attempt in range(max_retries):
            try:
                return self._execute_github_write_request(method, url, pat, payload)
            except Exception as e:
                error_str = str(e).lower()
                if "ssl/tls" in error_str or "handshake" in error_str or "curl: (35)" in error_str:
                    if attempt < max_retries - 1:
                        ui_logger.warning(f"  - âš ï¸ ç½‘ç»œæ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•... åŸå› : {e}", task_category=task_cat)
                        time.sleep(retry_delay)
                        continue
                raise e
        raise Exception("é‡è¯•é€»è¾‘æ‰§è¡Œå®Œæ¯•ä½†æœªèƒ½æˆåŠŸã€‚")

    def upload_to_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜å¤´åƒæ˜ å°„-ä¸Šä¼ "
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä¸Šä¼ æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨åˆ° GitHub...", task_category=task_cat)

        if not self.github_config.repo_url or not self.github_config.personal_access_token:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URL æˆ–ä¸ªäººè®¿é—®ä»¤ç‰Œ (PAT)ã€‚")

        if not os.path.exists(ACTOR_AVATAR_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨æ–‡ä»¶ actor_avatar_map.json ä¸å­˜åœ¨ã€‚")

        try:
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/3] æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            with open(ACTOR_AVATAR_MAP_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            content_b64 = base64.b64encode(content.encode('utf-8')).decode('utf-8')
            api_url = self._get_github_api_url()

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/3] æ­£åœ¨æ£€æŸ¥è¿œç¨‹æ–‡ä»¶çŠ¶æ€...", task_category=task_cat)
            sha = None
            try:
                remote_file = self._github_request("GET", api_url)
                if remote_file:
                    sha = remote_file.get('sha')
                    ui_logger.info("  - æ£€æµ‹åˆ°è¿œç¨‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†æ‰§è¡Œè¦†ç›–æ“ä½œã€‚", task_category=task_cat)
            except Exception:
                ui_logger.info("  - è¿œç¨‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†æ‰§è¡Œåˆ›å»ºæ“ä½œã€‚", task_category=task_cat)

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ3/3] æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...", task_category=task_cat)
            payload = {
                "message": f"feat: Update actor avatar map ({time.strftime('%Y-%m-%d %H:%M:%S')})",
                "content": content_b64,
                "branch": self.github_config.branch
            }
            if sha:
                payload["sha"] = sha
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨æ–°çš„åŸºäº curl çš„ä¸Šä¼ æ–¹æ³• ---
            self._execute_github_write_request_with_retry("PUT", api_url, self.github_config.personal_access_token, payload, task_cat=task_cat)
            # --- ä¿®æ”¹ç»“æŸ ---
            
            ui_logger.info("âœ… ä¸Šä¼ æˆåŠŸï¼æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨å·²åŒæ­¥åˆ° GitHub ä»“åº“ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä¸Šä¼ åˆ° GitHub å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e

    def download_from_github_task(self, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜å¤´åƒæ˜ å°„-ä¸‹è½½"
        ui_logger.info("ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹ä» GitHub ä¸‹è½½æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨...", task_category=task_cat)

        if not self.github_config.repo_url:
            raise ValueError("æœªé…ç½® GitHub ä»“åº“ URLã€‚")

        try:
            api_url = self._get_github_api_url()
            ui_logger.info("â¡ï¸ [é˜¶æ®µ1/2] æ­£åœ¨ä¸‹è½½è¿œç¨‹æ–‡ä»¶...", task_category=task_cat)
            
            remote_file = self._github_request("GET", api_url)
            if not remote_file or 'content' not in remote_file:
                raise ValueError("ä» GitHub è·å–æ–‡ä»¶å†…å®¹å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©ºã€‚")

            content = base64.b64decode(remote_file['content']).decode('utf-8')

            if cancellation_event.is_set(): return

            ui_logger.info("â¡ï¸ [é˜¶æ®µ2/2] æ­£åœ¨å†™å…¥æœ¬åœ°æ–‡ä»¶...", task_category=task_cat)
            try:
                with FileLock(ACTOR_AVATAR_MAP_LOCK_FILE, timeout=10):
                    with open(ACTOR_AVATAR_MAP_FILE, 'w', encoding='utf-8') as f:
                        f.write(content)
            except Timeout:
                raise IOError("è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨è®¿é—®è¯¥æ–‡ä»¶ã€‚")

            ui_logger.info("âœ… ä¸‹è½½æˆåŠŸï¼æœ¬åœ°æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨å·²æ›´æ–°ä¸º GitHub ç‰ˆæœ¬ã€‚", task_category=task_cat)

        except Exception as e:
            ui_logger.error(f"âŒ ä» GitHub ä¸‹è½½å¤±è´¥: {e}", task_category=task_cat, exc_info=True)
            raise e
        
    def restore_single_avatar_task(self, actor_info: Dict[str, Any], scope: ScheduledTasksTargetScope, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        """
        æ ¹æ®æŒ‡å®šçš„æ¼”å‘˜ä¿¡æ¯å’ŒèŒƒå›´ï¼Œæ¢å¤å•ä¸ªæ¼”å‘˜çš„å¤´åƒã€‚
        """
        actor_name = actor_info.get("actor_name", "æœªçŸ¥")
        tmdb_id_to_find = actor_info.get("tmdb_id")
        task_cat = f"æ¼”å‘˜å¤´åƒæ˜ å°„-æ¢å¤-{actor_name}"

        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼Œå‡†å¤‡ä¸ºæ¼”å‘˜ã€{actor_name}ã€‘(TMDB ID: {tmdb_id_to_find})æ¢å¤å¤´åƒ...", task_category=task_cat)

        # 1. è·å–èŒƒå›´å†…çš„æ‰€æœ‰æ¼”å‘˜
        ui_logger.info("â¡ï¸ [é˜¶æ®µ1/3] æ­£åœ¨æ ¹æ®èŒƒå›´è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
        selector = MediaSelector(self.config)
        media_ids_in_scope = selector.get_item_ids(scope)
        if not media_ids_in_scope:
            ui_logger.warning("âš ï¸ åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œæ— æ³•æ‰¾åˆ°è¯¥æ¼”å‘˜ã€‚", task_category=task_cat)
            return

        ui_logger.info(f"â¡ï¸ [é˜¶æ®µ2/3] å·²è·å– {len(media_ids_in_scope)} ä¸ªåª’ä½“é¡¹ï¼Œå¼€å§‹å¹¶å‘æŸ¥æ‰¾æ¼”å‘˜...", task_category=task_cat)
        
        emby_actor_to_update = None
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(selector._get_emby_item_details, item_id, "People"): item_id for item_id in media_ids_in_scope}
            for future in as_completed(future_to_id):
                if cancellation_event.is_set() or emby_actor_to_update:
                    break
                try:
                    people = future.result().get("People", [])
                    for person in people:
                        if person.get('Type') == 'Actor':
                            # ä¸ºæ¯ä¸ªæ¼”å‘˜è·å–å…¶ ProviderIds
                            person_details = selector._get_emby_item_details(person['Id'], "ProviderIds")
                            provider_ids = person_details.get("ProviderIds", {})
                            provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                            person_tmdb_id = provider_ids_lower.get("tmdb")
                            if str(person_tmdb_id) == str(tmdb_id_to_find):
                                emby_actor_to_update = person_details
                                ui_logger.info(f"   - âœ… åœ¨åª’ä½“é¡¹ {future_to_id[future]} ä¸­æ‰¾åˆ°äº†ç›®æ ‡æ¼”å‘˜ã€{actor_name}ã€‘(Emby ID: {emby_actor_to_update['Id']})ã€‚", task_category=task_cat)
                                break
                except Exception as e:
                    logging.error(f"ã€è°ƒè¯•ã€‘æŸ¥æ‰¾æ¼”å‘˜æ—¶å‡ºé”™: {e}")
        
        if cancellation_event.is_set():
            ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨æŸ¥æ‰¾æ¼”å‘˜é˜¶æ®µè¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
            return

        if not emby_actor_to_update:
            ui_logger.error(f"âŒ åœ¨æŒ‡å®šèŒƒå›´å†…æœªèƒ½æ‰¾åˆ° TMDB ID ä¸º {tmdb_id_to_find} çš„æ¼”å‘˜ã€{actor_name}ã€‘ã€‚", task_category=task_cat)
            return

        # 3. æ‰§è¡Œæ¢å¤
        ui_logger.info("â¡ï¸ [é˜¶æ®µ3/3] æ¼”å‘˜å·²å®šä½ï¼Œå¼€å§‹æ‰§è¡Œæ¢å¤...", task_category=task_cat)
        from actor_gallery_logic import ActorGalleryLogic
        from tmdb_logic import TMDB_IMAGE_BASE_URL, TMDB_IMAGE_SIZES

        gallery_logic = ActorGalleryLogic(self.config)
        
        image_source = actor_info.get("source")
        image_path = actor_info.get("image_path")

        if image_source == 'tmdb':
            image_url = f"{TMDB_IMAGE_BASE_URL}{TMDB_IMAGE_SIZES['original']}{image_path}"
        else:
            image_url = image_path

        if gallery_logic.upload_image_from_url(emby_actor_to_update['Id'], image_url, source=image_source):
            ui_logger.info(f"ğŸ‰ æˆåŠŸä¸ºæ¼”å‘˜ã€{actor_name}ã€‘æ¢å¤äº†å¤´åƒï¼", task_category=task_cat)
        else:
            ui_logger.error(f"âŒ ä¸ºæ¼”å‘˜ã€{actor_name}ã€‘æ¢å¤å¤´åƒå¤±è´¥ã€‚", task_category=task_cat)

    def restore_avatars_task(self, scope: ScheduledTasksTargetScope, cancellation_event: threading.Event, task_id: str, task_manager: TaskManager):
        task_cat = "æ¼”å‘˜å¤´åƒæ˜ å°„-æ‰¹é‡æ¢å¤"
        ui_logger.info(f"ğŸ‰ ä»»åŠ¡å¯åŠ¨ï¼ŒèŒƒå›´: {scope.mode}ï¼Œå¼€å§‹æ‰¹é‡æ¢å¤æ¼”å‘˜å¤´åƒ...", task_category=task_cat)

        # 1. åŠ è½½æœ¬åœ°æ˜ å°„è¡¨
        ui_logger.info("â¡ï¸ [é˜¶æ®µ1/5] æ­£åœ¨åŠ è½½æœ¬åœ°å¤´åƒæ˜ å°„è¡¨...", task_category=task_cat)
        if not os.path.exists(ACTOR_AVATAR_MAP_FILE):
            raise FileNotFoundError("æœ¬åœ°æ¼”å‘˜å¤´åƒæ˜ å°„è¡¨æ–‡ä»¶ actor_avatar_map.json ä¸å­˜åœ¨ã€‚")
        
        with open(ACTOR_AVATAR_MAP_FILE, 'r', encoding='utf-8') as f:
            avatar_map = json.load(f)
        
        if not avatar_map:
            ui_logger.warning("âš ï¸ æœ¬åœ°å¤´åƒæ˜ å°„è¡¨ä¸ºç©ºï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return

        # 2. è·å–ç›®æ ‡åª’ä½“é¡¹
        ui_logger.info("â¡ï¸ [é˜¶æ®µ2/5] æ­£åœ¨æ ¹æ®èŒƒå›´è·å–åª’ä½“åˆ—è¡¨...", task_category=task_cat)
        selector = MediaSelector(self.config)
        media_ids_in_scope = selector.get_item_ids(scope)
        if not media_ids_in_scope:
            ui_logger.info("âœ… åœ¨æŒ‡å®šèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•åª’ä½“é¡¹ï¼Œä»»åŠ¡å®Œæˆã€‚", task_category=task_cat)
            return

        # 3. è·å–æ‰€æœ‰åª’ä½“é¡¹ä¸‹çš„æ‰€æœ‰æ¼”å‘˜
        ui_logger.info(f"â¡ï¸ [é˜¶æ®µ3/5] å·²è·å– {len(media_ids_in_scope)} ä¸ªåª’ä½“é¡¹ï¼Œå¼€å§‹å¹¶å‘è·å–æ‰€æœ‰æ¼”å‘˜ä¿¡æ¯...", task_category=task_cat)
        
        all_actors_to_check = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(selector._get_emby_item_details, item_id, "People"): item_id for item_id in media_ids_in_scope}
            for future in as_completed(future_to_id):
                if cancellation_event.is_set(): return
                try:
                    people = future.result().get("People", [])
                    actors = [p for p in people if p.get('Type') == 'Actor']
                    all_actors_to_check.extend(actors)
                except Exception as e:
                    logging.error(f"ã€è°ƒè¯•ã€‘è·å–åª’ä½“ {future_to_id[future]} çš„æ¼”å‘˜åˆ—è¡¨å¤±è´¥: {e}")

        unique_actors_base_info = {actor['Id']: actor for actor in all_actors_to_check}.values()
        ui_logger.info(f"   - æ¼”å‘˜ä¿¡æ¯è·å–å®Œæ¯•ï¼Œå…±æ‰¾åˆ° {len(unique_actors_base_info)} ä¸ªä¸é‡å¤çš„æ¼”å‘˜éœ€è¦æ£€æŸ¥ã€‚", task_category=task_cat)

        ui_logger.info(f"â¡ï¸ [é˜¶æ®µ4/5] å¼€å§‹ä¸º {len(unique_actors_base_info)} ä¸ªç‹¬ç«‹æ¼”å‘˜å¹¶å‘è·å–è¯¦ç»†ä¿¡æ¯ (ProviderIds)...", task_category=task_cat)
        unique_actors_with_details = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_actor = {executor.submit(selector._get_emby_item_details, actor['Id'], "ProviderIds,Name"): actor for actor in unique_actors_base_info}
            for future in as_completed(future_to_actor):
                if cancellation_event.is_set(): return
                try:
                    full_actor_details = future.result()
                    unique_actors_with_details.append(full_actor_details)
                except Exception as e:
                    actor_info = future_to_actor[future]
                    logging.error(f"ã€è°ƒè¯•ã€‘è·å–æ¼”å‘˜ã€{actor_info.get('Name')}ã€‘(ID: {actor_info.get('Id')})çš„è¯¦æƒ…å¤±è´¥: {e}")
        
        ui_logger.info(f"   - æ¼”å‘˜è¯¦ç»†ä¿¡æ¯è·å–å®Œæ¯•ï¼Œå…±æˆåŠŸè·å– {len(unique_actors_with_details)} ä½æ¼”å‘˜çš„è¯¦æƒ…ã€‚", task_category=task_cat)

        # 5. åŒ¹é…å¹¶æ‰§è¡Œæ¢å¤
        ui_logger.info("â¡ï¸ [é˜¶æ®µ5/5] å¼€å§‹åŒ¹é…æ˜ å°„è¡¨å¹¶æ¢å¤å¤´åƒ...", task_category=task_cat)
        total_actors = len(unique_actors_with_details)
        task_manager.update_task_progress(task_id, 0, total_actors)
        
        from actor_gallery_logic import ActorGalleryLogic
        from tmdb_logic import TMDB_IMAGE_BASE_URL, TMDB_IMAGE_SIZES

        gallery_logic = ActorGalleryLogic(self.config)
        updated_count = 0

        for i, actor in enumerate(unique_actors_with_details):
            if cancellation_event.is_set():
                ui_logger.warning("âš ï¸ ä»»åŠ¡åœ¨æ¢å¤é˜¶æ®µè¢«ç”¨æˆ·å–æ¶ˆã€‚", task_category=task_cat)
                return

            try:
                provider_ids = actor.get("ProviderIds", {})
                provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                tmdb_id = provider_ids_lower.get("tmdb")
                
                if not tmdb_id:
                    continue

                if str(tmdb_id) in avatar_map:
                    map_entry = avatar_map[str(tmdb_id)]
                    actor_name = actor.get("Name")
                    ui_logger.info(f"  - [å‘½ä¸­] æ¼”å‘˜ã€{actor_name}ã€‘(TMDB ID: {tmdb_id}) åœ¨æ˜ å°„è¡¨ä¸­ï¼Œå‡†å¤‡æ¢å¤...", task_category=task_cat)

                    image_source = map_entry.get("source")
                    image_path = map_entry.get("image_path")
                    
                    if not image_source or not image_path:
                        ui_logger.warning(f"    - [è·³è¿‡] æ¼”å‘˜ã€{actor_name}ã€‘çš„æ˜ å°„ä¿¡æ¯ä¸å®Œæ•´ã€‚", task_category=task_cat)
                        continue

                    if image_source == 'tmdb':
                        image_url = f"{TMDB_IMAGE_BASE_URL}{TMDB_IMAGE_SIZES['original']}{image_path}"
                    else: # douban
                        image_url = image_path
                    
                    if gallery_logic.upload_image_from_url(actor['Id'], image_url, source=image_source):
                        ui_logger.info(f"    - âœ… æˆåŠŸä¸ºæ¼”å‘˜ã€{actor_name}ã€‘æ¢å¤å¤´åƒã€‚", task_category=task_cat)
                        updated_count += 1
                    else:
                        ui_logger.error(f"    - âŒ ä¸ºæ¼”å‘˜ã€{actor_name}ã€‘æ¢å¤å¤´åƒå¤±è´¥ã€‚", task_category=task_cat)
            except Exception as e:
                ui_logger.error(f"  - âŒ å¤„ç†æ¼”å‘˜ {actor.get('Name')} (ID: {actor.get('Id')}) æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            finally:
                task_manager.update_task_progress(task_id, i + 1, total_actors)
        
        ui_logger.info(f"ğŸ‰ æ‰¹é‡æ¢å¤æ¼”å‘˜å¤´åƒä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œå…±æˆåŠŸæ¢å¤äº† {updated_count} ä¸ªæ¼”å‘˜çš„å¤´åƒã€‚", task_category=task_cat)