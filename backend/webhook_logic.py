# backend/webhook_logic.py (æœ€ç»ˆä¿®å¤ç‰ˆ)

import logging
import threading
import time
import os
import json
from datetime import datetime

from log_manager import ui_logger
from models import AppConfig, WebhookConfig
from task_manager import TaskManager
import config as app_config

from douban_fixer_logic import DoubanFixerLogic
from actor_localizer_logic import ActorLocalizerLogic
from douban_poster_updater_logic import DoubanPosterUpdaterLogic
from douban_manager import DOUBAN_CACHE_FILE, _parse_folder_name

class WebhookLogic:
    def __init__(self, config: AppConfig):
        self.config = config
        self.server_config = config.server_config
        self.webhook_config = getattr(config, 'webhook_config', WebhookConfig())
        self.processed_flag_key = "ToolboxWebhookProcessed"

    def _get_emby_item_details(self, item_id: str, fields: str = "ProviderIds,Name,Type"):
        import requests
        url = f"{self.server_config.server}/Users/{self.server_config.user_id}/Items/{item_id}"
        params = {"api_key": self.server_config.api_key, "Fields": fields}
        try:
            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logging.error(f"ã€Webhookã€‘è·å– Emby åª’ä½“è¯¦æƒ… (ID: {item_id}) å¤±è´¥: {e}")
            return None

    def _set_processed_flag(self, item_id: str) -> bool:
        logging.info(f"ã€Webhookä»»åŠ¡ã€‘æ­£åœ¨ä¸ºåª’ä½“é¡¹ (ID: {item_id}) å†™å…¥å¤„ç†å®Œæˆæ ‡è®°...")
        try:
            import requests
            item_details = self._get_emby_item_details(item_id, fields="ProviderIds")
            if not item_details:
                logging.error(f"ã€Webhookä»»åŠ¡ã€‘å†™å…¥æ ‡è®°å‰è·å–åª’ä½“è¯¦æƒ…å¤±è´¥ï¼Œæ— æ³•å†™å…¥æ ‡è®°ã€‚")
                return False

            item_details.setdefault("ProviderIds", {})[self.processed_flag_key] = datetime.utcnow().isoformat() + "Z"
            
            update_url = f"{self.server_config.server}/Items/{item_id}"
            headers = {'Content-Type': 'application/json'}
            params = {"api_key": self.server_config.api_key}
            
            response = requests.post(update_url, params=params, json=item_details, headers=headers, timeout=20)
            response.raise_for_status()
            
            logging.info(f"ã€Webhookä»»åŠ¡ã€‘æˆåŠŸä¸ºåª’ä½“é¡¹ (ID: {item_id}) å†™å…¥å¤„ç†å®Œæˆæ ‡è®°ã€‚")
            return True
        except Exception as e:
            logging.error(f"ã€Webhookä»»åŠ¡ã€‘ä¸ºåª’ä½“é¡¹ (ID: {item_id}) å†™å…¥æ ‡è®°æ—¶å¤±è´¥: {e}", exc_info=True)
            return False

    # --- æ–°å¢å‡½æ•°ï¼šå¿«é€Ÿæ£€æŸ¥ä¸»ç¼“å­˜æ˜¯å¦å­˜åœ¨æŒ‡å®šè±†ç“£ID ---
    def _check_cache_exists(self, douban_id: str) -> bool:
        """
        å¿«é€Ÿæ£€æŸ¥ä¸»ç¼“å­˜æ–‡ä»¶ (douban_data.json) ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„è±†ç“£IDã€‚
        """
        if not os.path.exists(DOUBAN_CACHE_FILE):
            logging.info("ã€Webhook-å¿«é€Ÿæ£€æŸ¥ã€‘ä¸»ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œæ£€æŸ¥ã€‚")
            return False
        try:
            with open(DOUBAN_CACHE_FILE, 'r', encoding='utf-8') as f:
                douban_map = json.load(f)
            return douban_id in douban_map
        except (IOError, json.JSONDecodeError) as e:
            logging.error(f"ã€Webhook-å¿«é€Ÿæ£€æŸ¥ã€‘è¯»å–ä¸»ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
    

    def _update_douban_cache_incrementally(self, douban_id: str, media_type: str) -> bool:
        logging.info(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘å¼€å§‹ä¸ºè±†ç“£ID {douban_id} æ‰§è¡Œå¢é‡ç¼“å­˜æ›´æ–°...")
        
        try:
            from filelock import FileLock, Timeout
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå®šä¹‰é”æ–‡ä»¶ç›®å½•å’Œè·¯å¾„ ---
            lock_dir = os.path.join(os.path.dirname(DOUBAN_CACHE_FILE), "locks")
            os.makedirs(lock_dir, exist_ok=True)
            lock_path = os.path.join(lock_dir, os.path.basename(DOUBAN_CACHE_FILE) + ".lock")
            # --- ç»“æŸä¿®æ”¹ ---

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„ lock_path ---
            lock = FileLock(lock_path, timeout=10)
            # --- ç»“æŸä¿®æ”¹ ---
            with lock:
                if os.path.exists(DOUBAN_CACHE_FILE):
                    with open(DOUBAN_CACHE_FILE, 'r', encoding='utf-8') as f:
                        douban_map = json.load(f)
                else:
                    douban_map = {}
                
                if douban_id in douban_map:
                    logging.info(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘è±†ç“£ID {douban_id} çš„æ•°æ®å·²å­˜åœ¨äºç¼“å­˜ä¸­ï¼Œè·³è¿‡æ–‡ä»¶æ›´æ–°ã€‚")
                    return True

                douban_data_root = self.config.douban_config.directory
                if not douban_data_root or not os.path.isdir(douban_data_root):
                    logging.error("ã€Webhook-æ•°æ®åŒæ­¥ã€‘è±†ç“£æ•°æ®æ ¹ç›®å½•æœªé…ç½®æˆ–æ— æ•ˆï¼Œæ— æ³•è¿›è¡Œå¢é‡æ›´æ–°ã€‚")
                    return False

                sub_dir = 'douban-movies' if media_type == 'Movie' else 'douban-tv'
                target_dir = os.path.join(douban_data_root, sub_dir)

                if not os.path.isdir(target_dir):
                    logging.error(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘æ‰¾ä¸åˆ°è±†ç“£æ•°æ®å­ç›®å½•: {target_dir}")
                    return False

                found_folder = None
                for folder_name in os.listdir(target_dir):
                    parsed_db_id, _ = _parse_folder_name(folder_name)
                    if parsed_db_id == douban_id:
                        found_folder = os.path.join(target_dir, folder_name)
                        break
                
                if not found_folder:
                    logging.error(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘åœ¨ {target_dir} ä¸­æœªæ‰¾åˆ°ä¸è±†ç“£ID {douban_id} åŒ¹é…çš„æ–‡ä»¶å¤¹ã€‚")
                    return False

                json_filename = 'all.json' if media_type == 'Movie' else 'series.json'
                json_path = os.path.join(found_folder, json_filename)

                if not os.path.isfile(json_path):
                    logging.error(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘åœ¨ç›®å½•ã€{found_folder}ã€‘ä¸­æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ {json_filename}ã€‚")
                    return False

                with open(json_path, 'r', encoding='utf-8') as f:
                    new_data = json.load(f)
                
                item_data = {
                    'type': media_type,
                    'title': new_data.get('title', 'N/A'),
                    'year': new_data.get('year', ''),
                    'genres': new_data.get('genres', []),
                    'intro': new_data.get('intro', ''),
                    'pic': new_data.get('pic', {}),
                    'actors': [
                        {
                            'id': actor.get('id'),
                            'name': actor.get('name'),
                            'latin_name': actor.get('latin_name'),
                            'character': actor.get('character'),
                            'avatar': actor.get('avatar', {})
                        } for actor in new_data.get('actors', [])
                    ],
                    'imdb_id': _parse_folder_name(os.path.basename(found_folder))[1],
                    'countries': new_data.get('countries', [])
                }
                
                extra_fields = self.config.douban_config.extra_fields
                if 'rating' in extra_fields: item_data['rating'] = new_data.get('rating', {}).get('value')
                if 'pubdate' in extra_fields: item_data['pubdate'] = new_data.get('pubdate', [])
                if 'card_subtitle' in extra_fields: item_data['card_subtitle'] = new_data.get('card_subtitle', '')
                if 'languages' in extra_fields: item_data['languages'] = new_data.get('languages', [])
                if 'durations' in extra_fields and media_type == 'Movie': item_data['durations'] = new_data.get('durations', [])

                douban_map[douban_id] = item_data
                with open(DOUBAN_CACHE_FILE, 'w', encoding='utf-8') as f:
                    json.dump(douban_map, f, ensure_ascii=False, indent=4)
                
                logging.info(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘æˆåŠŸå°†è±†ç“£ID {douban_id} çš„æ•°æ®å¢é‡æ›´æ–°åˆ°ç¼“å­˜æ–‡ä»¶ã€‚")
                return True
        except Timeout:
            logging.error("ã€Webhook-æ•°æ®åŒæ­¥ã€‘è·å–æ–‡ä»¶é”è¶…æ—¶ï¼Œå¦ä¸€ä¸ªè¿›ç¨‹å¯èƒ½æ­£åœ¨å†™å…¥ç¼“å­˜æ–‡ä»¶ã€‚")
            return False
        except Exception as e:
            logging.error(f"ã€Webhook-æ•°æ®åŒæ­¥ã€‘å¤„ç†æˆ–å†™å…¥æ–°è±†ç“£æ•°æ®æ—¶å¤±è´¥: {e}", exc_info=True)
            return False


    def process_new_media_task(self, item_id: str, cancellation_event: threading.Event, series_id: str):
        # --- æ–°å¢ï¼šä» main å¯¼å…¥å…¨å±€æ ‡è®°é›†åˆ ---
        from main import main_task_completed_series, episode_sync_queue_lock, id_map_update_lock
        import main as main_module
        # --- æ–°å¢ç»“æŸ ---
        from tmdb_logic import TmdbLogic
        from chasing_center_logic import ChasingCenterLogic
        from actor_role_mapper_logic import ActorRoleMapperLogic, ACTOR_ROLE_MAP_FILE
        # --- æ–°å¢ï¼šå¯¼å…¥ç”µå½±é‡å‘½åé€»è¾‘ ---
        from movie_renamer_logic import MovieRenamerLogic
        # --- æ–°å¢ç»“æŸ ---

        item_details_pre = self._get_emby_item_details(item_id)
        item_name_pre = item_details_pre.get("Name", f"Item {item_id}") if item_details_pre else f"Item {item_id}"
        task_cat = f"Webhook-{item_name_pre}"

        ui_logger.info(f"ã€Webhookä»»åŠ¡ã€‘å·²å¯åŠ¨ï¼Œå¼€å§‹å¤„ç†æ–°å…¥åº“åª’ä½“: {item_name_pre} (ID: {item_id})", task_category=task_cat)
        
        ui_logger.info(f"ã€æ­¥éª¤ 0/9 | æ£€æŸ¥æ ‡è®°ã€‘æ­£åœ¨æ£€æŸ¥åª’ä½“é¡¹æ˜¯å¦å·²è¢«å¤„ç†è¿‡...", task_category=task_cat)
        item_details = self._get_emby_item_details(item_id)
        if not item_details:
            ui_logger.error(f"æ— æ³•è·å–åª’ä½“ {item_id} çš„è¯¦ç»†ä¿¡æ¯ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return

        item_name = item_details.get("Name", f"Item {item_id}")
        
        provider_ids = item_details.get("ProviderIds", {})
        provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
        if self.processed_flag_key.lower() in provider_ids_lower:
            processed_time = provider_ids_lower[self.processed_flag_key.lower()]
            ui_logger.info(f"æ£€æµ‹åˆ°åª’ä½“ã€{item_name}ã€‘å·²äº {processed_time} è¢«å¤„ç†è¿‡ï¼Œæœ¬æ¬¡ä»»åŠ¡è·³è¿‡ã€‚", task_category=task_cat)
            # --- æ–°å¢ï¼šå³ä½¿è·³è¿‡ï¼Œä¹Ÿè¦ç¡®ä¿è®¾ç½®å®Œæˆæ ‡è®°ï¼Œä»¥é˜²ä¸‡ä¸€ ---
            with episode_sync_queue_lock:
                if series_id not in main_task_completed_series:
                    main_task_completed_series.add(series_id)
                    ui_logger.info(f"   - [è¡¥ä¸] ä¸ºå·²å¤„ç†è¿‡çš„å‰§é›†ã€Š{item_name}ã€‹è¡¥åŠ ä¸»æµç¨‹å®Œæˆæ ‡è®°ï¼Œä»¥è§¦å‘å¯èƒ½ç§¯å‹çš„åˆ†é›†åŒæ­¥ä»»åŠ¡ã€‚", task_category=task_cat)
            # --- æ–°å¢ç»“æŸ ---
            return

        ui_logger.info(f"åª’ä½“ã€{item_name}ã€‘æ˜¯é¦–æ¬¡å¤„ç†ï¼Œç»§ç»­æ‰§è¡Œè‡ªåŠ¨åŒ–æµç¨‹ã€‚", task_category=task_cat)

        wait_time = self.webhook_config.initial_wait_time

        ui_logger.info(f"ã€æ­¥éª¤ 1/9 | åˆå§‹ç­‰å¾…ã€‘ç­‰å¾… {wait_time} ç§’ï¼Œä»¥ä¾¿ Emby è‡ªåŠ¨åˆ®å‰Š... (å¯é…ç½®)", task_category=task_cat)

        time.sleep(wait_time)
        if cancellation_event.is_set(): return

        ui_logger.info(f"ã€æ­¥éª¤ 2/9 | è·å–è±†ç“£IDã€‘å¼€å§‹...", task_category=task_cat)
        item_details = self._get_emby_item_details(item_id)
        if not item_details:
            ui_logger.error(f"ç­‰å¾…åæ— æ³•å†æ¬¡è·å–åª’ä½“ã€{item_name}ã€‘çš„è¯¦ç»†ä¿¡æ¯ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚", task_category=task_cat)
            return
        
        item_type = item_details.get("Type", "Movie")
        provider_ids = item_details.get("ProviderIds", {})
        douban_id = next((v for k, v in provider_ids.items() if k.lower() == 'douban'), None)

        if douban_id:
            ui_logger.info(f"ã€è±†ç“£IDä¿®å¤ã€‘åª’ä½“ã€{item_name}ã€‘å·²æœ‰å…³è”çš„è±†ç“£ID: {douban_id}ï¼Œè·³è¿‡IDä¿®å¤æ­¥éª¤ã€‚", task_category=task_cat)
        else:
            ui_logger.info(f"ã€è±†ç“£IDä¿®å¤ã€‘åª’ä½“ã€{item_name}ã€‘ç¼ºå°‘è±†ç“£IDï¼Œå¼€å§‹æ‰§è¡ŒIDä¿®å¤...", task_category=task_cat)
            fixer_logic = DoubanFixerLogic(self.config)
            if fixer_logic._process_single_item_for_fixing(item_id, task_cat):
                refreshed_details = self._get_emby_item_details(item_id)
                douban_id = next((v for k, v in refreshed_details.get("ProviderIds", {}).items() if k.lower() == 'douban'), None)
                if douban_id:
                    ui_logger.info(f"ã€è±†ç“£IDä¿®å¤ã€‘æˆåŠŸä¿®å¤å¹¶è·å–åˆ°æ–°çš„è±†ç“£ID: {douban_id}", task_category=task_cat)
                else:
                    ui_logger.error(f"ã€è±†ç“£IDä¿®å¤ã€‘ä¿®å¤ä»»åŠ¡å£°ç§°æˆåŠŸï¼Œä½†ä»æœªè·å–åˆ°è±†ç“£IDã€‚", task_category=task_cat)
            else:
                ui_logger.error(f"ã€è±†ç“£IDä¿®å¤ã€‘IDä¿®å¤å¤±è´¥ã€‚", task_category=task_cat)
        
        if not douban_id:
            ui_logger.error(f"æœ€ç»ˆæœªèƒ½è·å–åˆ°è±†ç“£IDï¼Œè‡ªåŠ¨åŒ–æµç¨‹ä¸­æ­¢ã€‚", task_category=task_cat)
            return
        if cancellation_event.is_set(): return

        if item_type == "Series" and self.config.chasing_center_config.enabled:
            ui_logger.info(f"ã€æ­¥éª¤ 3/9 | è¿½æ›´åˆ¤æ–­ã€‘æ£€æµ‹åˆ°æ–°å…¥åº“å‰§é›†ï¼Œå¼€å§‹åˆ¤æ–­æ˜¯å¦åŠ å…¥è¿½æ›´åˆ—è¡¨...", task_category=task_cat)
            try:
                provider_ids_lower = {k.lower(): v for k, v in provider_ids.items()}
                tmdb_id = provider_ids_lower.get("tmdb")

                if tmdb_id:
                    tmdb_logic = TmdbLogic(self.config)
                    tmdb_details = tmdb_logic._tmdb_request(f"tv/{tmdb_id}")
                    status = tmdb_details.get("status")
                    if status in ["Returning Series", "In Production"]:
                        chasing_logic = ChasingCenterLogic(self.config)
                        chasing_logic.add_to_chasing_list(
                            series_id=item_id, 
                            series_name=item_name
                        )
                    else:
                        ui_logger.info(f"å‰§é›†ã€Š{item_name}ã€‹åœ¨ TMDB çš„çŠ¶æ€ä¸º '{status}'ï¼Œéæ’­å‡ºä¸­ï¼Œè·³è¿‡æ·»åŠ ã€‚", task_category=task_cat)
                else:
                    ui_logger.warning(f"å‰§é›†ã€Š{item_name}ã€‹ç¼ºå°‘ TMDB IDï¼Œæ— æ³•åˆ¤æ–­å…¶æ’­å‡ºçŠ¶æ€ï¼Œè·³è¿‡æ·»åŠ ã€‚", task_category=task_cat)
            except Exception as e:
                ui_logger.error(f"âŒ åœ¨åˆ¤æ–­è¿½æ›´çŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {e}", task_category=task_cat)

        ui_logger.info(f"ã€æ­¥éª¤ 4/9 | åŒæ­¥è±†ç“£æ•°æ®ã€‘å¼€å§‹...", task_category=task_cat)
        
        ui_logger.info(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘æ­£åœ¨å¿«é€Ÿæ£€æŸ¥è±†ç“£ID {douban_id} æ˜¯å¦å·²å­˜åœ¨äºä¸»ç¼“å­˜ä¸­...", task_category=task_cat)
        if self._check_cache_exists(douban_id):
            ui_logger.info(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘å‘½ä¸­ç¼“å­˜ï¼æ— éœ€ç­‰å¾…ï¼Œç›´æ¥è¿›å…¥åç»­æµç¨‹ã€‚", task_category=task_cat)
        else:
            ui_logger.info(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘æœªå‘½ä¸­ç¼“å­˜ï¼Œéœ€è¦ç­‰å¾…è±†ç“£æ’ä»¶ä¸‹è½½å…ƒæ•°æ®ã€‚", task_category=task_cat)
            wait_time_for_plugin = self.webhook_config.plugin_wait_time
            ui_logger.info(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘å¼€å§‹ç­‰å¾… {wait_time_for_plugin} ç§’... (æ­¤æ—¶é—´å¯åœ¨â€œå®šæ—¶ä»»åŠ¡â€é¡µé¢çš„Webhookè®¾ç½®ä¸­ä¿®æ”¹)", task_category=task_cat)
            time.sleep(wait_time_for_plugin)
            
            if cancellation_event.is_set(): return

            ui_logger.info(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘ç­‰å¾…ç»“æŸï¼Œå¼€å§‹å°è¯•ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå¢é‡æ›´æ–°ç¼“å­˜ã€‚", task_category=task_cat)
            if not self._update_douban_cache_incrementally(douban_id, item_type):
                ui_logger.warning(f"ã€æ™ºèƒ½ç­‰å¾…ã€‘å¢é‡æ›´æ–°å¤±è´¥ã€‚æœªèƒ½ä»æœ¬åœ°æ–‡ä»¶æ‰¾åˆ°è±†ç“£ID {douban_id} çš„å…ƒæ•°æ®ï¼Œåç»­æµç¨‹å¯èƒ½å¤±è´¥æˆ–ä½¿ç”¨æ—§æ•°æ®ã€‚", task_category=task_cat)
        
        if cancellation_event.is_set(): return

        actor_localization_skipped = False
        ui_logger.info(f"ã€æ­¥éª¤ 5/9 | è§’è‰²æ˜ å°„æ£€æŸ¥ã€‘å¼€å§‹...", task_category=task_cat)
        
        item_details_for_map_check = self._get_emby_item_details(item_id, "ProviderIds,Type")
        provider_ids_lower_for_map = {k.lower(): v for k, v in item_details_for_map_check.get("ProviderIds", {}).items()}
        tmdb_id_for_map = provider_ids_lower_for_map.get("tmdb")
        item_type_for_map = item_details_for_map_check.get("Type")

        if tmdb_id_for_map and item_type_for_map and os.path.exists(ACTOR_ROLE_MAP_FILE):
            type_prefix = 'tv' if item_type_for_map == 'Series' else 'movie'
            map_key = f"{type_prefix}-{tmdb_id_for_map}"
            
            ui_logger.info(f"   - æ­£åœ¨æ£€æŸ¥ Key: {map_key} æ˜¯å¦å­˜åœ¨äºæœ¬åœ°æ˜ å°„è¡¨ä¸­...", task_category=task_cat)
            try:
                with open(ACTOR_ROLE_MAP_FILE, 'r', encoding='utf-8') as f:
                    actor_role_map = json.load(f)
                
                if map_key in actor_role_map:
                    ui_logger.info(f"   - âœ… å‘½ä¸­ï¼åœ¨æ˜ å°„è¡¨ä¸­æ‰¾åˆ°äº†ã€Š{item_name}ã€‹çš„è§’è‰²æ•°æ®ã€‚", task_category=task_cat)
                    actor_localization_skipped = True
                    
                    ui_logger.info(f"ã€æ­¥éª¤ 6/9 | æ¼”å‘˜ä¸­æ–‡åŒ–ã€‘â¡ï¸ [è·³è¿‡] å› æ‰¾åˆ°ç°æœ‰æ˜ å°„ï¼Œè·³è¿‡ä¸­æ–‡åŒ–æ­¥éª¤ã€‚", task_category=task_cat)
                    ui_logger.info(f"ã€æ­¥éª¤ 7/9 | è§’è‰²æ˜ å°„ç”Ÿæˆã€‘â¡ï¸ [è·³è¿‡] å› æ‰¾åˆ°ç°æœ‰æ˜ å°„ï¼Œè·³è¿‡æ˜ å°„ç”Ÿæˆæ­¥éª¤ã€‚", task_category=task_cat)
                    
                    ui_logger.info(f"   - ğŸ”„ [è§’è‰²æ¢å¤] å¼€å§‹å°†å·²å­˜åœ¨çš„ä¸­æ–‡è§’è‰²ååº”ç”¨åˆ°æ–°å…¥åº“çš„åª’ä½“é¡¹...", task_category=task_cat)
                    role_mapper_logic = ActorRoleMapperLogic(self.config)
                    map_data = actor_role_map[map_key]
                    
                    role_mapper_logic.restore_single_map_task(
                        item_ids=[item_id],
                        role_map=map_data.get("map", {}),
                        title=map_data.get("title", item_name),
                        cancellation_event=cancellation_event,
                        task_id=None,
                        task_manager=None
                    )
                else:
                    ui_logger.info(f"   - æœªåœ¨æ˜ å°„è¡¨ä¸­æ‰¾åˆ° Key: {map_key} çš„è®°å½•ï¼Œå°†æ‰§è¡Œæ ‡å‡†æµç¨‹ã€‚", task_category=task_cat)
            except (IOError, json.JSONDecodeError) as e:
                ui_logger.warning(f"   - âš ï¸ è¯»å–æœ¬åœ°è§’è‰²æ˜ å°„è¡¨å¤±è´¥ï¼Œå°†æ‰§è¡Œæ ‡å‡†æµç¨‹ã€‚é”™è¯¯: {e}", task_category=task_cat)
        else:
            if not tmdb_id_for_map or not item_type_for_map:
                ui_logger.info(f"   - åª’ä½“é¡¹ç¼ºå°‘ TMDB ID æˆ–ç±»å‹ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œæ˜ å°„æ£€æŸ¥ï¼Œå°†æ‰§è¡Œæ ‡å‡†æµç¨‹ã€‚", task_category=task_cat)
            else:
                ui_logger.info(f"   - æœ¬åœ°è§’è‰²æ˜ å°„è¡¨ä¸å­˜åœ¨ï¼Œå°†æ‰§è¡Œæ ‡å‡†æµç¨‹ã€‚", task_category=task_cat)

        if not actor_localization_skipped:
            ui_logger.info(f"ã€æ­¥éª¤ 6/9 | æ¼”å‘˜ä¸­æ–‡åŒ–ã€‘å¼€å§‹...", task_category=task_cat)
            actor_localization_success = False
            try:
                localizer_logic = ActorLocalizerLogic(self.config)
                localizer_logic._process_single_item_for_localization(item_id, self.config.actor_localizer_config, task_category=task_cat)
                actor_localization_success = True
            except Exception as e:
                ui_logger.error(f"ã€æ¼”å‘˜ä¸­æ–‡åŒ–ã€‘æ­¥éª¤æ‰§è¡Œå¤±è´¥ï¼Œä½†å°†ç»§ç»­åç»­ä»»åŠ¡ã€‚é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            if cancellation_event.is_set(): return

            ui_logger.info(f"ã€æ­¥éª¤ 7/9 | æ¼”å‘˜è§’è‰²æ˜ å°„ã€‘å¼€å§‹...", task_category=task_cat)
            if actor_localization_success:
                try:
                    role_mapper_logic = ActorRoleMapperLogic(self.config)
                    role_mapper_logic.generate_map_for_single_item(item_id, task_category=task_cat)
                except Exception as e:
                    ui_logger.error(f"ã€æ¼”å‘˜è§’è‰²æ˜ å°„ã€‘æ­¥éª¤æ‰§è¡Œå¤±è´¥ã€‚é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
            else:
                ui_logger.warning("ã€æ¼”å‘˜è§’è‰²æ˜ å°„ã€‘å› æ¼”å‘˜ä¸­æ–‡åŒ–æ­¥éª¤å¤±è´¥ï¼Œæœ¬æ­¥éª¤å·²è·³è¿‡ã€‚", task_category=task_cat)
        if cancellation_event.is_set(): return

        ui_logger.info(f"ã€æ­¥éª¤ 8/9 | è±†ç“£æµ·æŠ¥æ›´æ–°ã€‘å¼€å§‹...", task_category=task_cat)
        try:
            poster_logic = DoubanPosterUpdaterLogic(self.config)
            poster_logic.run_poster_update_for_items([item_id], self.config.douban_poster_updater_config, cancellation_event, None, None)
        except Exception as e:
            ui_logger.error(f"ã€è±†ç“£æµ·æŠ¥æ›´æ–°ã€‘æ­¥éª¤æ‰§è¡Œå¤±è´¥ã€‚é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
        if cancellation_event.is_set(): return
        
        # --- æ–°å¢ï¼šç”µå½±æ–‡ä»¶é‡å‘½åé€»è¾‘ ---
        if item_type == "Movie":
            ui_logger.info(f"ã€æ­¥éª¤ 9/9 | ç”µå½±æ–‡ä»¶é‡å‘½åã€‘å¼€å§‹...", task_category=task_cat)
            try:
                movie_renamer_logic = MovieRenamerLogic(self.config)
                # é‡æ–°è·å–ä¸€æ¬¡æœ€æ–°çš„åª’ä½“ä¿¡æ¯ï¼Œç¡®ä¿ Path å’Œ MediaSources æ˜¯å‡†ç¡®çš„
                final_movie_details = self._get_emby_item_details(item_id, fields="Name,Path,MediaSources")
                if final_movie_details:
                    movie_renamer_logic.process_single_movie(final_movie_details, task_cat)
                else:
                    ui_logger.error(f"ã€ç”µå½±æ–‡ä»¶é‡å‘½åã€‘åœ¨æœ€åé˜¶æ®µæ— æ³•è·å–ç”µå½±è¯¦æƒ…ï¼Œè·³è¿‡é‡å‘½åã€‚", task_category=task_cat)
            except Exception as e:
                # å³ä½¿é‡å‘½åå¤±è´¥ï¼Œä¹Ÿåªè®°å½•é”™è¯¯ï¼Œä¸å½±å“åç»­æµç¨‹
                ui_logger.error(f"ã€ç”µå½±æ–‡ä»¶é‡å‘½åã€‘æ­¥éª¤æ‰§è¡Œæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œä½†å°†ç»§ç»­å®Œæˆ Webhook æµç¨‹ã€‚é”™è¯¯: {e}", task_category=task_cat, exc_info=True)
        # --- æ–°å¢ç»“æŸ ---

        if item_type == "Series":
            with episode_sync_queue_lock:
                if series_id not in main_task_completed_series:
                    main_task_completed_series.add(series_id)
                    ui_logger.info(f"   - ğŸ”” [çŠ¶æ€åŒæ­¥] å·²ä¸ºå‰§é›†ã€Š{item_name}ã€‹è®¾ç½®ä¸»æµç¨‹å®Œæˆæ ‡è®°ï¼Œåˆ†é›†åŒæ­¥ä»»åŠ¡ç°å¯è°ƒåº¦ã€‚", task_category=task_cat)

        ui_logger.info(f"ã€æœ€ç»ˆæ­¥éª¤ | å†™å…¥æ ‡è®°ã€‘æ‰€æœ‰è‡ªåŠ¨åŒ–æ­¥éª¤æ‰§è¡Œå®Œæ¯•ï¼Œå¼€å§‹å†™å…¥å®Œæˆæ ‡è®°...", task_category=task_cat)
        if self._set_processed_flag(item_id):
            ui_logger.info(f"ğŸ‰ åª’ä½“ã€{item_name}ã€‘çš„é¦–æ¬¡è‡ªåŠ¨åŒ–å¤„ç†æµç¨‹å·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯•å¹¶æˆåŠŸæ ‡è®°ã€‚", task_category=task_cat)
        else:
            ui_logger.warning(f"åª’ä½“ã€{item_name}ã€‘çš„è‡ªåŠ¨åŒ–æµç¨‹å·²æ‰§è¡Œï¼Œä½†å†™å…¥å®Œæˆæ ‡è®°å¤±è´¥ã€‚ä¸‹æ¬¡å¯èƒ½ä¼šé‡å¤æ‰§è¡Œã€‚", task_category=task_cat)

        try:
            with id_map_update_lock:
                setattr(main_module, 'id_map_update_request_time', time.time())
            ui_logger.info(f"ğŸ””ã€IDæ˜ å°„è°ƒåº¦å™¨ã€‘å·²æˆåŠŸå‘é€IDæ˜ å°„è¡¨æ›´æ–°è¯·æ±‚ï¼Œé™é»˜æœŸè®¡æ—¶å™¨å·²é‡ç½®ã€‚", task_category=task_cat)
        except Exception as e:
            ui_logger.error(f"âŒã€Webhookä»»åŠ¡ã€‘å‘é€IDæ˜ å°„è¡¨æ›´æ–°è¯·æ±‚æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", task_category=task_cat, exc_info=True)